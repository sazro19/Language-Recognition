<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Нейросети для Natural Language Inference: логические умозаключения на русском языке / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/582620\/"},"headline":"Нейросети для Natural Language Inference: логические умозаключения на русском языке","datePublished":"2021-10-10T15:35:35+03:00","dateModified":"2021-10-10T23:02:46+03:00","author":{"@type":"Person","name":"Давид Дале"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"NLI (natural language inference) &ndash; это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и...","url":"https:\/\/habr.com\/ru\/post\/582620\/#post-content-body","about":["h_python","h_sw","h_programming","h_machine_learning","h_natural_language_processing","f_develop"],"image":["https:\/\/habr.com\/share\/publication\/582620\/98c99ff9d4d3fafb0382d89f2d55523c\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/b2a\/eb2\/cea\/b2aeb2ceaaa7d99ad953521f3e0a516a.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Нейросети для Natural Language Inference: логические умозаключения на русском языке" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Нейросети для Natural Language Inference: логические умозаключения на русском языке" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Нейросети для Natural Language Inference: логические умозаключения на русском языке" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A...." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A...." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A...." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A...." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A...." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="582620" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-10T12:35:35.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/582620/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/582620/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/getpro/habr/upload_files/3e1/4e8/5ff/3e14e85ffdb43c91e3f7de0875586f4a.png" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/582620/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/cointegrated/" title="cointegrated" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/0c9/340/334/0c934033455e38414b615e309d337a3d.jpg" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/cointegrated/" class="tm-user-info__username">
      cointegrated
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-10T12:35:35.000Z" title="2021-10-10, 15:35">10  октября   в 15:35</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Нейросети для Natural Language Inference: логические умозаключения на русском языке</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/python/" class="tm-article-snippet__hubs-item-link"><span>Python</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/sw/" class="tm-article-snippet__hubs-item-link"><span>Семантика</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/programming/" class="tm-article-snippet__hubs-item-link"><span>Программирование</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/natural_language_processing/" class="tm-article-snippet__hubs-item-link"><span>Natural Language Processing</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p>NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A. Эта задача сложная, потому что она требует хорошо понимать смысл текстов. Эта задача полезная, потому что "понимательную" способность модели можно эксплуатировать для прикладных задач типа классификации текстов. Иногда такая классификация неплохо работает даже без обучающей выборки! </p><p>До сих пор в открытом доступе не было нейросетей, специализированных на задаче NLI для русского языка, но теперь я обучил целых три: <a href="https://huggingface.co/cointegrated/rubert-tiny-bilingual-nli" rel="noopener noreferrer nofollow">tiny</a>, <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-twoway" rel="noopener noreferrer nofollow">twoway</a> и <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway" rel="noopener noreferrer nofollow">threeway</a>. Зачем эти модели нужны, как они обучались, и в чём между ними разница – под катом.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Модели NLI можно применять и для логического вывода, и для классификации текстов" title="Модели NLI можно применять и для логического вывода, и для классификации текстов" height="440" data-src="https://habrastorage.org/getpro/habr/upload_files/b2a/eb2/cea/b2aeb2ceaaa7d99ad953521f3e0a516a.png" data-width="780"/><figcaption>Модели NLI можно применять и для логического вывода, и для классификации текстов</figcaption></figure><h2>Задача NLI</h2><p>На русский язык понятие <em>natural language inference</em> можно перевести как <em>логический вывод (</em>или<em> умозаключения) на естественном языке</em>. Обычно эта задача формулируется как классификация пары текстов на два класса (<code>entailment/not_entailment</code>) или на три класса (<code>entailment/contradiction/neutral</code>). Выглядят классы примерно так:</p><ul><li><p>из "Петя – хакер" <em>следует</em>, что  "Петя – айтишник", ибо нам известно, что все хакеры – айтишники. Это <em>entailment</em>.</p></li><li><p>из "Петя – хакер" <em>не следует</em> "Петя – кот", более того, второе утверждение <em>противоречит</em> первому, потому что хакерами вроде как бывают только люди, но не коты. Это <em>contradiction.</em></p></li><li><p>из "Петя – козёл" <em>не следует</em>, что "Вася тоже хакер", но и противоречия между этими утверждениями нет. Это отношение зовётся <em>neutral</em>.</p></li></ul><p>В задаче NLI левый текст обычно называется <em>предпосылкой</em> (premise), а правый – <em>гипотезой</em> (hypothesis), и я буду придерживаться такой же терминологии.</p><p>Чтобы правильно делать подобные суждения, модель должна уметь очень много. Она должна знать слова ("хакер", "кот") и связи между ними ("хакеры – айтишники", "айтишники – люди", "коты – не люди"). Должна уметь в логические операции (отрицания, и/или, если/то, каждый/некоторый и т.п.). Должна понимать природу сущностей ("Швеция – это страна").  Должна понимать, как связаны друг с другом отношения между сущностями (если существует "Король Швеции", то "Швеция – это королевство"). Более подробно про эти умения можно почитать на сайте <a href="https://russiansuperglue.com/ru/datasets/" rel="noopener noreferrer nofollow">RussianSuperGLUE</a>, но уже и так понятно, что модель должна очень хорошо понимать смысл текстов. </p><p>За последние несколько лет появилось много нейросетей типа <a href="https://arxiv.org/abs/1810.04805" rel="noopener noreferrer nofollow">BERT</a>, предобученных так, что базовое понимание языка у них уже неплохое, в том числе и <a href="https://habr.com/ru/post/562064/" rel="noopener noreferrer nofollow">ряд моделей для русского языка</a>. При обучении двух из них (<a href="https://huggingface.co/DeepPavlov/rubert-base-cased-sentence" rel="noopener noreferrer nofollow">rubert-base-cased-sentence</a> от<a href="https://habr.com/ru/company/mipt/blog/472890/" rel="noopener noreferrer nofollow"> DeepPavlov</a> и <a href="https://huggingface.co/sberbank-ai/sbert_large_nlu_ru" rel="noopener noreferrer nofollow">sbert_large_nlu_ru</a> от <a href="https://habr.com/ru/company/sberdevices/blog/527576/" rel="noopener noreferrer nofollow">SberDevices</a>) даже использовались датасеты NLI, переведённые на русский язык. Но обе они устроены так, что сначала обрабатывают каждый текст по отдельности, а потом сравнивают между собой уже абстрактные представления (точнее, sentence embeddings) этих текстов. Если же модель читает оба текста одновременно, при необходимости "подглядывая" механизмом внимания из одного текста в другой (это называется <em>cross-encoder</em>), она имеет больше шансов понять, как связаны друг с другом смыслы этих текстов. Именно такие модели я и обучил. </p><h2>Применение</h2><p>Задача NLI важна для компьютерных лингвистов, ибо она позволяет детально рассмотреть, какие языковые явления данная модель понимает хорошо, а на каких – "плывёт"; по этому принципу устроены диагностические датасеты <a href="https://super.gluebenchmark.com/diagnostics" rel="noopener noreferrer nofollow">SuperGLUE </a>и <a href="https://russiansuperglue.com/ru/datasets/" rel="noopener noreferrer nofollow">RussianSuperGLUE</a>. Кроме этого, модели NLI обладают прикладной ценностью по нескольким причинам.</p><p>Во-первых, NLI можно использовать для контроля качества генеративных моделей. Есть масса задач, где на основе текста X нужно сгенерировать близкий к нему по смыслу текст Y: суммаризация, упрощение текстов, перефразирование, перенос стиля на текстах, текстовые вопросно-ответные системы, и даже машинный перевод. Современные seq2seq нейросети типа T5 (которая в этом году <a href="https://habr.com/ru/post/581932/" rel="noopener noreferrer nofollow">появилась и для русского языка</a>) в целом неплохо справляются с такими задачами, но время от времени лажают, упуская какую-то важную информацию из Х, или, наоборот, дописывая в текст Y что-то нафантазированное "от себя". С помощью модели NLI можно проверять, что из X следует Y (то есть в новом тексте нету "отсебятины", придуманной моделью), и что из Y следует X (т.е. вся информация, присутствовавшая в исходном тексте, в новом также отражена).  </p><p>Во-вторых, с помощью моделей NLI можно находить нетривиальные парафразы и в целом определять смысловую близость текстов. Для русского языка уже существует <a href="https://habr.com/ru/post/564916/" rel="noopener noreferrer nofollow">ряд моделей и датасетов по перефразированию</a>, но кажется, что можно сделать ещё больше и лучше. В статье <a href="https://arxiv.org/abs/2106.07691" rel="noopener noreferrer nofollow">Improving Paraphrase Detection with the Adversarial Paraphrasing Task </a>предложили считать парафразами такую пару предложений, в которой каждое логически следует из другого – и это весьма логично. Поэтому модели NLI можно использовать и для сбора обучающего корпуса парафраз (и не-парафраз, если стоит задача их детекции), и для фильтрации моделей, генерирующих парафразы.</p><p>В-третьих, NLI можно переиспользовать для задачи классификации текстов с небольшим числом обучающих примеров или даже <em>вообще без обучающей выборки</em>. В статье <a href="https://arxiv.org/pdf/2104.14690.pdf" rel="noopener noreferrer nofollow">Entailment as Few-Shot Learner</a> модель, обученную на задаче NLI, дообучали буквально на 8 примерах на новые задачи классификации текстов, и в результате модель справлялась с ними весьма неплохо; в других работах этот подход демонстрировали вообще без дообучения (хотя с этим и <a href="https://aclanthology.org/2021.acl-short.99/" rel="noopener noreferrer nofollow">обнаружены проблемы</a>). Работает это так: для текста, который надо классифицировать, готовится несколько выводов соответствующих разным, и выбирается самый правдоподобный из них. Например, так можно решить задачу анализа тональности текста:</p><pre><code class="python"># !pip install transformers sentencepiece
from transformers import pipeline
p = pipeline(
  task='zero-shot-classification', 
  model='cointegrated/rubert-base-cased-nli-twoway'
)
p(
  sequences="Сервис приличный, кормили вкусно", 
  candidate_labels="Мне понравилось, Мне не понравилось", 
  hypothesis_template="{}."
)
# {'labels': ['Мне понравилось', 'Мне не понравилось'],
#  'scores': [0.9580550789833069, 0.0419449619948864],
#  'sequence': 'Сервис приличный, кормили вкусно'}</code></pre><p>Здесь модель решила, что из текста отзыва вывод "<em>Мне понравилось.</em>" следует с двадцатикратно большей вероятностью, чем вывод "<em>Мне не понравилось</em>", и таким образом классифицировала текст как положительный. </p><p>Конкретно в этой имплементации (<a href="https://huggingface.co/transformers/main_classes/pipelines.html" rel="noopener noreferrer nofollow">transformers.pipelines</a>) метки классов можно подавать в виде одного полотна текста (через запятую) или как список строк, а аргумент <code>hypothesis_template</code> показывает, в форме какого шаблона эти метки должны подаваться в модель. Классов может быть сколько угодно, например, семь разных тематик, из которых модель правильно выбирает "путешествия":</p><pre><code class="python">p(
  sequences="Я хочу поехать в Дагестан", 
  candidate_labels="спорт,путешествия,музыка,кино,книги,наука,политика", 
  hypothesis_template="Мои интересы - {}."
)
# {'sequence': 'Я хочу поехать в Дагестан', 
   'labels': ['путешествия', 'спорт', 'политика', 'наука', 'кино', 'музыка', 'книги'], 
   'scores': [0.948, 0.019, 0.007, 0.006, 0.006, 0.005, 0.005]}</code></pre><p>Лично у меня zero-shot классификация на базе NLI не особо взлетела. Например, на задаче классификации 68 интентов zero-shot классификация на основе NLI с написанными вручную 68 гипотезами для каждого класса отработала хуже, чем метод ближайших соседей на эмбеддингах <a href="https://huggingface.co/cointegrated/LaBSE-en-ru" rel="noopener noreferrer nofollow">LaBSE </a>с всего лишь тремя примерами на каждый класс. На задачах классификации тональности и токсичности подход Labse+KNN тоже сравнялся по качеству с NLI+zero-shot на нескольких десятках размеченных примеров.  </p><p>Поэтому кажется, что zero-shot классификацию стоит применять только в случаях, когда нет возможности собрать даже небольшую обучающую выборку, и что её качество будет сильно зависеть от выбранных названий классов и от того, какой шаблон используется для гипотез. Поэтому, если есть возможность дообучить свою модель на задачу классификации, лучше дообучайте. Если возможности нет, но есть даже небольшое число размеченных примеров, используйте KNN. А к zero-shot прибегайте только в крайних случаях.</p><p>Впрочем, несмотря на свою относительную бесполезность, zero-shot классификация – это всё равно очень прикольно.</p><h2>Датасеты</h2><p>Насколько мне известно, сегодня существует два датасета, посвящённых задаче NLI на русском языке: <a href="https://russiansuperglue.com/ru/tasks/task_info/TERRa" rel="noopener noreferrer nofollow">TERRa</a>, собранная из русскоязычных публикаций и вручную размеченная, и <a href="https://github.com/facebookresearch/XNLI" rel="noopener noreferrer nofollow">XNLI</a>, где английские размеченные тексты были переведены на русский и ряд других языков. Оба эти датасета не очень большие, зато на английском языке существуют буквально миллионы размеченных пар текстов. Поэтому в качестве обучающей выборки я использовал в основном корпусы, машинно переведённые с английского языка. Большинство из них было взято из репозитория <a href="https://github.com/felipessalvatore/NLI_datasets" rel="noopener noreferrer nofollow">Felipe Salvatore</a>.</p><ul><li><p><a href="https://cs.brown.edu/people/epavlick/papers/ans.pdf" rel="noopener noreferrer nofollow">Add-one RTE</a>: корпус, в котором в текст добавляется одно слово, которое может поменять или не поменять его смысл. Например, "вселенная" и "вся вселенная" идентичны по смыслу, а "вселенная" и "воображаемая вселенная" – разные. </p></li><li><p><a href="https://github.com/facebookresearch/anli" rel="noopener noreferrer nofollow">ANLI</a>: три корпуса, собранные вручную таким образом, чтобы с примерами из них плохо справлялись уже имеющиеся продвинутые NLI модели.</p></li><li><p><a href="https://people.ict.usc.edu/~gordon/copa.html" rel="noopener noreferrer nofollow">CoPA</a>: корпус, в котором модель должна догадываться о возможных причинах и следствиях событий.</p></li><li><p><a href="https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md" rel="noopener noreferrer nofollow">NLI-style FEVER</a>: корпус, проверяющий, есть ли в данном источнике подтверждение данного факта.</p></li><li><p><a href="https://github.com/verypluming/HELP" rel="noopener noreferrer nofollow">HELP</a>: автоматически созданный корпус, требующий работы со значениями слов и логикой.</p></li><li><p><a href="https://github.com/facebookresearch/Imppres" rel="noopener noreferrer nofollow">IMPPRES</a>: автоматически сгенерированный датасет, анализирующий допущения, неявно подразумеваемые в тексте.</p></li><li><p><a href="https://aclanthology.org/I17-1100" rel="noopener noreferrer nofollow">IIE</a>: корпус из статьи"Inference is everything", представляющий в форме NLI другие лингвистические задачи: определение семантических ролей, понимание контекстных парафраз, и расшифровка местоимений.</p></li><li><p><a href="https://github.com/sheng-z/JOCI" rel="noopener noreferrer nofollow">JOCI</a>: корпус, фокусирующийся на применении "здравого смысла" (common sense).</p></li><li><p><a href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener noreferrer nofollow">MNLI</a>: большой многожанровый корпус, собранный из разнообразных устных и письменных источников.</p></li><li><p><a href="https://github.com/atticusg/MoNLI" rel="noopener noreferrer nofollow">MoNLI</a>: корпус, фокусирующийся на отношении "частное/общее". </p></li><li><p><a href="https://aclanthology.org/I17-1011/" rel="noopener noreferrer nofollow">MPE</a>: корпус, где вывод нужно сделать на основе не одной, а множества предпосылок.</p></li><li><p><a href="https://allenai.org/data/scitail" rel="noopener noreferrer nofollow">SCITAIL</a>: корпус вопросов на научную тематику, собранный из экзаменов и интернета.</p></li><li><p><a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf" rel="noopener noreferrer nofollow">SICK</a>: корпус, ориентированный на понимание того, как смысл фразы складывается из отдельных слов. </p></li><li><p><a href="https://nlp.stanford.edu/projects/snli/" rel="noopener noreferrer nofollow">SNLI</a>: огромный корпус подписей к картинкам, первый крупномасштабный датасет для задачи NLI. </p></li><li><p><a href="https://russiansuperglue.com/ru/tasks/task_info/TERRa" rel="noopener noreferrer nofollow">TERRa</a>: единственный корпус, который не пришлось переводить на русский.</p></li></ul><p>Переведённые тексты я объединил в <a href="https://drive.google.com/file/d/1RpCwvDxGomGE1Yh2ugpeCyruINgGBlBJ/view?usp=sharing" rel="noopener noreferrer nofollow">общий корпус</a>. Для большинства корпусов я использовал готовую train/dev/test разбивку (хотя во многих из них test часть была скрыта), а остальные разбил сам. Для обучения двухклассовых моделей (<code>entailment/not_entailment</code>) я использовал все корпусы (1.6 миллиона обучающих примеров), а для трёхклассовой (<code>entailment/contradiction/neutral</code>) – только <a href="https://github.com/facebookresearch/anli" rel="noopener noreferrer nofollow"><u>ANLI</u></a>, <a href="https://github.com/easonnie/combine-FEVER-NSMN/blob/master/other_resources/nli_fever.md" rel="noopener noreferrer nofollow"><u>NLI-style FEVER</u></a><u>,</u> <a href="https://github.com/facebookresearch/Imppres" rel="noopener noreferrer nofollow"><u>IMPPRES</u></a>.<a href="https://github.com/sheng-z/JOCI" rel="noopener noreferrer nofollow"><u>JOCI</u></a>, <a href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener noreferrer nofollow"><u>MNLI</u></a>, <a href="https://aclanthology.org/I17-1011/" rel="noopener noreferrer nofollow"><u>MPE</u></a>, <a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf" rel="noopener noreferrer nofollow"><u>SICK</u></a>, <a href="https://nlp.stanford.edu/projects/snli/" rel="noopener noreferrer nofollow"><u>SNLI</u></a> (1.3 миллиона).</p><h2>Модели</h2><p>На собранном мною датасете я обучил три модели (доступен <a href="https://colab.research.google.com/drive/1WHU4F9yz3cYvsVi7i_Hwex7J1aNnLhBj?usp=sharing" rel="noopener noreferrer nofollow">блокнот </a>с обучением и оценкой). Модель <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway" rel="noopener noreferrer nofollow">cointegrated/rubert-base-cased-nli-threeway</a> обучалась разделять все три класса, а модели <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-twoway" rel="noopener noreferrer nofollow">cointegrated/rubert-base-cased-nli-twoway</a> и <a href="https://huggingface.co/cointegrated/rubert-tiny-bilingual-nli" rel="noopener noreferrer nofollow">cointegrated/rubert-tiny-bilingual-nli</a> – только отличать <code>entailment</code> от остальных. В моделях threeway и twoway за основу взята нейросеть <a href="https://huggingface.co/DeepPavlov/rubert-base-cased" rel="noopener noreferrer nofollow"><u>DeepPavlov/rubert-base-cased</u></a> размером 700 мб, а в модели tiny – <a href="https://huggingface.co/cointegrated/rubert-tiny" rel="noopener noreferrer nofollow"><u>cointegrated/rubert-tiny</u></a> размером 45 мб. Поэтому версия tiny получилась ожидаемо глупее своих более крупных братьев, но зато и на порядок быстрее. Кроме того, в версии tiny я в 30% случаев подменял русский текст обучающего примера на английский, поэтому она умеет работать с разными комбинациями предпосылки и гипотезы на русском и английском языках.</p><p>Собственно для NLI модели можно применять примерно так:</p><pre><code class="python">import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)
if torch.cuda.is_available():
    model.cuda()

text1 = 'Сократ - человек, а все люди смертны.'
text2 = 'Сократ никогда не умрёт.'
with torch.inference_mode():
    out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))
    proba = torch.softmax(out.logits, -1).cpu().numpy()[0]
print(proba)
# [0.00952593 0.9332064  0.05726764]
print({v: proba[k] for k, v in model.config.id2label.items()})
# {'entailment': 0.009525929, 'contradiction': 0.9332064, 'neutral': 0.05726764} </code></pre><p>Чтобы оценить качество моделей, я рассчитал ROC AUC на dev выборке каждого из доступных датасетов. Для двухклассовых моделей я считал AUC класса entailment, для трёхклассовой – AUC каждого из классов. Кроме этого, я добавил в таблицу две мультиязычные NLI модели, понимающие в том числе и русский: <a href="https://huggingface.co/vicgalle/xlm-roberta-large-xnli-anli" rel="noopener noreferrer nofollow">xlm-roberta-large-xnli-anli</a> и <a href="https://huggingface.co/facebook/bart-large-mnli" rel="noopener noreferrer nofollow">bart-large-mnli</a>. </p><div class="table"><table><tbody><tr><th data-colwidth="199" width="199"><p>model</p></th><th data-colwidth="104" width="104"><p>class</p></th><th data-colwidth="121" width="121"><p>add_one_rte</p></th><th data-colwidth="75" width="75"><p>anli_r1</p></th><th data-colwidth="73" width="73"><p>anli_r2</p></th><th data-colwidth="73" width="73"><p>anli_r3</p></th><th data-colwidth="61" width="61"><p>copa</p></th><th data-colwidth="60" width="60"><p>fever</p></th><th data-colwidth="55" width="55"><p>help</p></th><th data-colwidth="57" width="57"><p>iie</p></th><th data-colwidth="86" width="86"><p>imppres</p></th><th><p>joci</p></th><th data-colwidth="57" width="57"><p>mnli</p></th><th data-colwidth="67" width="67"><p>monli</p></th><th data-colwidth="57" width="57"><p>mpe</p></th><th data-colwidth="67" width="67"><p>scitail</p></th><th data-colwidth="57" width="57"><p>sick</p></th><th><p>snli</p></th><th data-colwidth="60" width="60"><p>terra</p></th><th data-colwidth="67" width="67"><p>total</p></th></tr><tr><td data-colwidth="199" width="199"><p>n_observations</p></td><td data-colwidth="104" width="104"><p></p></td><td data-colwidth="121" width="121"><p>387</p></td><td data-colwidth="75" width="75"><p>1000</p></td><td data-colwidth="73" width="73"><p>1000</p></td><td data-colwidth="73" width="73"><p>1200</p></td><td data-colwidth="61" width="61"><p>200</p></td><td data-colwidth="60" width="60"><p>20474</p></td><td data-colwidth="55" width="55"><p>3355</p></td><td data-colwidth="57" width="57"><p>31232</p></td><td data-colwidth="86" width="86"><p>7661</p></td><td><p>939</p></td><td data-colwidth="57" width="57"><p>19647</p></td><td data-colwidth="67" width="67"><p>269</p></td><td data-colwidth="57" width="57"><p>1000</p></td><td data-colwidth="67" width="67"><p>2126</p></td><td data-colwidth="57" width="57"><p>500</p></td><td><p>9831</p></td><td data-colwidth="60" width="60"><p>307</p></td><td data-colwidth="67" width="67"><p>101128</p></td></tr><tr><td data-colwidth="199" width="199"><p>tiny</p></td><td data-colwidth="104" width="104"><p>entailment</p></td><td data-colwidth="121" width="121"><p>0.77</p></td><td data-colwidth="75" width="75"><p>0.59</p></td><td data-colwidth="73" width="73"><p>0.52</p></td><td data-colwidth="73" width="73"><p>0.53</p></td><td data-colwidth="61" width="61"><p>0.53</p></td><td data-colwidth="60" width="60"><p>0.90</p></td><td data-colwidth="55" width="55"><p>0.81</p></td><td data-colwidth="57" width="57"><p>0.78</p></td><td data-colwidth="86" width="86"><p>0.93</p></td><td><p>0.81</p></td><td data-colwidth="57" width="57"><p>0.82</p></td><td data-colwidth="67" width="67"><p>0.91</p></td><td data-colwidth="57" width="57"><p>0.81</p></td><td data-colwidth="67" width="67"><p>0.78</p></td><td data-colwidth="57" width="57"><p>0.93</p></td><td><p>0.95</p></td><td data-colwidth="60" width="60"><p>0.67</p></td><td data-colwidth="67" width="67"><p>0.77</p></td></tr><tr><td data-colwidth="199" width="199"><p>twoway</p></td><td data-colwidth="104" width="104"><p>entailment</p></td><td data-colwidth="121" width="121"><p>0.89</p></td><td data-colwidth="75" width="75"><p>0.73</p></td><td data-colwidth="73" width="73"><p>0.61</p></td><td data-colwidth="73" width="73"><p>0.62</p></td><td data-colwidth="61" width="61"><p>0.58</p></td><td data-colwidth="60" width="60"><p>0.96</p></td><td data-colwidth="55" width="55"><p>0.92</p></td><td data-colwidth="57" width="57"><p>0.87</p></td><td data-colwidth="86" width="86"><p>0.99</p></td><td><p>0.90</p></td><td data-colwidth="57" width="57"><p>0.90</p></td><td data-colwidth="67" width="67"><p>0.99</p></td><td data-colwidth="57" width="57"><p>0.91</p></td><td data-colwidth="67" width="67"><p>0.96</p></td><td data-colwidth="57" width="57"><p>0.97</p></td><td><p>0.97</p></td><td data-colwidth="60" width="60"><p>0.87</p></td><td data-colwidth="67" width="67"><p>0.86</p></td></tr><tr><td data-colwidth="199" width="199"><p>threeway</p></td><td data-colwidth="104" width="104"><p>entailment</p></td><td data-colwidth="121" width="121"><p>0.91</p></td><td data-colwidth="75" width="75"><p>0.75</p></td><td data-colwidth="73" width="73"><p>0.61</p></td><td data-colwidth="73" width="73"><p>0.61</p></td><td data-colwidth="61" width="61"><p>0.57</p></td><td data-colwidth="60" width="60"><p>0.96</p></td><td data-colwidth="55" width="55"><p>0.56</p></td><td data-colwidth="57" width="57"><p>0.61</p></td><td data-colwidth="86" width="86"><p>0.99</p></td><td><p>0.90</p></td><td data-colwidth="57" width="57"><p>0.91</p></td><td data-colwidth="67" width="67"><p>0.67</p></td><td data-colwidth="57" width="57"><p>0.92</p></td><td data-colwidth="67" width="67"><p>0.84</p></td><td data-colwidth="57" width="57"><p>0.98</p></td><td><p>0.98</p></td><td data-colwidth="60" width="60"><p>0.90</p></td><td data-colwidth="67" width="67"><p>0.80</p></td></tr><tr><td data-colwidth="199" width="199"><p>xlm-roberta-large-xnli-anli</p></td><td data-colwidth="104" width="104"><p>entailment</p></td><td data-colwidth="121" width="121"><p>0.88</p></td><td data-colwidth="75" width="75"><p>0.79</p></td><td data-colwidth="73" width="73"><p>0.63</p></td><td data-colwidth="73" width="73"><p>0.66</p></td><td data-colwidth="61" width="61"><p>0.57</p></td><td data-colwidth="60" width="60"><p>0.93</p></td><td data-colwidth="55" width="55"><p>0.56</p></td><td data-colwidth="57" width="57"><p>0.62</p></td><td data-colwidth="86" width="86"><p>0.77</p></td><td><p>0.80</p></td><td data-colwidth="57" width="57"><p>0.90</p></td><td data-colwidth="67" width="67"><p>0.70</p></td><td data-colwidth="57" width="57"><p>0.83</p></td><td data-colwidth="67" width="67"><p>0.84</p></td><td data-colwidth="57" width="57"><p>0.91</p></td><td><p>0.93</p></td><td data-colwidth="60" width="60"><p>0.93</p></td><td data-colwidth="67" width="67"><p>0.78</p></td></tr><tr><td data-colwidth="199" width="199"><p>bart-large-mnli</p></td><td data-colwidth="104" width="104"><p>entailment</p></td><td data-colwidth="121" width="121"><p>0.51</p></td><td data-colwidth="75" width="75"><p>0.41</p></td><td data-colwidth="73" width="73"><p>0.43</p></td><td data-colwidth="73" width="73"><p>0.47</p></td><td data-colwidth="61" width="61"><p>0.50</p></td><td data-colwidth="60" width="60"><p>0.74</p></td><td data-colwidth="55" width="55"><p>0.55</p></td><td data-colwidth="57" width="57"><p>0.57</p></td><td data-colwidth="86" width="86"><p>0.60</p></td><td><p>0.63</p></td><td data-colwidth="57" width="57"><p>0.70</p></td><td data-colwidth="67" width="67"><p>0.52</p></td><td data-colwidth="57" width="57"><p>0.56</p></td><td data-colwidth="67" width="67"><p>0.68</p></td><td data-colwidth="57" width="57"><p>0.67</p></td><td><p>0.72</p></td><td data-colwidth="60" width="60"><p>0.64</p></td><td data-colwidth="67" width="67"><p>0.58</p></td></tr><tr><td data-colwidth="199" width="199"><p>threeway</p></td><td data-colwidth="104" width="104"><p>contradiction</p></td><td data-colwidth="121" width="121"><p></p></td><td data-colwidth="75" width="75"><p>0.71</p></td><td data-colwidth="73" width="73"><p>0.64</p></td><td data-colwidth="73" width="73"><p>0.61</p></td><td data-colwidth="61" width="61"><p></p></td><td data-colwidth="60" width="60"><p>0.97</p></td><td data-colwidth="55" width="55"><p></p></td><td data-colwidth="57" width="57"><p></p></td><td data-colwidth="86" width="86"><p>1.00</p></td><td><p>0.77</p></td><td data-colwidth="57" width="57"><p>0.92</p></td><td data-colwidth="67" width="67"><p></p></td><td data-colwidth="57" width="57"><p>0.89</p></td><td data-colwidth="67" width="67"><p></p></td><td data-colwidth="57" width="57"><p>0.99</p></td><td><p>0.98</p></td><td data-colwidth="60" width="60"><p></p></td><td data-colwidth="67" width="67"><p>0.85</p></td></tr><tr><td data-colwidth="199" width="199"><p>threeway</p></td><td data-colwidth="104" width="104"><p>neutral</p></td><td data-colwidth="121" width="121"><p></p></td><td data-colwidth="75" width="75"><p>0.79</p></td><td data-colwidth="73" width="73"><p>0.70</p></td><td data-colwidth="73" width="73"><p>0.62</p></td><td data-colwidth="61" width="61"><p></p></td><td data-colwidth="60" width="60"><p>0.91</p></td><td data-colwidth="55" width="55"><p></p></td><td data-colwidth="57" width="57"><p></p></td><td data-colwidth="86" width="86"><p>0.99</p></td><td><p>0.68</p></td><td data-colwidth="57" width="57"><p>0.86</p></td><td data-colwidth="67" width="67"><p></p></td><td data-colwidth="57" width="57"><p>0.79</p></td><td data-colwidth="67" width="67"><p></p></td><td data-colwidth="57" width="57"><p>0.96</p></td><td><p>0.96</p></td><td data-colwidth="60" width="60"><p></p></td><td data-colwidth="67" width="67"><p>0.83 </p></td></tr></tbody></table></div><p>Перформанс модели XLM весьма неплох, но надо сделать скидку на то, что это большая и довольно медленная модель класса large. На видеокарте, с которой я работал, XLM и BART обрабатывали за секунду чуть меньше 2 батчей по 32 пары текстов, RuBERT-base –  7 батчей в секунду, а RuBERT-tiny – аж 36 батчей в секунду.</p><p>В целом, для задач zero-shot classification и распознавания entailment я рекомендую выбирать между умной и медленной <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-twoway" rel="noopener noreferrer nofollow">cointegrated/rubert-base-cased-nli-twoway</a> и глупой и быстрой <a href="https://huggingface.co/cointegrated/rubert-tiny-bilingual-nli" rel="noopener noreferrer nofollow">cointegrated/rubert-tiny-bilingual-nli</a>. Если же вам важно различать разницу между классами neutral и contradiction, то берите модель <a href="https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway" rel="noopener noreferrer nofollow">cointegrated/rubert-base-cased-nli-threeway</a>, которая тоже работает весьма неплохо.</p><p>Я не уверен, что мне удалось создать самые лучшие модели NLI для русского языка; наверняка в закромах Сбера или Яндекса есть варианты помощнее. Но зато мои модели выложены в открытый доступ, а значит, вы можете использовать их для задач NLI, классификации, и детекции парафраз уже сейчас. </p><p>А если вы уже успели попробовать применить русские модели для NLI, то пишите в комменты: на каких данных применяли, какой результат получился, какое общее впечатление? И не забывайте лайкать этот пост 🙃. <br/><br/>Мир вам, и да пребудет с вами сила умозаключений!</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnli%5D" class="tm-tags-list__link">nli</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnlu%5D" class="tm-tags-list__link">nlu</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnatural%20language%20inference%5D" class="tm-tags-list__link">natural language inference</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnatural%20language%20understanding%5D" class="tm-tags-list__link">natural language understanding</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnlp%5D" class="tm-tags-list__link">nlp</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bnatural%20language%20processing%5D" class="tm-tags-list__link">natural language processing</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0%20%D0%B5%D1%81%D1%82%D0%B5%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE%20%D1%8F%D0%B7%D1%8B%D0%BA%D0%B0%5D" class="tm-tags-list__link">обработка естественного языка</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bbert%5D" class="tm-tags-list__link">bert</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btransformers%5D" class="tm-tags-list__link">transformers</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bzero-shot%20classification%5D" class="tm-tags-list__link">zero-shot classification</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/python/" class="tm-hubs-list__link">
    Python
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/sw/" class="tm-hubs-list__link">
    Семантика
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/programming/" class="tm-hubs-list__link">
    Программирование
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/natural_language_processing/" class="tm-hubs-list__link">
    Natural Language Processing
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 24: ↑24 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 24: ↑24 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+24</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">5.9K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    78
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/cointegrated/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/0c9/340/334/0c934033455e38414b615e309d337a3d.jpg" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 123 голоса " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    103
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">40</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Давид Дале</span> <a href="/ru/users/cointegrated/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @cointegrated
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Разработчик / Аналитик / Data Scientist / NLPшник</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <button type="submit" class="tm-user-card__button btn btn_transparent btn_small">
      Задонатить
    </button> <!----> <!----></div></div> <div class="tm-article-author__user-contacts"><a href="https://daviddale.ru" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a><a href="https://facebook.com/dale.david.fluteman" rel="noopener" target="_blank" class="tm-article-author__contact">
      Facebook
    </a><a href="https://vk.com/dale.david" rel="noopener" target="_blank" class="tm-article-author__contact">
      ВКонтакте
    </a><a href="https://github.com/avidale/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Github
    </a><a href="https://medium.com/@cointegrated" rel="noopener" target="_blank" class="tm-article-author__contact">
      Medium
    </a></div></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/582620/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 3 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/582620/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/582620/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"582620":{"id":"582620","timePublished":"2021-10-10T12:35:35+00:00","isCorporative":false,"lang":"ru","titleHtml":"Нейросети для Natural Language Inference: логические умозаключения на русском языке","leadData":{"textHtml":"\u003Cp\u003ENLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A. Эта задача сложная, потому что она требует хорошо понимать смысл текстов. Эта задача полезная, потому что \"понимательную\" способность модели можно эксплуатировать для прикладных задач типа классификации текстов. Иногда такая классификация неплохо работает даже без обучающей выборки! \u003C\u002Fp\u003E\u003Cp\u003EДо сих пор в открытом доступе не было нейросетей, специализированных на задаче NLI для русского языка, но теперь я обучил целых три: \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-tiny-bilingual-nli\" rel=\"noopener noreferrer nofollow\"\u003Etiny\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-twoway\" rel=\"noopener noreferrer nofollow\"\u003Etwoway\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-threeway\" rel=\"noopener noreferrer nofollow\"\u003Ethreeway\u003C\u002Fa\u003E. Зачем эти модели нужны, как они обучались, и в чём между ними разница – под катом.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e1\u002F4e8\u002F5ff\u002F3e14e85ffdb43c91e3f7de0875586f4a.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e1\u002F4e8\u002F5ff\u002F3e14e85ffdb43c91e3f7de0875586f4a.png","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":103,"votesCount":123},"rating":40,"relatedData":null,"contacts":[{"title":"Сайт","url":"https:\u002F\u002Fdaviddale.ru","value":"https:\u002F\u002Fdaviddale.ru"},{"title":"Facebook","url":"https:\u002F\u002Ffacebook.com\u002Fdale.david.fluteman","value":"dale.david.fluteman"},{"title":"ВКонтакте","url":"https:\u002F\u002Fvk.com\u002Fdale.david","value":"dale.david"},{"title":"Github","url":"https:\u002F\u002Fgithub.com\u002Favidale\u002F","value":"avidale"},{"title":"Medium","url":"https:\u002F\u002Fmedium.com\u002F@cointegrated","value":"cointegrated"}],"authorContacts":[{"title":"Сайт","url":"https:\u002F\u002Fdaviddale.ru","value":"https:\u002F\u002Fdaviddale.ru"},{"title":"Facebook","url":"https:\u002F\u002Ffacebook.com\u002Fdale.david.fluteman","value":"dale.david.fluteman"},{"title":"ВКонтакте","url":"https:\u002F\u002Fvk.com\u002Fdale.david","value":"dale.david"},{"title":"Github","url":"https:\u002F\u002Fgithub.com\u002Favidale\u002F","value":"avidale"},{"title":"Medium","url":"https:\u002F\u002Fmedium.com\u002F@cointegrated","value":"cointegrated"}],"paymentDetails":{"paymentYandexMoney":"410011860612306","paymentPayPalMe":null,"paymentWebmoney":"212945711688"},"id":"1383398","alias":"cointegrated","fullname":"Давид Дале","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F0c9\u002F340\u002F334\u002F0c934033455e38414b615e309d337a3d.jpg","speciality":"Разработчик \u002F Аналитик \u002F Data Scientist \u002F NLPшник"},"statistics":{"commentsCount":3,"favoritesCount":78,"readingCount":5921,"score":24,"votesCount":24},"hubs":[{"relatedData":null,"id":"340","alias":"python","type":"collective","title":"Python","titleHtml":"Python","isProfiled":true},{"relatedData":null,"id":"345","alias":"sw","type":"collective","title":"Семантика","titleHtml":"Семантика","isProfiled":true},{"relatedData":null,"id":"359","alias":"programming","type":"collective","title":"Программирование","titleHtml":"Программирование","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"22125","alias":"natural_language_processing","type":"collective","title":"Natural Language Processing","titleHtml":"Natural Language Processing","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003ENLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A. Эта задача сложная, потому что она требует хорошо понимать смысл текстов. Эта задача полезная, потому что \"понимательную\" способность модели можно эксплуатировать для прикладных задач типа классификации текстов. Иногда такая классификация неплохо работает даже без обучающей выборки! \u003C\u002Fp\u003E\u003Cp\u003EДо сих пор в открытом доступе не было нейросетей, специализированных на задаче NLI для русского языка, но теперь я обучил целых три: \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-tiny-bilingual-nli\" rel=\"noopener noreferrer nofollow\"\u003Etiny\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-twoway\" rel=\"noopener noreferrer nofollow\"\u003Etwoway\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-threeway\" rel=\"noopener noreferrer nofollow\"\u003Ethreeway\u003C\u002Fa\u003E. Зачем эти модели нужны, как они обучались, и в чём между ними разница – под катом.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Модели NLI можно применять и для логического вывода, и для классификации текстов\" title=\"Модели NLI можно применять и для логического вывода, и для классификации текстов\" height=\"440\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fb2a\u002Feb2\u002Fcea\u002Fb2aeb2ceaaa7d99ad953521f3e0a516a.png\" data-width=\"780\"\u002F\u003E\u003Cfigcaption\u003EМодели NLI можно применять и для логического вывода, и для классификации текстов\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EЗадача NLI\u003C\u002Fh2\u003E\u003Cp\u003EНа русский язык понятие \u003Cem\u003Enatural language inference\u003C\u002Fem\u003E можно перевести как \u003Cem\u003Eлогический вывод (\u003C\u002Fem\u003Eили\u003Cem\u003E умозаключения) на естественном языке\u003C\u002Fem\u003E. Обычно эта задача формулируется как классификация пары текстов на два класса (\u003Ccode\u003Eentailment\u002Fnot_entailment\u003C\u002Fcode\u003E) или на три класса (\u003Ccode\u003Eentailment\u002Fcontradiction\u002Fneutral\u003C\u002Fcode\u003E). Выглядят классы примерно так:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eиз \"Петя – хакер\" \u003Cem\u003Eследует\u003C\u002Fem\u003E, что  \"Петя – айтишник\", ибо нам известно, что все хакеры – айтишники. Это \u003Cem\u003Eentailment\u003C\u002Fem\u003E.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eиз \"Петя – хакер\" \u003Cem\u003Eне следует\u003C\u002Fem\u003E \"Петя – кот\", более того, второе утверждение \u003Cem\u003Eпротиворечит\u003C\u002Fem\u003E первому, потому что хакерами вроде как бывают только люди, но не коты. Это \u003Cem\u003Econtradiction.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eиз \"Петя – козёл\" \u003Cem\u003Eне следует\u003C\u002Fem\u003E, что \"Вася тоже хакер\", но и противоречия между этими утверждениями нет. Это отношение зовётся \u003Cem\u003Eneutral\u003C\u002Fem\u003E.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EВ задаче NLI левый текст обычно называется \u003Cem\u003Eпредпосылкой\u003C\u002Fem\u003E (premise), а правый – \u003Cem\u003Eгипотезой\u003C\u002Fem\u003E (hypothesis), и я буду придерживаться такой же терминологии.\u003C\u002Fp\u003E\u003Cp\u003EЧтобы правильно делать подобные суждения, модель должна уметь очень много. Она должна знать слова (\"хакер\", \"кот\") и связи между ними (\"хакеры – айтишники\", \"айтишники – люди\", \"коты – не люди\"). Должна уметь в логические операции (отрицания, и\u002Fили, если\u002Fто, каждый\u002Fнекоторый и т.п.). Должна понимать природу сущностей (\"Швеция – это страна\").  Должна понимать, как связаны друг с другом отношения между сущностями (если существует \"Король Швеции\", то \"Швеция – это королевство\"). Более подробно про эти умения можно почитать на сайте \u003Ca href=\"https:\u002F\u002Frussiansuperglue.com\u002Fru\u002Fdatasets\u002F\" rel=\"noopener noreferrer nofollow\"\u003ERussianSuperGLUE\u003C\u002Fa\u003E, но уже и так понятно, что модель должна очень хорошо понимать смысл текстов. \u003C\u002Fp\u003E\u003Cp\u003EЗа последние несколько лет появилось много нейросетей типа \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1810.04805\" rel=\"noopener noreferrer nofollow\"\u003EBERT\u003C\u002Fa\u003E, предобученных так, что базовое понимание языка у них уже неплохое, в том числе и \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F562064\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eряд моделей для русского языка\u003C\u002Fa\u003E. При обучении двух из них (\u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002FDeepPavlov\u002Frubert-base-cased-sentence\" rel=\"noopener noreferrer nofollow\"\u003Erubert-base-cased-sentence\u003C\u002Fa\u003E от\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fmipt\u002Fblog\u002F472890\u002F\" rel=\"noopener noreferrer nofollow\"\u003E DeepPavlov\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fsberbank-ai\u002Fsbert_large_nlu_ru\" rel=\"noopener noreferrer nofollow\"\u003Esbert_large_nlu_ru\u003C\u002Fa\u003E от \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsberdevices\u002Fblog\u002F527576\u002F\" rel=\"noopener noreferrer nofollow\"\u003ESberDevices\u003C\u002Fa\u003E) даже использовались датасеты NLI, переведённые на русский язык. Но обе они устроены так, что сначала обрабатывают каждый текст по отдельности, а потом сравнивают между собой уже абстрактные представления (точнее, sentence embeddings) этих текстов. Если же модель читает оба текста одновременно, при необходимости \"подглядывая\" механизмом внимания из одного текста в другой (это называется \u003Cem\u003Ecross-encoder\u003C\u002Fem\u003E), она имеет больше шансов понять, как связаны друг с другом смыслы этих текстов. Именно такие модели я и обучил. \u003C\u002Fp\u003E\u003Ch2\u003EПрименение\u003C\u002Fh2\u003E\u003Cp\u003EЗадача NLI важна для компьютерных лингвистов, ибо она позволяет детально рассмотреть, какие языковые явления данная модель понимает хорошо, а на каких – \"плывёт\"; по этому принципу устроены диагностические датасеты \u003Ca href=\"https:\u002F\u002Fsuper.gluebenchmark.com\u002Fdiagnostics\" rel=\"noopener noreferrer nofollow\"\u003ESuperGLUE \u003C\u002Fa\u003Eи \u003Ca href=\"https:\u002F\u002Frussiansuperglue.com\u002Fru\u002Fdatasets\u002F\" rel=\"noopener noreferrer nofollow\"\u003ERussianSuperGLUE\u003C\u002Fa\u003E. Кроме этого, модели NLI обладают прикладной ценностью по нескольким причинам.\u003C\u002Fp\u003E\u003Cp\u003EВо-первых, NLI можно использовать для контроля качества генеративных моделей. Есть масса задач, где на основе текста X нужно сгенерировать близкий к нему по смыслу текст Y: суммаризация, упрощение текстов, перефразирование, перенос стиля на текстах, текстовые вопросно-ответные системы, и даже машинный перевод. Современные seq2seq нейросети типа T5 (которая в этом году \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F581932\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eпоявилась и для русского языка\u003C\u002Fa\u003E) в целом неплохо справляются с такими задачами, но время от времени лажают, упуская какую-то важную информацию из Х, или, наоборот, дописывая в текст Y что-то нафантазированное \"от себя\". С помощью модели NLI можно проверять, что из X следует Y (то есть в новом тексте нету \"отсебятины\", придуманной моделью), и что из Y следует X (т.е. вся информация, присутствовавшая в исходном тексте, в новом также отражена).  \u003C\u002Fp\u003E\u003Cp\u003EВо-вторых, с помощью моделей NLI можно находить нетривиальные парафразы и в целом определять смысловую близость текстов. Для русского языка уже существует \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F564916\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eряд моделей и датасетов по перефразированию\u003C\u002Fa\u003E, но кажется, что можно сделать ещё больше и лучше. В статье \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2106.07691\" rel=\"noopener noreferrer nofollow\"\u003EImproving Paraphrase Detection with the Adversarial Paraphrasing Task \u003C\u002Fa\u003Eпредложили считать парафразами такую пару предложений, в которой каждое логически следует из другого – и это весьма логично. Поэтому модели NLI можно использовать и для сбора обучающего корпуса парафраз (и не-парафраз, если стоит задача их детекции), и для фильтрации моделей, генерирующих парафразы.\u003C\u002Fp\u003E\u003Cp\u003EВ-третьих, NLI можно переиспользовать для задачи классификации текстов с небольшим числом обучающих примеров или даже \u003Cem\u003Eвообще без обучающей выборки\u003C\u002Fem\u003E. В статье \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2104.14690.pdf\" rel=\"noopener noreferrer nofollow\"\u003EEntailment as Few-Shot Learner\u003C\u002Fa\u003E модель, обученную на задаче NLI, дообучали буквально на 8 примерах на новые задачи классификации текстов, и в результате модель справлялась с ними весьма неплохо; в других работах этот подход демонстрировали вообще без дообучения (хотя с этим и \u003Ca href=\"https:\u002F\u002Faclanthology.org\u002F2021.acl-short.99\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eобнаружены проблемы\u003C\u002Fa\u003E). Работает это так: для текста, который надо классифицировать, готовится несколько выводов соответствующих разным, и выбирается самый правдоподобный из них. Например, так можно решить задачу анализа тональности текста:\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003E# !pip install transformers sentencepiece\nfrom transformers import pipeline\np = pipeline(\n  task='zero-shot-classification', \n  model='cointegrated\u002Frubert-base-cased-nli-twoway'\n)\np(\n  sequences=\"Сервис приличный, кормили вкусно\", \n  candidate_labels=\"Мне понравилось, Мне не понравилось\", \n  hypothesis_template=\"{}.\"\n)\n# {'labels': ['Мне понравилось', 'Мне не понравилось'],\n#  'scores': [0.9580550789833069, 0.0419449619948864],\n#  'sequence': 'Сервис приличный, кормили вкусно'}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EЗдесь модель решила, что из текста отзыва вывод \"\u003Cem\u003EМне понравилось.\u003C\u002Fem\u003E\" следует с двадцатикратно большей вероятностью, чем вывод \"\u003Cem\u003EМне не понравилось\u003C\u002Fem\u003E\", и таким образом классифицировала текст как положительный. \u003C\u002Fp\u003E\u003Cp\u003EКонкретно в этой имплементации (\u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Ftransformers\u002Fmain_classes\u002Fpipelines.html\" rel=\"noopener noreferrer nofollow\"\u003Etransformers.pipelines\u003C\u002Fa\u003E) метки классов можно подавать в виде одного полотна текста (через запятую) или как список строк, а аргумент \u003Ccode\u003Ehypothesis_template\u003C\u002Fcode\u003E показывает, в форме какого шаблона эти метки должны подаваться в модель. Классов может быть сколько угодно, например, семь разных тематик, из которых модель правильно выбирает \"путешествия\":\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Ep(\n  sequences=\"Я хочу поехать в Дагестан\", \n  candidate_labels=\"спорт,путешествия,музыка,кино,книги,наука,политика\", \n  hypothesis_template=\"Мои интересы - {}.\"\n)\n# {'sequence': 'Я хочу поехать в Дагестан', \n   'labels': ['путешествия', 'спорт', 'политика', 'наука', 'кино', 'музыка', 'книги'], \n   'scores': [0.948, 0.019, 0.007, 0.006, 0.006, 0.005, 0.005]}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EЛично у меня zero-shot классификация на базе NLI не особо взлетела. Например, на задаче классификации 68 интентов zero-shot классификация на основе NLI с написанными вручную 68 гипотезами для каждого класса отработала хуже, чем метод ближайших соседей на эмбеддингах \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002FLaBSE-en-ru\" rel=\"noopener noreferrer nofollow\"\u003ELaBSE \u003C\u002Fa\u003Eс всего лишь тремя примерами на каждый класс. На задачах классификации тональности и токсичности подход Labse+KNN тоже сравнялся по качеству с NLI+zero-shot на нескольких десятках размеченных примеров.  \u003C\u002Fp\u003E\u003Cp\u003EПоэтому кажется, что zero-shot классификацию стоит применять только в случаях, когда нет возможности собрать даже небольшую обучающую выборку, и что её качество будет сильно зависеть от выбранных названий классов и от того, какой шаблон используется для гипотез. Поэтому, если есть возможность дообучить свою модель на задачу классификации, лучше дообучайте. Если возможности нет, но есть даже небольшое число размеченных примеров, используйте KNN. А к zero-shot прибегайте только в крайних случаях.\u003C\u002Fp\u003E\u003Cp\u003EВпрочем, несмотря на свою относительную бесполезность, zero-shot классификация – это всё равно очень прикольно.\u003C\u002Fp\u003E\u003Ch2\u003EДатасеты\u003C\u002Fh2\u003E\u003Cp\u003EНасколько мне известно, сегодня существует два датасета, посвящённых задаче NLI на русском языке: \u003Ca href=\"https:\u002F\u002Frussiansuperglue.com\u002Fru\u002Ftasks\u002Ftask_info\u002FTERRa\" rel=\"noopener noreferrer nofollow\"\u003ETERRa\u003C\u002Fa\u003E, собранная из русскоязычных публикаций и вручную размеченная, и \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002FXNLI\" rel=\"noopener noreferrer nofollow\"\u003EXNLI\u003C\u002Fa\u003E, где английские размеченные тексты были переведены на русский и ряд других языков. Оба эти датасета не очень большие, зато на английском языке существуют буквально миллионы размеченных пар текстов. Поэтому в качестве обучающей выборки я использовал в основном корпусы, машинно переведённые с английского языка. Большинство из них было взято из репозитория \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffelipessalvatore\u002FNLI_datasets\" rel=\"noopener noreferrer nofollow\"\u003EFelipe Salvatore\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fcs.brown.edu\u002Fpeople\u002Fepavlick\u002Fpapers\u002Fans.pdf\" rel=\"noopener noreferrer nofollow\"\u003EAdd-one RTE\u003C\u002Fa\u003E: корпус, в котором в текст добавляется одно слово, которое может поменять или не поменять его смысл. Например, \"вселенная\" и \"вся вселенная\" идентичны по смыслу, а \"вселенная\" и \"воображаемая вселенная\" – разные. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002Fanli\" rel=\"noopener noreferrer nofollow\"\u003EANLI\u003C\u002Fa\u003E: три корпуса, собранные вручную таким образом, чтобы с примерами из них плохо справлялись уже имеющиеся продвинутые NLI модели.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fpeople.ict.usc.edu\u002F~gordon\u002Fcopa.html\" rel=\"noopener noreferrer nofollow\"\u003ECoPA\u003C\u002Fa\u003E: корпус, в котором модель должна догадываться о возможных причинах и следствиях событий.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Feasonnie\u002Fcombine-FEVER-NSMN\u002Fblob\u002Fmaster\u002Fother_resources\u002Fnli_fever.md\" rel=\"noopener noreferrer nofollow\"\u003ENLI-style FEVER\u003C\u002Fa\u003E: корпус, проверяющий, есть ли в данном источнике подтверждение данного факта.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fverypluming\u002FHELP\" rel=\"noopener noreferrer nofollow\"\u003EHELP\u003C\u002Fa\u003E: автоматически созданный корпус, требующий работы со значениями слов и логикой.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002FImppres\" rel=\"noopener noreferrer nofollow\"\u003EIMPPRES\u003C\u002Fa\u003E: автоматически сгенерированный датасет, анализирующий допущения, неявно подразумеваемые в тексте.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Faclanthology.org\u002FI17-1100\" rel=\"noopener noreferrer nofollow\"\u003EIIE\u003C\u002Fa\u003E: корпус из статьи\"Inference is everything\", представляющий в форме NLI другие лингвистические задачи: определение семантических ролей, понимание контекстных парафраз, и расшифровка местоимений.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsheng-z\u002FJOCI\" rel=\"noopener noreferrer nofollow\"\u003EJOCI\u003C\u002Fa\u003E: корпус, фокусирующийся на применении \"здравого смысла\" (common sense).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fcims.nyu.edu\u002F~sbowman\u002Fmultinli\u002F\" rel=\"noopener noreferrer nofollow\"\u003EMNLI\u003C\u002Fa\u003E: большой многожанровый корпус, собранный из разнообразных устных и письменных источников.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fatticusg\u002FMoNLI\" rel=\"noopener noreferrer nofollow\"\u003EMoNLI\u003C\u002Fa\u003E: корпус, фокусирующийся на отношении \"частное\u002Fобщее\". \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Faclanthology.org\u002FI17-1011\u002F\" rel=\"noopener noreferrer nofollow\"\u003EMPE\u003C\u002Fa\u003E: корпус, где вывод нужно сделать на основе не одной, а множества предпосылок.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fallenai.org\u002Fdata\u002Fscitail\" rel=\"noopener noreferrer nofollow\"\u003ESCITAIL\u003C\u002Fa\u003E: корпус вопросов на научную тематику, собранный из экзаменов и интернета.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"http:\u002F\u002Fwww.lrec-conf.org\u002Fproceedings\u002Flrec2014\u002Fpdf\u002F363_Paper.pdf\" rel=\"noopener noreferrer nofollow\"\u003ESICK\u003C\u002Fa\u003E: корпус, ориентированный на понимание того, как смысл фразы складывается из отдельных слов. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fnlp.stanford.edu\u002Fprojects\u002Fsnli\u002F\" rel=\"noopener noreferrer nofollow\"\u003ESNLI\u003C\u002Fa\u003E: огромный корпус подписей к картинкам, первый крупномасштабный датасет для задачи NLI. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Frussiansuperglue.com\u002Fru\u002Ftasks\u002Ftask_info\u002FTERRa\" rel=\"noopener noreferrer nofollow\"\u003ETERRa\u003C\u002Fa\u003E: единственный корпус, который не пришлось переводить на русский.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EПереведённые тексты я объединил в \u003Ca href=\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1RpCwvDxGomGE1Yh2ugpeCyruINgGBlBJ\u002Fview?usp=sharing\" rel=\"noopener noreferrer nofollow\"\u003Eобщий корпус\u003C\u002Fa\u003E. Для большинства корпусов я использовал готовую train\u002Fdev\u002Ftest разбивку (хотя во многих из них test часть была скрыта), а остальные разбил сам. Для обучения двухклассовых моделей (\u003Ccode\u003Eentailment\u002Fnot_entailment\u003C\u002Fcode\u003E) я использовал все корпусы (1.6 миллиона обучающих примеров), а для трёхклассовой (\u003Ccode\u003Eentailment\u002Fcontradiction\u002Fneutral\u003C\u002Fcode\u003E) – только \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002Fanli\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EANLI\u003C\u002Fu\u003E\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Feasonnie\u002Fcombine-FEVER-NSMN\u002Fblob\u002Fmaster\u002Fother_resources\u002Fnli_fever.md\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003ENLI-style FEVER\u003C\u002Fu\u003E\u003C\u002Fa\u003E\u003Cu\u003E,\u003C\u002Fu\u003E \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002FImppres\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EIMPPRES\u003C\u002Fu\u003E\u003C\u002Fa\u003E.\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsheng-z\u002FJOCI\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EJOCI\u003C\u002Fu\u003E\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fcims.nyu.edu\u002F~sbowman\u002Fmultinli\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EMNLI\u003C\u002Fu\u003E\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Faclanthology.org\u002FI17-1011\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EMPE\u003C\u002Fu\u003E\u003C\u002Fa\u003E, \u003Ca href=\"http:\u002F\u002Fwww.lrec-conf.org\u002Fproceedings\u002Flrec2014\u002Fpdf\u002F363_Paper.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003ESICK\u003C\u002Fu\u003E\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fnlp.stanford.edu\u002Fprojects\u002Fsnli\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003ESNLI\u003C\u002Fu\u003E\u003C\u002Fa\u003E (1.3 миллиона).\u003C\u002Fp\u003E\u003Ch2\u003EМодели\u003C\u002Fh2\u003E\u003Cp\u003EНа собранном мною датасете я обучил три модели (доступен \u003Ca href=\"https:\u002F\u002Fcolab.research.google.com\u002Fdrive\u002F1WHU4F9yz3cYvsVi7i_Hwex7J1aNnLhBj?usp=sharing\" rel=\"noopener noreferrer nofollow\"\u003Eблокнот \u003C\u002Fa\u003Eс обучением и оценкой). Модель \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-threeway\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-base-cased-nli-threeway\u003C\u002Fa\u003E обучалась разделять все три класса, а модели \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-twoway\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-base-cased-nli-twoway\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-tiny-bilingual-nli\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-tiny-bilingual-nli\u003C\u002Fa\u003E – только отличать \u003Ccode\u003Eentailment\u003C\u002Fcode\u003E от остальных. В моделях threeway и twoway за основу взята нейросеть \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002FDeepPavlov\u002Frubert-base-cased\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003EDeepPavlov\u002Frubert-base-cased\u003C\u002Fu\u003E\u003C\u002Fa\u003E размером 700 мб, а в модели tiny – \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-tiny\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ecointegrated\u002Frubert-tiny\u003C\u002Fu\u003E\u003C\u002Fa\u003E размером 45 мб. Поэтому версия tiny получилась ожидаемо глупее своих более крупных братьев, но зато и на порядок быстрее. Кроме того, в версии tiny я в 30% случаев подменял русский текст обучающего примера на английский, поэтому она умеет работать с разными комбинациями предпосылки и гипотезы на русском и английском языках.\u003C\u002Fp\u003E\u003Cp\u003EСобственно для NLI модели можно применять примерно так:\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Eimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_checkpoint = 'cointegrated\u002Frubert-base-cased-nli-threeway'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\nif torch.cuda.is_available():\n    model.cuda()\n\ntext1 = 'Сократ - человек, а все люди смертны.'\ntext2 = 'Сократ никогда не умрёт.'\nwith torch.inference_mode():\n    out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n    proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\nprint(proba)\n# [0.00952593 0.9332064  0.05726764]\nprint({v: proba[k] for k, v in model.config.id2label.items()})\n# {'entailment': 0.009525929, 'contradiction': 0.9332064, 'neutral': 0.05726764} \u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EЧтобы оценить качество моделей, я рассчитал ROC AUC на dev выборке каждого из доступных датасетов. Для двухклассовых моделей я считал AUC класса entailment, для трёхклассовой – AUC каждого из классов. Кроме этого, я добавил в таблицу две мультиязычные NLI модели, понимающие в том числе и русский: \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fvicgalle\u002Fxlm-roberta-large-xnli-anli\" rel=\"noopener noreferrer nofollow\"\u003Exlm-roberta-large-xnli-anli\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Ffacebook\u002Fbart-large-mnli\" rel=\"noopener noreferrer nofollow\"\u003Ebart-large-mnli\u003C\u002Fa\u003E. \u003C\u002Fp\u003E\u003Cdiv class=\"table\"\u003E\u003Ctable\u003E\u003Ctbody\u003E\u003Ctr\u003E\u003Cth data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Emodel\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eclass\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003Eadd_one_rte\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003Eanli_r1\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003Eanli_r2\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003Eanli_r3\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003Ecopa\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003Efever\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003Ehelp\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003Eiie\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003Eimppres\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth\u003E\u003Cp\u003Ejoci\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003Emnli\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003Emonli\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003Empe\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003Escitail\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003Esick\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth\u003E\u003Cp\u003Esnli\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003Eterra\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003Cth data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003Etotal\u003C\u002Fp\u003E\u003C\u002Fth\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003En_observations\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E387\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E1000\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E1000\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E1200\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E200\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E20474\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E3355\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E31232\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E7661\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E939\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E19647\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E269\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E1000\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E2126\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E500\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E9831\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E307\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E101128\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Etiny\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eentailment\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E0.77\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.59\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.52\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.53\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E0.53\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E0.81\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.78\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.93\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.81\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.82\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.81\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.78\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.93\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.95\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.67\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.77\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Etwoway\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eentailment\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E0.89\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.73\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.61\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.62\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E0.58\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.96\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E0.92\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.87\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.99\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.99\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.96\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.97\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.97\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.87\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.86\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Ethreeway\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eentailment\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.75\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.61\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.61\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E0.57\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.96\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E0.56\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.61\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.99\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.67\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.92\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.84\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.98\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.98\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.80\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Exlm-roberta-large-xnli-anli\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eentailment\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E0.88\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.79\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.63\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.66\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E0.57\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.93\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E0.56\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.62\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.77\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.80\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.90\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.70\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.83\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.84\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.93\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.93\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.78\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Ebart-large-mnli\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eentailment\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E0.51\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.41\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.43\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.47\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E0.50\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.74\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E0.55\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.57\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.60\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.63\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.70\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.52\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.56\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.68\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.67\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.72\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.64\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.58\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Ethreeway\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Econtradiction\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.71\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.64\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.61\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.97\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E1.00\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.77\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.92\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.89\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.99\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.98\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.85\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd data-colwidth=\"199\" width=\"199\"\u003E\u003Cp\u003Ethreeway\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"104\" width=\"104\"\u003E\u003Cp\u003Eneutral\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"121\" width=\"121\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"75\" width=\"75\"\u003E\u003Cp\u003E0.79\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.70\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"73\" width=\"73\"\u003E\u003Cp\u003E0.62\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"61\" width=\"61\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E0.91\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"55\" width=\"55\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"86\" width=\"86\"\u003E\u003Cp\u003E0.99\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.68\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.86\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.79\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"57\" width=\"57\"\u003E\u003Cp\u003E0.96\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.96\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"60\" width=\"60\"\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd data-colwidth=\"67\" width=\"67\"\u003E\u003Cp\u003E0.83 \u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\u003C\u002Fdiv\u003E\u003Cp\u003EПерформанс модели XLM весьма неплох, но надо сделать скидку на то, что это большая и довольно медленная модель класса large. На видеокарте, с которой я работал, XLM и BART обрабатывали за секунду чуть меньше 2 батчей по 32 пары текстов, RuBERT-base –  7 батчей в секунду, а RuBERT-tiny – аж 36 батчей в секунду.\u003C\u002Fp\u003E\u003Cp\u003EВ целом, для задач zero-shot classification и распознавания entailment я рекомендую выбирать между умной и медленной \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-twoway\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-base-cased-nli-twoway\u003C\u002Fa\u003E и глупой и быстрой \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-tiny-bilingual-nli\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-tiny-bilingual-nli\u003C\u002Fa\u003E. Если же вам важно различать разницу между классами neutral и contradiction, то берите модель \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fcointegrated\u002Frubert-base-cased-nli-threeway\" rel=\"noopener noreferrer nofollow\"\u003Ecointegrated\u002Frubert-base-cased-nli-threeway\u003C\u002Fa\u003E, которая тоже работает весьма неплохо.\u003C\u002Fp\u003E\u003Cp\u003EЯ не уверен, что мне удалось создать самые лучшие модели NLI для русского языка; наверняка в закромах Сбера или Яндекса есть варианты помощнее. Но зато мои модели выложены в открытый доступ, а значит, вы можете использовать их для задач NLI, классификации, и детекции парафраз уже сейчас. \u003C\u002Fp\u003E\u003Cp\u003EА если вы уже успели попробовать применить русские модели для NLI, то пишите в комменты: на каких данных применяли, какой результат получился, какое общее впечатление? И не забывайте лайкать этот пост 🙃. \u003Cbr\u002F\u003E\u003Cbr\u002F\u003EМир вам, и да пребудет с вами сила умозаключений!\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"nli"},{"titleHtml":"nlu"},{"titleHtml":"natural language inference"},{"titleHtml":"natural language understanding"},{"titleHtml":"nlp"},{"titleHtml":"natural language processing"},{"titleHtml":"обработка естественного языка"},{"titleHtml":"bert"},{"titleHtml":"transformers"},{"titleHtml":"zero-shot classification"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e1\u002F4e8\u002F5ff\u002F3e14e85ffdb43c91e3f7de0875586f4a.png","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e1\u002F4e8\u002F5ff\u002F3e14e85ffdb43c91e3f7de0875586f4a.png","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582620\\\u002F\"},\"headline\":\"Нейросети для Natural Language Inference: логические умозаключения на русском языке\",\"datePublished\":\"2021-10-10T15:35:35+03:00\",\"dateModified\":\"2021-10-10T23:02:46+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Давид Дале\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"NLI (natural language inference) &ndash; это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582620\\\u002F#post-content-body\",\"about\":[\"h_python\",\"h_sw\",\"h_programming\",\"h_machine_learning\",\"h_natural_language_processing\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F582620\\\u002F98c99ff9d4d3fafb0382d89f2d55523c\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fb2a\\\u002Feb2\\\u002Fcea\\\u002Fb2aeb2ceaaa7d99ad953521f3e0a516a.png\"]}","metaDescription":"NLI (natural language inference) – это задача автоматического определения логической связи между текстами. Обычно она формулируется так: для двух утверждений A и B надо выяснить, следует ли B из A....","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"python,sw,programming,machine_learning,natural_language_processing"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
