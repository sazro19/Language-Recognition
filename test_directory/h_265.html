<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Препарирование нейронок, или TSNE и кластеризация на терабайтах данных / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/ntechlab\/blog\/584062\/"},"headline":"Препарирование нейронок, или TSNE и кластеризация на терабайтах данных","datePublished":"2021-10-20T13:10:00+03:00","dateModified":"2021-10-20T17:59:47+03:00","author":{"@type":"Person","name":"Максим"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в N...","url":"https:\/\/habr.com\/ru\/company\/ntechlab\/blog\/584062\/#post-content-body","about":["c_ntechlab","h_python","h_data_mining","h_machine_learning","f_develop"],"image":["https:\/\/habr.com\/share\/publication\/584062\/0b7d5afa7f82d6c07a747deae6c6c583\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/abb\/5a7\/8b7\/abb5a78b7905d7b4ba66c2359a3f3d83.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/3d9\/461\/850\/3d9461850b1b54e86f1318d1b6ce54c4.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/3e7\/756\/2e6\/3e77562e63290708f83415f8991c7e0f.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/70b\/1f6\/056\/70b1f60562fe0110adaed9d56ba75821.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/431\/63e\/c27\/43163ec2763e68024ac02478a4378618.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/574\/add\/453\/574add45329c05fd626ed8e585614835.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/401\/1b3\/662\/4011b366261e9d2b2c38f512d29a1654.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/8fb\/dd5\/be5\/8fbdd5be57eb0bece736a655813c5b1b.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/544\/545\/9ef\/5445459ef87a5a76410ee6dcd0707d47.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/24a\/8ae\/a40\/24a8aea404f6074f204d9499528836a5.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/c14\/197\/981\/c14197981fdafadad39a8d99cfc01181.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Препарирование нейронок, или TSNE и кластеризация на терабайтах данных" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Препарирование нейронок, или TSNE и кластеризация на терабайтах данных" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Препарирование нейронок, или TSNE и кластеризация на терабайтах данных" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="584062" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-20T10:10:00.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/584062/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/ntechlab/blog/584062/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/584062/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="ntechlab" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><!----></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"><div class="tm-company-card tm-company-article__company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/ntechlab/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/company/f2f/711/d1e/f2f711d1e56621060a912a73d2483243.png" width="48" class="tm-entity-image__pic"></div></a> <!----> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">57.21</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/ntechlab/profile/" class="tm-company-card__name">
        NtechLab
      </a> <div class="tm-company-card__description"></div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/Ferres/" title="Ferres" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/8f2/b4b/4e5/8f2b4b4e5120419f6917af85948bff8c.jpg" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/Ferres/" class="tm-user-info__username">
      Ferres
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-20T10:10:00.000Z" title="2021-10-20, 13:10">20  октября   в 13:10</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Препарирование нейронок, или TSNE и кластеризация на терабайтах данных</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/ntechlab/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании NtechLab</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/python/" class="tm-article-snippet__hubs-item-link"><span>Python</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/data_mining/" class="tm-article-snippet__hubs-item-link"><span>Data Mining</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="full-width "><img src="/img/image-loader.svg" height="540" data-src="https://habrastorage.org/getpro/habr/upload_files/abb/5a7/8b7/abb5a78b7905d7b4ba66c2359a3f3d83.png" data-width="960"/><figcaption></figcaption></figure><p>У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той ситуации, когда данных так много, что привычные инструменты интроспекции нейронных сетей становятся не информативны или вовсе не запускаются. У нас нет привычной разметки для обучения атрибутов. Но нам удалось вытащить из нейронной сети достаточно, чтобы классифицировать все имеющиеся данные на понятные человеку и учтенные нейронной сетью атрибуты. В этом посте мы расскажем, как это сделать.</p><p>Методов для интроспекции нейронных сетей придумано достаточно. Первое, что приходит в голову:</p><ul><li><p><a href="https://arxiv.org/abs/2002.00772"><u>Silence Map</u></a></p></li><li><p><a href="https://arxiv.org/abs/1602.04938v3"><u>LIME</u></a></p></li></ul><p>(Еще можно посмотреть <a href="https://christophm.github.io/interpretable-ml-book/neural-networks.html#neural-networks"><u>здесь</u></a>).</p><p>Преимущественно все эти методы исследуют и объясняют предсказание только одного объекта. Методов, которые изучают нейронку целиком, пытаются выяснить, что вообще выучила сетка, какие концепты и высокоуровневые признаки содержатся в данных, критически мало. Для понимания мест, где качество нейронки (Feature Extractor) может проседать, нужна информация обо всех примерах в структурированном виде.</p><figure class="full-width "><img src="/img/image-loader.svg" height="799" data-src="https://habrastorage.org/getpro/habr/upload_files/3d9/461/850/3d9461850b1b54e86f1318d1b6ce54c4.png" data-width="1692"/><figcaption></figcaption></figure><p>В ходе решения задачи распознавания лиц у нас возникла такая гипотеза, что в данных содержится гораздо больше информации, чем остается после сжатия в вектор признаков (Feature Vector). К примеру, у лиц, несомненно, есть атрибуты. Принято полагать, что на каждом следующем слое нейронной сети выделяются все более и более высокоуровневые признаки: начиная с уголков, черточек и других примитивов, заканчивая прической, полом, возрастом (применительно к распознаванию лиц). Мы не знаем заранее, какие высокоуровневые признаки на самом деле выделяются, из-за отсутствия разметки. Например, это могут быть: ношение очков, пол, ракурс съемки, прочие визуальные препятствия на фото. Если получить разметку таких скрытых атрибутов удастся, то можно фильтровать данные по ним, собирать малопредставленные в данных признаки (очки, маски) и так далее. В общем, вещь полезная.</p><p>Мы провели анализ собственной сетки распознавания лиц, и это помогло лучше понять, что происходит в обучении, и занять первое место в <a href="https://www.biometricupdate.com/202105/ntechlab-scores-highest-biometric-matching-accuracy-rates-in-three-nist-test-categories"><u>NIST</u></a>. Мы очень вдохновились полученными результатами и решили поделиться методологией с сообществом.</p><h3>Идея</h3><p>Как достать больше информации из нейронной сети? Хочется взглянуть на ее внутреннее представление до сжатия в вектор признаков. Однако размерность пространства достаточно большая, и анализировать его сложно. На помощь могли бы прийти PCA или TSNE, которые отлично справляются со сжатием в ограниченное число размерностей. Рассмотрим PCA:</p><figure class=""><img src="/img/image-loader.svg" height="278" data-src="https://habrastorage.org/getpro/habr/upload_files/3e7/756/2e6/3e77562e63290708f83415f8991c7e0f.png" data-width="372"/><figcaption></figcaption></figure><p>Рассмотрим компоненты PCA и визуализируем первые 10 из них картинками из датасета. Выясняется, что:</p><ol><li><p>Чтобы объяснить 80% вариативности, нужно достаточно много (200) компонент.</p></li><li><p>Анализ главных компонент PCA не оказался информативным, преобладание компоненты не означало наличия интерпретируемого признака (зато там есть Гарри Поттер).</p><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/70b/1f6/056/70b1f60562fe0110adaed9d56ba75821.jpg" alt="Анализ главных компонент на признаках нейронной сети" title="Анализ главных компонент на признаках нейронной сети" width="1923" height="1105" data-src="https://habrastorage.org/getpro/habr/upload_files/70b/1f6/056/70b1f60562fe0110adaed9d56ba75821.jpg" data-blurred="true"/><figcaption>Анализ главных компонент на признаках нейронной сети</figcaption></figure></li></ol><p>Теперь TSNE. Его проблемы состоят в том, что:</p><ol><li><p>Он не масштабируется на размер датасета, который предполагается исследовать: мы не дождемся результатов.</p></li><li><p>Если мы сделаем сжатие на меньшей выборке, экстраполировать на остальную выборку не представляется возможным: есть fit, нет predict.</p></li></ol><p>Предположим, мы запустили TSNE. Далее нам пригодится сделать кластеризацию, чтобы выявить похожие примеры из датасета. Тут надеемся, что кластеризация сможет выявить необходимые нам атрибуты.</p><h4>Масштабируем TSNE + Кластеризацию</h4><figure class="full-width "><img src="/img/image-loader.svg" alt="Пайплайн обучения модели TSNE+Кластеризации" title="Пайплайн обучения модели TSNE+Кластеризации" height="894" data-src="https://habrastorage.org/getpro/habr/upload_files/431/63e/c27/43163ec2763e68024ac02478a4378618.png" data-width="2048"/><figcaption>Пайплайн обучения модели TSNE+Кластеризации</figcaption></figure><p>Решение кроется в том, что в действительности нам не так важен результат работы TSNE – куда важнее получить метки кластеров. Будем использовать внутреннее представление нейронной сети – эмбеддинги. Если нам надо получить только метки, мы можем, например, сделать следующий трюк (нумерация соответствует картинке выше):</p><ol><li><p>Прогоняем нейронную сеть и делаем подвыборку из эмбеддингов датасета.</p></li><li><p>Делаем TSNE на подвыборке (2% – в нашем случае).</p></li><li><p>Делаем кластеризацию на результате п.2.</p></li><li><p>Обучаем классификатор «эмбеддинг – номер кластера». Сохраняем модель в ONNX.</p></li><li><p>Объединяем ONNX-граф нейронной сети с ONNX-графом классификатора.</p></li><li><p>Прогоняем классификатор на полной выборке или новых данных.</p></li></ol><p>При таком подходе мы сможем аппроксимировать результат понижения размерности + кластеризации на неограниченный объем данных. Приступим.</p><h3>Готовимся</h3><p>Предполагается, что проделанный анализ может провести любой желающий, поэтому необходимые ресурсы для эксперимента были весьма ограниченными.</p><ul><li><p>NVIDIA GeForce RTX 2080 Ti</p></li><li><p>Intel(R) Core(TM) i7-9700 CPU @ 3.00GHz</p></li><li><p>64G RAM</p></li></ul><p>Такой конфигурации будет более чем достаточно, чтобы и извлечь эмбеддинги, и запустить TSNE и провести кластеризацию.</p><blockquote><p>Весь используемый код находится в этом репозитории:<a href="https://github.com/NTech-Lab/dl-tsne"> <u>https://github.com/NTech-Lab/dl-tsne</u></a> </p><p>В посте будут только важные сниппеты без очень технических подробностей, за деталями лучше идти сразу в репозиторий и читать.</p></blockquote><h4>Подготовка нейронной сети</h4><p>Перед началом работы необходимо, конечно, обучить нейронную сеть на задаче (в нашем случае – это распознавание лиц) и сконвертировать ее в формат ONNX. В формате ONNX, оказывается, значительно проще работать с вычислительным графом и извлекать промежуточные слои. Более того, пайплайн хорошо переносится на широкий спектр фреймворков обучения.</p><p>Для открытого эксперимента мы взяли нейронную сеть распознавания лиц из репозитория<a href="https://github.com/deepinsight/insightface/tree/master/model_zoo"> <u>InsightFace</u></a>: <strong>webface_r50_pfc.onnx</strong>. Одну из самых лучших, доступных для свободного скачивания в академических целях.</p><h4>Извлечение признаков</h4><p>Имея ONNX-модель, нам необходимо научиться доставать скрытые слои этой нейронной сети на новых картинках. Оказалось, что этого можно добиться средствами ONNX без привязки к фреймворку обучения (<a href="https://github.com/microsoft/onnxruntime/issues/2119"><u>полезная ссылка</u></a>). Пересохраняем модель с промежуточными слоями.</p><details class="spoiler"><summary>Модификация ONNX</summary><div class="spoiler__content"><pre><code class="python">model = onnx.load_model(model_file)
intermediate_tensor_name = model.graph.node[-4].output[0]
intermediate_layer_value_info = onnx.helper.ValueInfoProto()
intermediate_layer_value_info.name = intermediate_tensor_name
model.graph.output.extend([intermediate_layer_value_info])
onnx.save(model, "interim+"+model_file)</code></pre></div></details><p><strong>О выборе промежуточного слоя.</strong> Посмотреть список промежуточных слоев в нейронной сети можно через <code>model.graph.node</code> – это лист из нод ONNX. Для желаемого слоя нам надо узнать имя тензора, где сохраняется результат выхода. Интуиция такая, что:</p><ol><li><p>чем глубже слой, тем более высокоуровневые признаки там содержатся;</p></li><li><p>беспроигрышным вариантом – будет выбрать последний слой перед сжатием информации (любое понижение размерности, перевод в логиты классификации, регуляризационные боттлнеки и т.д.).</p></li></ol><p>Конечно, хочется использовать сам вектор признаков лица, однако это будет не оптимально. Если посмотреть на устройство нейронной сети, увидим, что вектор признаков размерности 512 получается из тензора размерности 512х7х7 и сжимает информацию. В нашем случае – у сетки <strong>webface_r50_pfc.onnx</strong> сжатие информации происходит для создания эмбеддинга лица. Последний слой перед сжатием это:</p><details class="spoiler"><summary>model.graph.node[-4]</summary><div class="spoiler__content"><pre><code>input: "679"
input: "bn2.weight"
input: "bn2.bias"
input: "bn2.running_mean"
input: "bn2.running_var"
output: "680"
name: "BatchNormalization_126"
op_type: "BatchNormalization"
attribute {
  name: "epsilon"
  f: 9.999999747378752e-06
  type: FLOAT
}
attribute {
  name: "momentum"
  f: 0.8999999761581421
  type: FLOAT
}</code></pre></div></details><h4>Подготовка данных</h4><p>Для эксперимента мы скачали уже подготовленные данные <strong>glint360k</strong>, ссылку на скачивание можно найти<a href="https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_"> <u>в репозитории InsightFace</u></a> (распакован в <code>data/glint360</code>). Для использования своих датасетов можно обратить внимание на скрипт, <a href="https://github.com/NTech-Lab/dl-tsne/blob/main/normalizer.py"><u>который мы подготовили</u></a> (он задействует пайплайн инсайта для детекции и нормализации). Мы сложили все в папку <code>data/</code>, чтобы можно было, в случае чего, подменить данные.</p><p>Для однообразного доступа к каждой картинке можно использовать простые списки файлов. Например, файл <code>glint360.txt</code> был создан, как</p><pre><code class="bash">cd data
find ./glint_orig/ -name '*.jpg' > ../lists/glint360.txt</code></pre><h4>Готовим признаки</h4><blockquote><p>Обязательно выясните, как нормализовать картинки для нейронной сети, потому что неправильная нормализация испортит весь анализ, и его придется переделывать.</p></blockquote><pre><code class="python">def prepare_batch(imgs):
    if not isinstance(imgs, list):
        imgs = [imgs]
    blob = cv2.dnn.blobFromImages(
				imgs, 1.0 / input_std, input_size,
        (input_mean, input_mean, input_mean), 
				swapRB=True
		)
    return blob</code></pre><p>Для хранения признаков настоятельно рекомендуем использовать HDF5 формат, он удобен, переносим и выдерживает огромные размеры датасетов. Из недостатков самый неприятный – случайный доступ к конкретным элементам, что понадобится в дальнейшем. Имеет смысл сразу сделать как полный дамп эмбеддингов, так и подвыборку, чтобы потом сэкономить время.</p><details class="spoiler"><summary>Как мы организовали дамп в HDF5</summary><div class="spoiler__content"><p><strong>Важно:</strong> для скрытого слоя берем <strong>центральный пиксель.</strong> Эмпирически🙂 выяснено, что это работает в среднем лучше, чем другие попытки (пробовали maxpool и avgpool).</p><pre><code class="python">P = 0.02
files = np.asarray(list(map(str.strip, open("../lists/glint360.txt").readlines())))
subset = np.random.RandomState(2463426724).random(len(files)) &lt; P
subset_files = files[subset]
root = "../data/"

with tqdm.tqdm(subset_files) as _files, h5py.File(model_file + f".{P}-embeddings.h5", "w") as f:
    prefacen = f.create_dataset("prefacen", (0, 512), maxshape=(None, 512), chunks=(512, 512))
    facen = f.create_dataset("facen", (0, 512), maxshape=(None, 512), chunks=(512, 512))
    for images in more_itertools.chunked(
            map(cv2.imread, map(root.__add__, _files))
        , 512):
        batch = prepare_batch(images)
        facen_i, prefacen_i = session.run(output_cfg, {input_name: batch})
        prefacen.resize((prefacen.shape[0]+prefacen_i.shape[0], prefacen.shape[1]))
        facen.resize((facen.shape[0]+facen_i.shape[0], facen.shape[1]))
        prefacen[-prefacen_i.shape[0]:] = prefacen_i**[..., prefacen_i.shape[-1] // 2, prefacen_i.shape[-1] // 2]**
        facen[-facen_i.shape[0]:] = facen_i
</code></pre></div></details><p>Можно всячески оптимизировать извлечение признаков, но это не было основной целью демонстрации. Мы просто оставили на ночь считаться, и вернулись к задаче на следующий день. Распараллелить цикл на несколько GPU, сохранять результаты в разные HDF5 файлы и потом объединять было бы гораздо быстрее.</p><h3>TSNE + Кластеризация</h3><h4>Понижение размерности</h4><p>Когда мы подготовили данные, у нас получилось два файла с эмбеддингами:</p><pre><code>-rw-rw-r-- 1 user user 1.4G Sep 16 12:16 webface_r50_pfc.onnx.0.02-embeddings.h5
-rw-rw-r-- 1 user user  66G Sep 16 22:31 webface_r50_pfc.onnx.1-embeddings.h5</code></pre><p>Уже упоминалось, что случайную подвыборку делать ужасно долго, поэтому <code>webface_r50_pfc.onnx.0.02-embeddings.h5</code> – то, что нам надо. Это 2%-я подвыборка из всего датасета, на ней можно проводить анализ, чтобы потом кластеризовать весь оставшийся датасет. Этот размер датасета выбран не случайно: он помещается в GPU (RTX 2080ti) для подсчета TSNE. Если у вас GPU пожирнее, можно увеличить подвыборку, но это не принципиально.</p><pre><code class="python">subset_embeddings = h5py.File("webface_r50_pfc.onnx.0.02-embeddings.h5", "r")
prefacen = subset_embeddings["prefacen"][()]</code></pre><p>В этом виде данные уже можно отправлять в TSNE (выбор гиперпараметров был произведен вручную):</p><pre><code class="python">tsne = tsnecuda.TSNE(
    num_neighbors=1000,
    perplexity=200, n_iter=4000, learning_rate=2000
).fit_transform(prefacen)</code></pre><p>Получаем вот такие двумерные признаки <code>tsne</code> из изначальных эмбедднигов (была размерность 512). Кластера визуально отличимы друг от друга, как и хотелось для проведения анализа.</p><figure class=""><img src="/img/image-loader.svg" alt="Двумерные признаки TSNE" title="Двумерные признаки TSNE" height="248" data-src="https://habrastorage.org/getpro/habr/upload_files/574/add/453/574add45329c05fd626ed8e585614835.png" data-width="370"/><figcaption>Двумерные признаки TSNE</figcaption></figure><p>Уже видны намеки на то, что это можно как-то кластеризовать. Прежде чем пойдем дальше, – пара слов о процессе обучения TSNE.</p><blockquote><p>Подбор гиперпараметров (про них подробнее <a href="https://habr.com/ru/post/267041/"><u>здесь</u></a> и <a href="https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868"><u>здесь</u></a>) оказался исключительно ручным процессом. Не сильно долгий, чтобы быть неэффективным и безысходным, но и не настолько быстрый, чтобы оставить его без внимания. Особенно чувствительными параметрами TSNE оказались те, что показаны в сниппете. Отдельно хочется заметить, что при большой выборке параметр <strong>num_neighbors</strong> пришлось увеличить, без этого все остальные параметры были нечувствительны к изменениям – стабильно давали плохой результат. Потом опытным путем, чуть-чуть увеличив <strong>perplexity</strong> и увеличив количество итераций, получили достаточно многообещающую картинку (видны скопления объектов, кластера!). <em>Все найденные параметры специфичны под эту конкретную сетку и данные. Для сетки в NtechLab оптимальными были чуть другие, но идея та же.</em></p></blockquote><h4>Кластеризация</h4><p>Для кластеризации напрашивается DBSCAN с его порогом для разделения кластеров по плотности. Про DBSCAN можно почитать <a href="https://habr.com/ru/post/322034/"><u>здесь</u></a>.</p><p>Мы немного его адаптировали, чтобы он работал не так долго на таком объеме данных. Исходный DBSCAN работает несколько минут на всей подвыборке, а это слишком долго, чтобы быстро итерироваться и подобрать хорошие гиперпараметры. Идея такая:</p><ul><li><p>берем подвыборку;</p></li><li><p>запускаем DBSCAN, получаем метки кластеров;</p></li><li><p>обучаем KNN на метках кластеров, размечаем все остальное;</p></li><li><p>получаем быструю версию DBSCAN🙂.</p></li></ul><details class="spoiler"><summary>KNNDBSCAN(sklearn.cluster.DBSCAN):</summary><div class="spoiler__content"><pre><code class="python">class KNNDBSCAN(sklearn.cluster.DBSCAN):
    """DBSCAN worked well when I sample down points. But gives no prediction.
    So I train KNN on top of cluster labels
    """
    def __init__(self, *args, subset=1, knn_params=None, random_seed=42, **kwargs, ):
        super().__init__(*args, **kwargs)
        knn_params = knn_params or dict()
        self.knn = sklearn.neighbors.KNeighborsClassifier(
            n_jobs=kwargs.pop("n_jobs", None),
            **knn_params
        )
        self.subset_ = subset
        self.rng = np.random.RandomState(random_seed)
    
    def subset(self, X, y=None):
        train_idx = np.arange(len(X))
        self.rng.shuffle(train_idx)
        train_idx = train_idx[:int(len(X) * self.subset_)]
        if y is None:
            return X[train_idx]
        else:
            return X[train_idx], y[train_idx]

    def fit(self, X):
        train_X = self.subset(X)
        super().fit(train_X)
        train_labels = self.labels_
        train_kidx = np.where(train_labels >= 0)
        self.knn.fit(train_X[train_kidx], train_labels[train_kidx])
        del self.labels_
        return self
    
    def predict(self, X):
        return self.knn.predict(X)

    def fit_predict(self, X):
        return self.fit(X).predict(X)</code></pre></div></details><blockquote><p>Подбор гиперпараметров DBSCAN – еще более долгий процесс, чем TSNE. Подобрать гиперпараметры было непросто, чтобы разбивка на кластеры выглядела визуально хорошо. Если у кого есть идея, как сделать лучше, – велком.</p></blockquote><pre><code class="python">ntsne = (tsne - tsne.mean(0)) / tsne.std(0)
y = KNNDBSCAN(min_samples=120, subset=0.5, eps=0.05, knn_params=dict(n_neighbors=5)).fit_predict(ntsne)
display_labels(ntsne, y, slc=slice(None, None, 5), alpha=0.002)</code></pre><figure class=""><img src="/img/image-loader.svg" alt="Кластеризованный TSNE" title="Кластеризованный TSNE" height="248" data-src="https://habrastorage.org/getpro/habr/upload_files/401/1b3/662/4011b366261e9d2b2c38f512d29a1654.png" data-width="382"/><figcaption>Кластеризованный TSNE</figcaption></figure><h4>Предварительные результаты</h4><p>Для текущей подвыборки мы можем найти наиболее явные кластеры и посмотреть на фото, которые им соответствуют.</p><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/8fb/dd5/be5/8fbdd5be57eb0bece736a655813c5b1b.jpg" width="1914" height="1229" data-src="https://habrastorage.org/getpro/habr/upload_files/8fb/dd5/be5/8fbdd5be57eb0bece736a655813c5b1b.jpg" data-blurred="true"/><figcaption></figcaption></figure><p>Если присмотреться, то маленькие кластеры (10, 8, 6, 4 и 3) очень репрезентативны. Например, третий – кластер с очками. С маленькими кластерами и связана вся сложность подбора гиперпараметров. Они яркие, но выделить их бывает сложно.</p><h3>Переносим модель на терабайты</h3><p>Мы получили разметку для наших данных, но у нас осталось 98% данных без этой разметки по кластерам. Для применения модели на практике необходимо все это дело довести до ума. В идеале – иметь ONNX-модель, которая делает все сразу. Это достижимый результат, давайте его реализуем.</p><h4>Доменная регрессия</h4><p>Как ни странно, но для применения модели нам будет достаточно обычной линейной регрессии. Обучим ее.</p><pre><code class="python">from sklearn.linear_model import LogisticRegressionCV
cluster_model = LogisticRegressionCV(n_jobs=-1, max_iter=1000)
cluster_model.fit(prefacen, y)
score = cluster_model.score(prefacen, y)</code></pre><p>В моем случае score=0.9623, что достаточно неплохо. На нашей практике проблемы наблюдались когда score&lt;0.7, так что 0.96 – достойный результат. ROC AUC (ovo/ovr; weighted/macro) больше 0.975, что тоже не вызывает подозрений. Визуальное сравнение тоже в порядке. Идем дальше!</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Визуальное сравнение модели классификации и исходной кластеризации" title="Визуальное сравнение модели классификации и исходной кластеризации" height="319" data-src="https://habrastorage.org/getpro/habr/upload_files/544/545/9ef/5445459ef87a5a76410ee6dcd0707d47.png" data-width="944"/><figcaption>Визуальное сравнение модели классификации и исходной кластеризации</figcaption></figure><details class="spoiler"><summary>Конвертируем в ONNX:</summary><div class="spoiler__content"><pre><code class="python">from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
initial_type = [('float_input', FloatTensorType([None, 512]))]
options = {id(cluster_model): {'raw_scores': True}}
onx = convert_sklearn(cluster_model, initial_types=initial_type, options=options)
with open("cluster_model.webface_r50_pfc.680.onnx", "wb") as f:
    f.write(onx.SerializeToString())</code></pre></div></details><h3>Применение модели</h3><p>Итак, на данном этапе мы обучили модель классификации кластеров по эмбеддингам сетки. Но, чтобы применить это на практике эффективно, нам надо сделать несколько дополнительных шагов. Нерационально иметь две модели, одна из которых зависит от другой. Для инференса лучше сделать одну общую ONNX-модель под капотом, запуская модель кластеризации по эмбеддингам. Приступим.</p><p>У нас имеются:</p><ul><li><p><code>cluster_model.webface_r50_pfc.680.onnx</code></p></li><li><p><code>webface_r50_pfc.onnx</code></p></li></ul><p>Для манипуляции графами ONNX была использована библиотека <a href="https://github.com/scailable/sclblonnx"><u>sclblonnx</u></a>. Она позволяет склеивать графы, подменять входы и выходы, то что нужно.</p><details class="spoiler"><summary>Код конвертации:</summary><div class="spoiler__content"><pre><code class="python"># load 2 models to merge
# note that all operations below mutate the input graph
model = so.graph_from_file("webface_r50_pfc.onnx")
cluster = so.graph_from_file("cluster_model.webface_r50_pfc.680.onnx")

# prepare nodes to extract the correct slice
node_slice = onnx.helper.make_node(
    'Slice',
    inputs=['680', "680.start", "680.end", "680.axes"],
    outputs=['680.slice.nd'],
    name="Slice.680"
)
node_squeeze = onnx.helper.make_node(
    'Squeeze',
    inputs=['680.slice.nd'],
    axes=[2, 3],
    outputs=['680.slice'],
    name="Squeeze.680"
)
# constants are required to pass to slice parameters, need to be added to the graph
model = so.add_constant(model, "680.start", value=np.asarray([3, 3]), data_type="INT64")
model = so.add_constant(model, "680.end", value=np.asarray([4, 4]), data_type="INT64")
model = so.add_constant(model, "680.axes", value=np.asarray([2, 3]), data_type="INT64")
# extracting slice from 680 layer
model = so.add_node(model, node_slice)
model = so.add_node(model, node_squeeze)
# merging
model12 = so.merge(model, cluster, io_match=[("680.slice", "float_input")], complete=False)
# fix weird shape warning, complained on shape 1 output
out0 = onnx.helper.ValueInfoProto()
out0.name = model12.output[0].name
model12.output.remove(model12.output[0])
model12.output.insert(0, out0)
# saving
so.graph_to_file(model12, "webface_r50_pfc+cluster.onnx")</code></pre></div></details><p>Теперь можно запускать модель на новых данных и получать метки кластеров. К примеру, третий кластер с очками уже из исходного датасета, где большей части не было в обучении модели кластеризации:</p><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/24a/8ae/a40/24a8aea404f6074f204d9499528836a5.jpg" alt="Третий кластер с очками" title="Третий кластер с очками" width="1131" height="1105" data-src="https://habrastorage.org/getpro/habr/upload_files/24a/8ae/a40/24a8aea404f6074f204d9499528836a5.jpg" data-blurred="true"/><figcaption>Третий кластер с очками</figcaption></figure><p>Вот так выглядит распределение кластеров в датасете:</p><figure class=""><img src="/img/image-loader.svg" alt="Распределение кластеров в датасете" title="Распределение кластеров в датасете" height="273" data-src="https://habrastorage.org/getpro/habr/upload_files/c14/197/981/c14197981fdafadad39a8d99cfc01181.png" data-width="386"/><figcaption>Распределение кластеров в датасете</figcaption></figure><h3>Выводы</h3><p>Кластеры можно разделить условно на желаемые и нежелаемые. Желаемые кластеры – это, например, пол, где разные кластеры не могут быть одним человеком. Нежелаемые кластеры, наоборот, объединяют людей по признаку, который мы хотим игнорировать. Например, качество снимка, угол съемки, очки, маска.</p><p>В исследуемой сетке наблюдается повышенное внимание к очкам, и хочется дальше исследовать это направление в поиске решения связанной адаптации модели к разным доменам (про это писали <a href="https://habr.com/ru/company/mailru/blog/426803/"><u>здесь</u></a>).</p><p>Схожие результаты анализа на наших данных мы использовали для:</p><ul><li><p>подбора обучающей выборки для тренировки новой модели;</p></li><li><p>фильтрации нежелательных, на наш взгляд, кластеров (картинки с «мусором»).</p></li></ul><h4>Что можно было сделать лучше</h4><p>В целом результат получился хороший: даже маленькие домены (недостаточно представленные, но отличные от общей массы) выделены, и они репрезентативны. Как всегда, есть нюансы, которым стоило бы уделить больше времени на доработку, полировку:</p><ul><li><p>разделить получше большой первый кластер, так как там достаточно смешанный домен;</p></li><li><p>использовать другой алгоритм кластеризации: думаем, OPTICS должен быть более гибким, по сравнению с DBSCAN (реализация в sklearn <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS"><u>здесь</u></a>).</p></li></ul></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bdeep%20learning%5D" class="tm-tags-list__link">deep learning</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bunsupervised%20learning%5D" class="tm-tags-list__link">unsupervised learning</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Blarge%20scale%20machine%20learning%5D" class="tm-tags-list__link">large scale machine learning</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btsne%5D" class="tm-tags-list__link">tsne</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bdbscan%5D" class="tm-tags-list__link">dbscan</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/company/ntechlab/blog/" class="tm-hubs-list__link router-link-active">
    Блог компании NtechLab
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/python/" class="tm-hubs-list__link">
    Python
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/data_mining/" class="tm-hubs-list__link">
    Data Mining
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 16: ↑12 и ↓4</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 16: ↑12 и ↓4" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+8</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">2K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    26
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/ntechlab/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/company/f2f/711/d1e/f2f711d1e56621060a912a73d2483243.png" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/ntechlab/profile/" class="tm-company-snippet__title">NtechLab</a> <div class="tm-company-snippet__description">Компания</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <div class="tm-article-author__company-contacts"><a href="https://findface.pro/ru/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a><a href="http://ntechlab.ru/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a></div> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/Ferres/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/8f2/b4b/4e5/8f2b4b4e5120419f6917af85948bff8c.jpg" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 18 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    16
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">8</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Максим</span> <a href="/ru/users/Ferres/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @Ferres
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Data Scientist</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <div class="tm-article-author__user-contacts"><a href="https://github.com/ferrine/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Github
    </a></div></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/ntechlab/blog/584062/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 2 
    </span></a> <!----></div></div></div>  <!---->  <!----> <!----></div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2015-09-30T21:00:00.000Z" title="2015-10-01, 00:00">1  октября  2015</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    Россия
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="http://ntechlab.ru" target="_blank" class="tm-company-basic-info__link">
      ntechlab.ru
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    101–200 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2017-02-27T14:06:29.000Z" title="2017-02-27, 17:06">27  февраля  2017</time></dd></dl> <!----></div></div> <!----></section> <div class="tm-company-widgets"></div> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/ntechlab/blog/584062/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/ntechlab/blog/584062/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"584062":{"id":"584062","timePublished":"2021-10-20T10:10:00+00:00","isCorporative":true,"lang":"ru","titleHtml":"Препарирование нейронок, или TSNE и кластеризация на терабайтах данных","leadData":{"textHtml":"\u003Cp\u003EУ вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той ситуации, когда данных так много, что привычные инструменты интроспекции нейронных сетей становятся не информативны или вовсе не запускаются. У нас нет привычной разметки для обучения атрибутов. Но нам удалось вытащить из нейронной сети достаточно, чтобы классифицировать все имеющиеся данные на понятные человеку и учтенные нейронной сетью атрибуты. В этом посте мы расскажем, как это сделать.\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabb\u002F5a7\u002F8b7\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabb\u002F5a7\u002F8b7\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":16,"votesCount":18},"rating":8,"relatedData":null,"contacts":[{"title":"Github","url":"https:\u002F\u002Fgithub.com\u002Fferrine\u002F","value":"ferrine"}],"authorContacts":[{"title":"Github","url":"https:\u002F\u002Fgithub.com\u002Fferrine\u002F","value":"ferrine"}],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"941404","alias":"Ferres","fullname":"Максим","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F8f2\u002Fb4b\u002F4e5\u002F8f2b4b4e5120419f6917af85948bff8c.jpg","speciality":"Data Scientist"},"statistics":{"commentsCount":2,"favoritesCount":26,"readingCount":1952,"score":8,"votesCount":16},"hubs":[{"relatedData":null,"id":"20984","alias":"ntechlab","type":"corporative","title":"Блог компании NtechLab","titleHtml":"Блог компании NtechLab","isProfiled":false},{"relatedData":null,"id":"340","alias":"python","type":"collective","title":"Python","titleHtml":"Python","isProfiled":true},{"relatedData":null,"id":"7152","alias":"data_mining","type":"collective","title":"Data Mining","titleHtml":"Data Mining","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"540\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabb\u002F5a7\u002F8b7\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png\" data-width=\"960\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EУ вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той ситуации, когда данных так много, что привычные инструменты интроспекции нейронных сетей становятся не информативны или вовсе не запускаются. У нас нет привычной разметки для обучения атрибутов. Но нам удалось вытащить из нейронной сети достаточно, чтобы классифицировать все имеющиеся данные на понятные человеку и учтенные нейронной сетью атрибуты. В этом посте мы расскажем, как это сделать.\u003C\u002Fp\u003E\u003Cp\u003EМетодов для интроспекции нейронных сетей придумано достаточно. Первое, что приходит в голову:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2002.00772\"\u003E\u003Cu\u003ESilence Map\u003C\u002Fu\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1602.04938v3\"\u003E\u003Cu\u003ELIME\u003C\u002Fu\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E(Еще можно посмотреть \u003Ca href=\"https:\u002F\u002Fchristophm.github.io\u002Finterpretable-ml-book\u002Fneural-networks.html#neural-networks\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003Cp\u003EПреимущественно все эти методы исследуют и объясняют предсказание только одного объекта. Методов, которые изучают нейронку целиком, пытаются выяснить, что вообще выучила сетка, какие концепты и высокоуровневые признаки содержатся в данных, критически мало. Для понимания мест, где качество нейронки (Feature Extractor) может проседать, нужна информация обо всех примерах в структурированном виде.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"799\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3d9\u002F461\u002F850\u002F3d9461850b1b54e86f1318d1b6ce54c4.png\" data-width=\"1692\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EВ ходе решения задачи распознавания лиц у нас возникла такая гипотеза, что в данных содержится гораздо больше информации, чем остается после сжатия в вектор признаков (Feature Vector). К примеру, у лиц, несомненно, есть атрибуты. Принято полагать, что на каждом следующем слое нейронной сети выделяются все более и более высокоуровневые признаки: начиная с уголков, черточек и других примитивов, заканчивая прической, полом, возрастом (применительно к распознаванию лиц). Мы не знаем заранее, какие высокоуровневые признаки на самом деле выделяются, из-за отсутствия разметки. Например, это могут быть: ношение очков, пол, ракурс съемки, прочие визуальные препятствия на фото. Если получить разметку таких скрытых атрибутов удастся, то можно фильтровать данные по ним, собирать малопредставленные в данных признаки (очки, маски) и так далее. В общем, вещь полезная.\u003C\u002Fp\u003E\u003Cp\u003EМы провели анализ собственной сетки распознавания лиц, и это помогло лучше понять, что происходит в обучении, и занять первое место в \u003Ca href=\"https:\u002F\u002Fwww.biometricupdate.com\u002F202105\u002Fntechlab-scores-highest-biometric-matching-accuracy-rates-in-three-nist-test-categories\"\u003E\u003Cu\u003ENIST\u003C\u002Fu\u003E\u003C\u002Fa\u003E. Мы очень вдохновились полученными результатами и решили поделиться методологией с сообществом.\u003C\u002Fp\u003E\u003Ch3\u003EИдея\u003C\u002Fh3\u003E\u003Cp\u003EКак достать больше информации из нейронной сети? Хочется взглянуть на ее внутреннее представление до сжатия в вектор признаков. Однако размерность пространства достаточно большая, и анализировать его сложно. На помощь могли бы прийти PCA или TSNE, которые отлично справляются со сжатием в ограниченное число размерностей. Рассмотрим PCA:\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"278\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e7\u002F756\u002F2e6\u002F3e77562e63290708f83415f8991c7e0f.png\" data-width=\"372\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EРассмотрим компоненты PCA и визуализируем первые 10 из них картинками из датасета. Выясняется, что:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003EЧтобы объяснить 80% вариативности, нужно достаточно много (200) компонент.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EАнализ главных компонент PCA не оказался информативным, преобладание компоненты не означало наличия интерпретируемого признака (зато там есть Гарри Поттер).\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F70b\u002F1f6\u002F056\u002F70b1f60562fe0110adaed9d56ba75821.jpg\" alt=\"Анализ главных компонент на признаках нейронной сети\" title=\"Анализ главных компонент на признаках нейронной сети\" width=\"1923\" height=\"1105\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F70b\u002F1f6\u002F056\u002F70b1f60562fe0110adaed9d56ba75821.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EАнализ главных компонент на признаках нейронной сети\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EТеперь TSNE. Его проблемы состоят в том, что:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003EОн не масштабируется на размер датасета, который предполагается исследовать: мы не дождемся результатов.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EЕсли мы сделаем сжатие на меньшей выборке, экстраполировать на остальную выборку не представляется возможным: есть fit, нет predict.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EПредположим, мы запустили TSNE. Далее нам пригодится сделать кластеризацию, чтобы выявить похожие примеры из датасета. Тут надеемся, что кластеризация сможет выявить необходимые нам атрибуты.\u003C\u002Fp\u003E\u003Ch4\u003EМасштабируем TSNE + Кластеризацию\u003C\u002Fh4\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Пайплайн обучения модели TSNE+Кластеризации\" title=\"Пайплайн обучения модели TSNE+Кластеризации\" height=\"894\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F431\u002F63e\u002Fc27\u002F43163ec2763e68024ac02478a4378618.png\" data-width=\"2048\"\u002F\u003E\u003Cfigcaption\u003EПайплайн обучения модели TSNE+Кластеризации\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EРешение кроется в том, что в действительности нам не так важен результат работы TSNE – куда важнее получить метки кластеров. Будем использовать внутреннее представление нейронной сети – эмбеддинги. Если нам надо получить только метки, мы можем, например, сделать следующий трюк (нумерация соответствует картинке выше):\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003EПрогоняем нейронную сеть и делаем подвыборку из эмбеддингов датасета.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EДелаем TSNE на подвыборке (2% – в нашем случае).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EДелаем кластеризацию на результате п.2.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EОбучаем классификатор «эмбеддинг – номер кластера». Сохраняем модель в ONNX.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EОбъединяем ONNX-граф нейронной сети с ONNX-графом классификатора.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EПрогоняем классификатор на полной выборке или новых данных.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EПри таком подходе мы сможем аппроксимировать результат понижения размерности + кластеризации на неограниченный объем данных. Приступим.\u003C\u002Fp\u003E\u003Ch3\u003EГотовимся\u003C\u002Fh3\u003E\u003Cp\u003EПредполагается, что проделанный анализ может провести любой желающий, поэтому необходимые ресурсы для эксперимента были весьма ограниченными.\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003ENVIDIA GeForce RTX 2080 Ti\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EIntel(R) Core(TM) i7-9700 CPU @ 3.00GHz\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E64G RAM\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EТакой конфигурации будет более чем достаточно, чтобы и извлечь эмбеддинги, и запустить TSNE и провести кластеризацию.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EВесь используемый код находится в этом репозитории:\u003Ca href=\"https:\u002F\u002Fgithub.com\u002FNTech-Lab\u002Fdl-tsne\"\u003E \u003Cu\u003Ehttps:\u002F\u002Fgithub.com\u002FNTech-Lab\u002Fdl-tsne\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003Cp\u003EВ посте будут только важные сниппеты без очень технических подробностей, за деталями лучше идти сразу в репозиторий и читать.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Ch4\u003EПодготовка нейронной сети\u003C\u002Fh4\u003E\u003Cp\u003EПеред началом работы необходимо, конечно, обучить нейронную сеть на задаче (в нашем случае – это распознавание лиц) и сконвертировать ее в формат ONNX. В формате ONNX, оказывается, значительно проще работать с вычислительным графом и извлекать промежуточные слои. Более того, пайплайн хорошо переносится на широкий спектр фреймворков обучения.\u003C\u002Fp\u003E\u003Cp\u003EДля открытого эксперимента мы взяли нейронную сеть распознавания лиц из репозитория\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fdeepinsight\u002Finsightface\u002Ftree\u002Fmaster\u002Fmodel_zoo\"\u003E \u003Cu\u003EInsightFace\u003C\u002Fu\u003E\u003C\u002Fa\u003E: \u003Cstrong\u003Ewebface_r50_pfc.onnx\u003C\u002Fstrong\u003E. Одну из самых лучших, доступных для свободного скачивания в академических целях.\u003C\u002Fp\u003E\u003Ch4\u003EИзвлечение признаков\u003C\u002Fh4\u003E\u003Cp\u003EИмея ONNX-модель, нам необходимо научиться доставать скрытые слои этой нейронной сети на новых картинках. Оказалось, что этого можно добиться средствами ONNX без привязки к фреймворку обучения (\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmicrosoft\u002Fonnxruntime\u002Fissues\u002F2119\"\u003E\u003Cu\u003Eполезная ссылка\u003C\u002Fu\u003E\u003C\u002Fa\u003E). Пересохраняем модель с промежуточными слоями.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EМодификация ONNX\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Emodel = onnx.load_model(model_file)\nintermediate_tensor_name = model.graph.node[-4].output[0]\nintermediate_layer_value_info = onnx.helper.ValueInfoProto()\nintermediate_layer_value_info.name = intermediate_tensor_name\nmodel.graph.output.extend([intermediate_layer_value_info])\nonnx.save(model, \"interim+\"+model_file)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003E\u003Cstrong\u003EО выборе промежуточного слоя.\u003C\u002Fstrong\u003E Посмотреть список промежуточных слоев в нейронной сети можно через \u003Ccode\u003Emodel.graph.node\u003C\u002Fcode\u003E – это лист из нод ONNX. Для желаемого слоя нам надо узнать имя тензора, где сохраняется результат выхода. Интуиция такая, что:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003Eчем глубже слой, тем более высокоуровневые признаки там содержатся;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eбеспроигрышным вариантом – будет выбрать последний слой перед сжатием информации (любое понижение размерности, перевод в логиты классификации, регуляризационные боттлнеки и т.д.).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EКонечно, хочется использовать сам вектор признаков лица, однако это будет не оптимально. Если посмотреть на устройство нейронной сети, увидим, что вектор признаков размерности 512 получается из тензора размерности 512х7х7 и сжимает информацию. В нашем случае – у сетки \u003Cstrong\u003Ewebface_r50_pfc.onnx\u003C\u002Fstrong\u003E сжатие информации происходит для создания эмбеддинга лица. Последний слой перед сжатием это:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003Emodel.graph.node[-4]\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Einput: \"679\"\ninput: \"bn2.weight\"\ninput: \"bn2.bias\"\ninput: \"bn2.running_mean\"\ninput: \"bn2.running_var\"\noutput: \"680\"\nname: \"BatchNormalization_126\"\nop_type: \"BatchNormalization\"\nattribute {\n  name: \"epsilon\"\n  f: 9.999999747378752e-06\n  type: FLOAT\n}\nattribute {\n  name: \"momentum\"\n  f: 0.8999999761581421\n  type: FLOAT\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Ch4\u003EПодготовка данных\u003C\u002Fh4\u003E\u003Cp\u003EДля эксперимента мы скачали уже подготовленные данные \u003Cstrong\u003Eglint360k\u003C\u002Fstrong\u003E, ссылку на скачивание можно найти\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fdeepinsight\u002Finsightface\u002Ftree\u002Fmaster\u002Frecognition\u002F_datasets_\"\u003E \u003Cu\u003Eв репозитории InsightFace\u003C\u002Fu\u003E\u003C\u002Fa\u003E (распакован в \u003Ccode\u003Edata\u002Fglint360\u003C\u002Fcode\u003E). Для использования своих датасетов можно обратить внимание на скрипт, \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FNTech-Lab\u002Fdl-tsne\u002Fblob\u002Fmain\u002Fnormalizer.py\"\u003E\u003Cu\u003Eкоторый мы подготовили\u003C\u002Fu\u003E\u003C\u002Fa\u003E (он задействует пайплайн инсайта для детекции и нормализации). Мы сложили все в папку \u003Ccode\u003Edata\u002F\u003C\u002Fcode\u003E, чтобы можно было, в случае чего, подменить данные.\u003C\u002Fp\u003E\u003Cp\u003EДля однообразного доступа к каждой картинке можно использовать простые списки файлов. Например, файл \u003Ccode\u003Eglint360.txt\u003C\u002Fcode\u003E был создан, как\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"bash\"\u003Ecd data\nfind .\u002Fglint_orig\u002F -name '*.jpg' \u003E ..\u002Flists\u002Fglint360.txt\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Ch4\u003EГотовим признаки\u003C\u002Fh4\u003E\u003Cblockquote\u003E\u003Cp\u003EОбязательно выясните, как нормализовать картинки для нейронной сети, потому что неправильная нормализация испортит весь анализ, и его придется переделывать.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Edef prepare_batch(imgs):\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    blob = cv2.dnn.blobFromImages(\n\t\t\t\timgs, 1.0 \u002F input_std, input_size,\n        (input_mean, input_mean, input_mean), \n\t\t\t\tswapRB=True\n\t\t)\n    return blob\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EДля хранения признаков настоятельно рекомендуем использовать HDF5 формат, он удобен, переносим и выдерживает огромные размеры датасетов. Из недостатков самый неприятный – случайный доступ к конкретным элементам, что понадобится в дальнейшем. Имеет смысл сразу сделать как полный дамп эмбеддингов, так и подвыборку, чтобы потом сэкономить время.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКак мы организовали дамп в HDF5\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cp\u003E\u003Cstrong\u003EВажно:\u003C\u002Fstrong\u003E для скрытого слоя берем \u003Cstrong\u003Eцентральный пиксель.\u003C\u002Fstrong\u003E Эмпирически🙂 выяснено, что это работает в среднем лучше, чем другие попытки (пробовали maxpool и avgpool).\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003EP = 0.02\nfiles = np.asarray(list(map(str.strip, open(\"..\u002Flists\u002Fglint360.txt\").readlines())))\nsubset = np.random.RandomState(2463426724).random(len(files)) &lt; P\nsubset_files = files[subset]\nroot = \"..\u002Fdata\u002F\"\n\nwith tqdm.tqdm(subset_files) as _files, h5py.File(model_file + f\".{P}-embeddings.h5\", \"w\") as f:\n    prefacen = f.create_dataset(\"prefacen\", (0, 512), maxshape=(None, 512), chunks=(512, 512))\n    facen = f.create_dataset(\"facen\", (0, 512), maxshape=(None, 512), chunks=(512, 512))\n    for images in more_itertools.chunked(\n            map(cv2.imread, map(root.__add__, _files))\n        , 512):\n        batch = prepare_batch(images)\n        facen_i, prefacen_i = session.run(output_cfg, {input_name: batch})\n        prefacen.resize((prefacen.shape[0]+prefacen_i.shape[0], prefacen.shape[1]))\n        facen.resize((facen.shape[0]+facen_i.shape[0], facen.shape[1]))\n        prefacen[-prefacen_i.shape[0]:] = prefacen_i**[..., prefacen_i.shape[-1] \u002F\u002F 2, prefacen_i.shape[-1] \u002F\u002F 2]**\n        facen[-facen_i.shape[0]:] = facen_i\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EМожно всячески оптимизировать извлечение признаков, но это не было основной целью демонстрации. Мы просто оставили на ночь считаться, и вернулись к задаче на следующий день. Распараллелить цикл на несколько GPU, сохранять результаты в разные HDF5 файлы и потом объединять было бы гораздо быстрее.\u003C\u002Fp\u003E\u003Ch3\u003ETSNE + Кластеризация\u003C\u002Fh3\u003E\u003Ch4\u003EПонижение размерности\u003C\u002Fh4\u003E\u003Cp\u003EКогда мы подготовили данные, у нас получилось два файла с эмбеддингами:\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode\u003E-rw-rw-r-- 1 user user 1.4G Sep 16 12:16 webface_r50_pfc.onnx.0.02-embeddings.h5\n-rw-rw-r-- 1 user user  66G Sep 16 22:31 webface_r50_pfc.onnx.1-embeddings.h5\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EУже упоминалось, что случайную подвыборку делать ужасно долго, поэтому \u003Ccode\u003Ewebface_r50_pfc.onnx.0.02-embeddings.h5\u003C\u002Fcode\u003E – то, что нам надо. Это 2%-я подвыборка из всего датасета, на ней можно проводить анализ, чтобы потом кластеризовать весь оставшийся датасет. Этот размер датасета выбран не случайно: он помещается в GPU (RTX 2080ti) для подсчета TSNE. Если у вас GPU пожирнее, можно увеличить подвыборку, но это не принципиально.\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Esubset_embeddings = h5py.File(\"webface_r50_pfc.onnx.0.02-embeddings.h5\", \"r\")\nprefacen = subset_embeddings[\"prefacen\"][()]\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EВ этом виде данные уже можно отправлять в TSNE (выбор гиперпараметров был произведен вручную):\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Etsne = tsnecuda.TSNE(\n    num_neighbors=1000,\n    perplexity=200, n_iter=4000, learning_rate=2000\n).fit_transform(prefacen)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EПолучаем вот такие двумерные признаки \u003Ccode\u003Etsne\u003C\u002Fcode\u003E из изначальных эмбедднигов (была размерность 512). Кластера визуально отличимы друг от друга, как и хотелось для проведения анализа.\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Двумерные признаки TSNE\" title=\"Двумерные признаки TSNE\" height=\"248\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F574\u002Fadd\u002F453\u002F574add45329c05fd626ed8e585614835.png\" data-width=\"370\"\u002F\u003E\u003Cfigcaption\u003EДвумерные признаки TSNE\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EУже видны намеки на то, что это можно как-то кластеризовать. Прежде чем пойдем дальше, – пара слов о процессе обучения TSNE.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EПодбор гиперпараметров (про них подробнее \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F267041\u002F\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E) оказался исключительно ручным процессом. Не сильно долгий, чтобы быть неэффективным и безысходным, но и не настолько быстрый, чтобы оставить его без внимания. Особенно чувствительными параметрами TSNE оказались те, что показаны в сниппете. Отдельно хочется заметить, что при большой выборке параметр \u003Cstrong\u003Enum_neighbors\u003C\u002Fstrong\u003E пришлось увеличить, без этого все остальные параметры были нечувствительны к изменениям – стабильно давали плохой результат. Потом опытным путем, чуть-чуть увеличив \u003Cstrong\u003Eperplexity\u003C\u002Fstrong\u003E и увеличив количество итераций, получили достаточно многообещающую картинку (видны скопления объектов, кластера!). \u003Cem\u003EВсе найденные параметры специфичны под эту конкретную сетку и данные. Для сетки в NtechLab оптимальными были чуть другие, но идея та же.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Ch4\u003EКластеризация\u003C\u002Fh4\u003E\u003Cp\u003EДля кластеризации напрашивается DBSCAN с его порогом для разделения кластеров по плотности. Про DBSCAN можно почитать \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F322034\u002F\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003EМы немного его адаптировали, чтобы он работал не так долго на таком объеме данных. Исходный DBSCAN работает несколько минут на всей подвыборке, а это слишком долго, чтобы быстро итерироваться и подобрать хорошие гиперпараметры. Идея такая:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eберем подвыборку;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eзапускаем DBSCAN, получаем метки кластеров;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eобучаем KNN на метках кластеров, размечаем все остальное;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eполучаем быструю версию DBSCAN🙂.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EKNNDBSCAN(sklearn.cluster.DBSCAN):\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Eclass KNNDBSCAN(sklearn.cluster.DBSCAN):\n    \"\"\"DBSCAN worked well when I sample down points. But gives no prediction.\n    So I train KNN on top of cluster labels\n    \"\"\"\n    def __init__(self, *args, subset=1, knn_params=None, random_seed=42, **kwargs, ):\n        super().__init__(*args, **kwargs)\n        knn_params = knn_params or dict()\n        self.knn = sklearn.neighbors.KNeighborsClassifier(\n            n_jobs=kwargs.pop(\"n_jobs\", None),\n            **knn_params\n        )\n        self.subset_ = subset\n        self.rng = np.random.RandomState(random_seed)\n    \n    def subset(self, X, y=None):\n        train_idx = np.arange(len(X))\n        self.rng.shuffle(train_idx)\n        train_idx = train_idx[:int(len(X) * self.subset_)]\n        if y is None:\n            return X[train_idx]\n        else:\n            return X[train_idx], y[train_idx]\n\n    def fit(self, X):\n        train_X = self.subset(X)\n        super().fit(train_X)\n        train_labels = self.labels_\n        train_kidx = np.where(train_labels \u003E= 0)\n        self.knn.fit(train_X[train_kidx], train_labels[train_kidx])\n        del self.labels_\n        return self\n    \n    def predict(self, X):\n        return self.knn.predict(X)\n\n    def fit_predict(self, X):\n        return self.fit(X).predict(X)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cblockquote\u003E\u003Cp\u003EПодбор гиперпараметров DBSCAN – еще более долгий процесс, чем TSNE. Подобрать гиперпараметры было непросто, чтобы разбивка на кластеры выглядела визуально хорошо. Если у кого есть идея, как сделать лучше, – велком.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Entsne = (tsne - tsne.mean(0)) \u002F tsne.std(0)\ny = KNNDBSCAN(min_samples=120, subset=0.5, eps=0.05, knn_params=dict(n_neighbors=5)).fit_predict(ntsne)\ndisplay_labels(ntsne, y, slc=slice(None, None, 5), alpha=0.002)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Кластеризованный TSNE\" title=\"Кластеризованный TSNE\" height=\"248\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F401\u002F1b3\u002F662\u002F4011b366261e9d2b2c38f512d29a1654.png\" data-width=\"382\"\u002F\u003E\u003Cfigcaption\u003EКластеризованный TSNE\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EПредварительные результаты\u003C\u002Fh4\u003E\u003Cp\u003EДля текущей подвыборки мы можем найти наиболее явные кластеры и посмотреть на фото, которые им соответствуют.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8fb\u002Fdd5\u002Fbe5\u002F8fbdd5be57eb0bece736a655813c5b1b.jpg\" width=\"1914\" height=\"1229\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8fb\u002Fdd5\u002Fbe5\u002F8fbdd5be57eb0bece736a655813c5b1b.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EЕсли присмотреться, то маленькие кластеры (10, 8, 6, 4 и 3) очень репрезентативны. Например, третий – кластер с очками. С маленькими кластерами и связана вся сложность подбора гиперпараметров. Они яркие, но выделить их бывает сложно.\u003C\u002Fp\u003E\u003Ch3\u003EПереносим модель на терабайты\u003C\u002Fh3\u003E\u003Cp\u003EМы получили разметку для наших данных, но у нас осталось 98% данных без этой разметки по кластерам. Для применения модели на практике необходимо все это дело довести до ума. В идеале – иметь ONNX-модель, которая делает все сразу. Это достижимый результат, давайте его реализуем.\u003C\u002Fp\u003E\u003Ch4\u003EДоменная регрессия\u003C\u002Fh4\u003E\u003Cp\u003EКак ни странно, но для применения модели нам будет достаточно обычной линейной регрессии. Обучим ее.\u003C\u002Fp\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Efrom sklearn.linear_model import LogisticRegressionCV\ncluster_model = LogisticRegressionCV(n_jobs=-1, max_iter=1000)\ncluster_model.fit(prefacen, y)\nscore = cluster_model.score(prefacen, y)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cp\u003EВ моем случае score=0.9623, что достаточно неплохо. На нашей практике проблемы наблюдались когда score&lt;0.7, так что 0.96 – достойный результат. ROC AUC (ovo\u002Fovr; weighted\u002Fmacro) больше 0.975, что тоже не вызывает подозрений. Визуальное сравнение тоже в порядке. Идем дальше!\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Визуальное сравнение модели классификации и исходной кластеризации\" title=\"Визуальное сравнение модели классификации и исходной кластеризации\" height=\"319\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F544\u002F545\u002F9ef\u002F5445459ef87a5a76410ee6dcd0707d47.png\" data-width=\"944\"\u002F\u003E\u003Cfigcaption\u003EВизуальное сравнение модели классификации и исходной кластеризации\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКонвертируем в ONNX:\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003Efrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\ninitial_type = [('float_input', FloatTensorType([None, 512]))]\noptions = {id(cluster_model): {'raw_scores': True}}\nonx = convert_sklearn(cluster_model, initial_types=initial_type, options=options)\nwith open(\"cluster_model.webface_r50_pfc.680.onnx\", \"wb\") as f:\n    f.write(onx.SerializeToString())\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Ch3\u003EПрименение модели\u003C\u002Fh3\u003E\u003Cp\u003EИтак, на данном этапе мы обучили модель классификации кластеров по эмбеддингам сетки. Но, чтобы применить это на практике эффективно, нам надо сделать несколько дополнительных шагов. Нерационально иметь две модели, одна из которых зависит от другой. Для инференса лучше сделать одну общую ONNX-модель под капотом, запуская модель кластеризации по эмбеддингам. Приступим.\u003C\u002Fp\u003E\u003Cp\u003EУ нас имеются:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003E\u003Ccode\u003Ecluster_model.webface_r50_pfc.680.onnx\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Ccode\u003Ewebface_r50_pfc.onnx\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EДля манипуляции графами ONNX была использована библиотека \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fscailable\u002Fsclblonnx\"\u003E\u003Cu\u003Esclblonnx\u003C\u002Fu\u003E\u003C\u002Fa\u003E. Она позволяет склеивать графы, подменять входы и выходы, то что нужно.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКод конвертации:\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode class=\"python\"\u003E# load 2 models to merge\n# note that all operations below mutate the input graph\nmodel = so.graph_from_file(\"webface_r50_pfc.onnx\")\ncluster = so.graph_from_file(\"cluster_model.webface_r50_pfc.680.onnx\")\n\n# prepare nodes to extract the correct slice\nnode_slice = onnx.helper.make_node(\n    'Slice',\n    inputs=['680', \"680.start\", \"680.end\", \"680.axes\"],\n    outputs=['680.slice.nd'],\n    name=\"Slice.680\"\n)\nnode_squeeze = onnx.helper.make_node(\n    'Squeeze',\n    inputs=['680.slice.nd'],\n    axes=[2, 3],\n    outputs=['680.slice'],\n    name=\"Squeeze.680\"\n)\n# constants are required to pass to slice parameters, need to be added to the graph\nmodel = so.add_constant(model, \"680.start\", value=np.asarray([3, 3]), data_type=\"INT64\")\nmodel = so.add_constant(model, \"680.end\", value=np.asarray([4, 4]), data_type=\"INT64\")\nmodel = so.add_constant(model, \"680.axes\", value=np.asarray([2, 3]), data_type=\"INT64\")\n# extracting slice from 680 layer\nmodel = so.add_node(model, node_slice)\nmodel = so.add_node(model, node_squeeze)\n# merging\nmodel12 = so.merge(model, cluster, io_match=[(\"680.slice\", \"float_input\")], complete=False)\n# fix weird shape warning, complained on shape 1 output\nout0 = onnx.helper.ValueInfoProto()\nout0.name = model12.output[0].name\nmodel12.output.remove(model12.output[0])\nmodel12.output.insert(0, out0)\n# saving\nso.graph_to_file(model12, \"webface_r50_pfc+cluster.onnx\")\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EТеперь можно запускать модель на новых данных и получать метки кластеров. К примеру, третий кластер с очками уже из исходного датасета, где большей части не было в обучении модели кластеризации:\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F24a\u002F8ae\u002Fa40\u002F24a8aea404f6074f204d9499528836a5.jpg\" alt=\"Третий кластер с очками\" title=\"Третий кластер с очками\" width=\"1131\" height=\"1105\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F24a\u002F8ae\u002Fa40\u002F24a8aea404f6074f204d9499528836a5.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EТретий кластер с очками\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EВот так выглядит распределение кластеров в датасете:\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Распределение кластеров в датасете\" title=\"Распределение кластеров в датасете\" height=\"273\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fc14\u002F197\u002F981\u002Fc14197981fdafadad39a8d99cfc01181.png\" data-width=\"386\"\u002F\u003E\u003Cfigcaption\u003EРаспределение кластеров в датасете\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EВыводы\u003C\u002Fh3\u003E\u003Cp\u003EКластеры можно разделить условно на желаемые и нежелаемые. Желаемые кластеры – это, например, пол, где разные кластеры не могут быть одним человеком. Нежелаемые кластеры, наоборот, объединяют людей по признаку, который мы хотим игнорировать. Например, качество снимка, угол съемки, очки, маска.\u003C\u002Fp\u003E\u003Cp\u003EВ исследуемой сетке наблюдается повышенное внимание к очкам, и хочется дальше исследовать это направление в поиске решения связанной адаптации модели к разным доменам (про это писали \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fmailru\u002Fblog\u002F426803\u002F\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003Cp\u003EСхожие результаты анализа на наших данных мы использовали для:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eподбора обучающей выборки для тренировки новой модели;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eфильтрации нежелательных, на наш взгляд, кластеров (картинки с «мусором»).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Ch4\u003EЧто можно было сделать лучше\u003C\u002Fh4\u003E\u003Cp\u003EВ целом результат получился хороший: даже маленькие домены (недостаточно представленные, но отличные от общей массы) выделены, и они репрезентативны. Как всегда, есть нюансы, которым стоило бы уделить больше времени на доработку, полировку:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eразделить получше большой первый кластер, так как там достаточно смешанный домен;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eиспользовать другой алгоритм кластеризации: думаем, OPTICS должен быть более гибким, по сравнению с DBSCAN (реализация в sklearn \u003Ca href=\"https:\u002F\u002Fscikit-learn.org\u002Fstable\u002Fmodules\u002Fgenerated\u002Fsklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS\"\u003E\u003Cu\u003Eздесь\u003C\u002Fu\u003E\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"deep learning"},{"titleHtml":"unsupervised learning"},{"titleHtml":"large scale machine learning"},{"titleHtml":"tsne"},{"titleHtml":"dbscan"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabb\u002F5a7\u002F8b7\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabb\u002F5a7\u002F8b7\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fntechlab\\\u002Fblog\\\u002F584062\\\u002F\"},\"headline\":\"Препарирование нейронок, или TSNE и кластеризация на терабайтах данных\",\"datePublished\":\"2021-10-20T13:10:00+03:00\",\"dateModified\":\"2021-10-20T17:59:47+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Максим\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в N...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fntechlab\\\u002Fblog\\\u002F584062\\\u002F#post-content-body\",\"about\":[\"c_ntechlab\",\"h_python\",\"h_data_mining\",\"h_machine_learning\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F584062\\\u002F0b7d5afa7f82d6c07a747deae6c6c583\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fabb\\\u002F5a7\\\u002F8b7\\\u002Fabb5a78b7905d7b4ba66c2359a3f3d83.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F3d9\\\u002F461\\\u002F850\\\u002F3d9461850b1b54e86f1318d1b6ce54c4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F3e7\\\u002F756\\\u002F2e6\\\u002F3e77562e63290708f83415f8991c7e0f.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F70b\\\u002F1f6\\\u002F056\\\u002F70b1f60562fe0110adaed9d56ba75821.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F431\\\u002F63e\\\u002Fc27\\\u002F43163ec2763e68024ac02478a4378618.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F574\\\u002Fadd\\\u002F453\\\u002F574add45329c05fd626ed8e585614835.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F401\\\u002F1b3\\\u002F662\\\u002F4011b366261e9d2b2c38f512d29a1654.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F8fb\\\u002Fdd5\\\u002Fbe5\\\u002F8fbdd5be57eb0bece736a655813c5b1b.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F544\\\u002F545\\\u002F9ef\\\u002F5445459ef87a5a76410ee6dcd0707d47.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F24a\\\u002F8ae\\\u002Fa40\\\u002F24a8aea404f6074f204d9499528836a5.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fc14\\\u002F197\\\u002F981\\\u002Fc14197981fdafadad39a8d99cfc01181.png\"]}","metaDescription":"У вас продакшн нейронные сети, терабайты данных? Вам хочется понять, как работает нейронная сеть, но на таком объеме это сложно сделать? Сложно, но можно. Мы в NtechLab находимся именно в той...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":""},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"ntechlab":{"alias":"ntechlab","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompany\u002Ff2f\u002F711\u002Fd1e\u002Ff2f711d1e56621060a912a73d2483243.png","titleHtml":"NtechLab","descriptionHtml":null,"relatedData":null,"statistics":{"postsCount":5,"newsCount":0,"vacanciesCount":0,"employeesCount":13,"careerRating":null,"subscribersCount":56,"rating":57.21,"invest":null},"foundationDate":{"year":"2015","month":"10","day":"01"},"location":{"city":{"id":"447159","title":"Москва"},"region":{"id":"1885","title":"Москва и Московская обл."},"country":{"id":"168","title":"Россия"}},"siteUrl":"http:\u002F\u002Fntechlab.ru","staffNumber":"101–200 человек","registrationDate":"2017-02-27T14:06:29+00:00","representativeUser":null,"contacts":[{"title":"Сайт","url":"https:\u002F\u002Ffindface.pro\u002Fru\u002F"},{"title":"Сайт","url":"http:\u002F\u002Fntechlab.ru\u002F"}],"settings":{"analyticsSettings":[],"branding":null,"status":"active"},"metadata":{"titleHtml":"NtechLab, Москва -  с 1 октября 2015 г.","title":"NtechLab, Москва -  с 1 октября 2015 г.","keywords":["Машинное обучение","Обработка изображений","Работа с видео","Анализ и проектирование систем","Тестирование IT-систем"],"descriptionHtml":"5 статей от авторов компании NtechLab","description":"5 статей от авторов компании NtechLab"},"aDeskSettings":null,"careerAlias":"ntechlab","maxCustomTrackerLinks":0}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
