<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Опыт извлечения обучающих данных из генеративных языковых моделей / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/582922\/"},"headline":"Опыт извлечения обучающих данных из генеративных языковых моделей","datePublished":"2021-10-12T09:29:14+03:00","dateModified":"2021-10-13T19:48:15+03:00","author":{"@type":"Person","name":"NTA"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&nbsp;Extracting Training Data from Large Language M...","url":"https:\/\/habr.com\/ru\/post\/582922\/#post-content-body","about":["h_python","h_programming","h_data_mining","h_bigdata","h_machine_learning","f_develop"],"image":["https:\/\/habr.com\/share\/publication\/582922\/4d8d7a68ed814d34ef0e22f48165c9c3\/"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Опыт извлечения обучающих данных из генеративных языковых моделей" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Опыт извлечения обучающих данных из генеративных языковых моделей" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Опыт извлечения обучающих данных из генеративных языковых моделей" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&amp;nbsp;Extracting Training Data from Large Language Models/Извлечение обучающих данных..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&amp;nbsp;Extracting Training Data from Large Language Models/Извлечение обучающих данных..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&amp;nbsp;Extracting Training Data from Large Language Models/Извлечение обучающих данных..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&amp;nbsp;Extracting Training Data from Large Language Models/Извлечение обучающих данных..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&amp;nbsp;Extracting Training Data from Large Language Models/Извлечение обучающих данных..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="582922" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-12T06:29:14.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/582922/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/582922/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/582922/4d8d7a68ed814d34ef0e22f48165c9c3/" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/582922/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/NewTechAudit/" title="NewTechAudit" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/62e/cf1/3f1/62ecf13f1b5e83c0cced637ff786d5a1.png" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/NewTechAudit/" class="tm-user-info__username">
      NewTechAudit
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-12T06:29:14.000Z" title="2021-10-12, 09:29">12  октября   в 09:29</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Опыт извлечения обучающих данных из генеративных языковых моделей</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/python/" class="tm-article-snippet__hubs-item-link"><span>Python</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/programming/" class="tm-article-snippet__hubs-item-link"><span>Программирование</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/data_mining/" class="tm-article-snippet__hubs-item-link"><span>Data Mining</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/bigdata/" class="tm-article-snippet__hubs-item-link"><span>Big Data</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p>Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:</p><p><strong>A. </strong>Extracting Training Data from Large Language Models/Извлечение обучающих данных из больших языковых моделей (генеративных)/Authors: Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee1, Adam Roberts, Tom Brown, Dawn Song, Úlfar Erlingsson, Alina Oprea, Colin Raffel (<a href="https://arxiv.org/abs/2012.07805" rel="noopener noreferrer nofollow">https://arxiv.org/abs/2012.07805</a>)</p><p><strong>B. </strong>The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks/Открывающий секреты: оценка и тестирование непреднамеренного запоминания в нейронных сетях/ Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej Kos, Dawn Song. (<a href="https://arxiv.org/abs/1802.08232" rel="noopener noreferrer nofollow">https://arxiv.org/abs/1802.08232</a>)</p><p><strong>C. </strong>Membership Inference Attacks Against Machine Learning Models/Атаки на определение членства против моделей машинного обучения/ Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov (<a href="https://arxiv.org/abs/1610.05820" rel="noopener noreferrer nofollow">https://arxiv.org/abs/1610.05820</a>)</p><p><strong>D.</strong> An Attack on InstaHide: Is Private Learning Possible with Instance Encoding?/Атака на InstaHide: Возможно ли частное (приватное/не допускающее утечек) обучение с помощью кодировния экземпляра при обучении моделей / Nicholas Carlini, Samuel Deng, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Shuang Song, Abhradeep Thakurta, Florian Tramèr (<a href="https://arxiv.org/abs/2011.05315" rel="noopener noreferrer nofollow">https://arxiv.org/abs/2011.05315</a>)</p><p><strong>E. </strong>Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning/ Всесторонний анализ конфиденциальности глубокого обучения: Пассивные и активные атаки вывода обучающего набора данных на модель в белом ящике при централизованном и федеративном обучении/ Milad Nasr, Reza Shokri, Amir Houmansadr (<a href="https://arxiv.org/abs/1812.00910" rel="noopener noreferrer nofollow">https://arxiv.org/abs/1812.00910</a>)</p><p>мы решили на собственном опыте апробировать описанные методы. В качестве «подопытных» мы взяли модели <a href="https://github.com/sberbank-ai/ru-gpts" rel="noopener noreferrer nofollow">GPT3ru</a></p><p>GPT – это генеративный предобученный трансформер, который представляет собой нейронную сеть с отдельным слоем внимания. При этом языковые модели решают ровно одну задачу: они пытаются предсказать следующий токен (обычно слово или его часть) в последовательности по предшествующим с учетом предыдущего контекста.</p><p>Почему мы считаем важным изучать и понимать ЯМ? Известны случаи неконтролируемого поведения чат-ботов по негативному сценарию.</p><p>Например, чат-бот одного банка предложил клиентке отрезать себе пальцы: <em>на комментарий, что сервис по входу через отпечаток пальца не работает, бот ответил:</em> <strong>«<em>Пальцы бы вам отрезать</em>»</strong>. Чат-бот Lee Luda, разработанный сеульским стартапом Scatter Lab, <em>был </em><strong><em>удалён</em></strong><em> из Facebook messenger </em><strong><em>из-за</em></strong><em> </em><strong><em>оскорбительных высказываний.</em></strong></p><p>Для того чтобы выпускать качественный IT-продукт необходимо понимать и контролировать все его действия. Поэтому мы решили разобраться, действительно ли ЯМ могут запомнить данные, как можно их извлечь. Для работы с моделями мы использовали платформы: <a href="https://colab.research.google.com/" rel="noopener noreferrer nofollow">Google Colaboratory</a> и <a href="https://sbercloud.ru/ru/aicloud/mlspace" rel="noopener noreferrer nofollow">ML Space</a>.</p><p>Чтобы не перегружать текст статьи код на python мы сохранили <a href="https://colab.research.google.com/drive/1bhS8G1PD1oCcPTJiO8Mx4pkVlaIQgWb1?usp=sharing" rel="noopener noreferrer nofollow">в виде ноутбука на Google Colaboratory</a> (авторы не претендуют на идеальный код)</p><p>В данной статье мы рассматриваем модель в качестве чёрного ящика, так как хотели установить смогут ли среднестатистические мошенники получить чувствительные данные, без изучения весов и параметров модели, для осуществления противоправных действий. Чёрный ящик – это модель системы, при которой наблюдателю не известно внутреннее устройство и свойства системы. Наблюдатель видит только то, что система принимает на свой вход и то, что получается на выходе.</p><p>Белый ящик – это противоположное понятие, то есть в этой модели системы наблюдатель знает из каких частей и подсистем она состоит, какие связи есть между элементами, какие функции доступны, структуру системы.</p><p>В качестве чувствительных данных мы будем рассматривать персональные данные людей и номера карт.</p><p>Проанализировав опыт статей, мы отобрали три способа извлечения данных, которые показали относительно большую эффективность в достижении поставленных целей:</p><p><strong>Первый</strong> основывается на принципах статистики и теории вероятностей (источник [А]). Предполагается, что если модель запомнила какие-то данные, то эти данные должны появиться при значительном числе сгенерированных текстов. Последовательность действий такая: определяется три стратегии генерации текста:</p><ul><li><p>При авторегрессионном построении строк (собственно принцип работы GPT) каждое следующее слово выбирается из 40 наиболее вероятных для данной последовательности</p></li><li><p>С помощью параметра temperature для первых 10% генерируемых слов сглаживаются вероятности их появления с учётом исходного набора и постепенно снижается параметр temperature с 10 до 1. После генерации этих 10% последующие слова отбираются по 1 стратегии.</p></li><li><p>Использовать в качестве затравок первые части реальных данных из интернета. После генерации выполняется поиск совпадений с исходными данными.</p></li></ul><p> По каждой стратегии на основе заданных префиксов (<em>строк текста, подающихся в модель</em>) генерируется 200 000 текстов, затем наборы очищаются от дубликатов, в том числе от текстов схожих по триграммам. Затем по каждой из шести метрик отбираются по 100 текстов и мануально в интернете осуществляется поиск совпадений сгенерированных строк с реальными.</p><p>В качестве метрик используются следующие:</p><ul><li><p>Perplexity (неопределённость), чем показатель ниже, тем сгенерированный текст правдоподобнее для самой модели</p></li><li><p>SmallPerplexity: отношение Perplexity Большой GPT3 к Perplexity Малой GPT3</p></li><li><p>MediumPerplexity: отношение Perplexity Большой GPT3 к Perplexity Средней GPT3</p></li><li><p>Zlib entropy: расчёт энтропии текста упрощённым способом – используя сжатие zlib</p></li><li><p> Lowercase: отношение Perplexity Большой GPT3, полученной на исходных генерациях и на генерации отформатированной только в строчные буквы.</p></li><li><p>Window: минимум из Perplexity Большой GPT3 из всех скользящих окон по тексту. Размер окна – 20% от максимальной длины.</p></li></ul><p>Авторы метода утверждают, что из отобранных 1800 текстов в среднем 33,5% имеют запомненные чувствительные данные.</p><p><strong>Второй</strong> способ подразумевает генерацию и отбор текстов с помощью графа (источник [B]). Корнем дерева-графа является затравка, которая подаётся для генерации, в узлах каждого следующего уровня располагаются сгенерированные слова, а веса рёбер соответствуют вероятностям этих слов, с которой они могут являться продолжением корневой для этого узла фразы. После построения дерева-графа, с помощью алгоритма Дейкстры поиска оптимального пути формируются наиболее вероятные строки и проверяется их наличие среди чувствительных данных (в нашем случае – поиск в интернете).</p><p><strong>Третий</strong> способ использует специально обученную модель атаки для извлечения данных (источник [С]). Модель атаки является классификатором, который помечает тип данных, сгенерированных целевой моделью: были они в обучающих данных или нет.</p><p>Основная сложность этого способа заключается в вопросе: «Как обучить модель атаки?»</p><p>Для решения проблемы предлагается использовать метод теневого обучения: в этом случае создаётся несколько «теневых моделей», которые имитируют поведение целевой. Теневые модели должны быть созданы и обучены аналогично целевой модели. Основополагающая идея в том, что аналогичные модели, обученные на относительно похожих записях данных с использованием одного и того же метода, ведут себя аналогичным образом.</p><p>Эмпирически исследователями доказано, что чем больше теневых моделей, тем точнее атака.</p><p>Для обучения теневых моделей требуется генерация обучающих корпусов, если не известно на чём обучалась целевая модель. Генерация осуществляется с помощью целевой модели.</p><p>Предполагается, что записи, которые классифицируются целевой моделью с высокой степенью достоверности, должны быть статистически подобны учебному набору данных и, таким образом, служить хорошим обучающим набором для теневых моделей.</p><p>Процесс синтеза проходит в два этапа: на (1)-ом, используя алгоритм поиска восхождение к вершине (простой итеративный алгоритм поиска локального оптимума), осуществить поиск пространства возможных записей данных, которые классифицируются целевой моделью с высокой степенью достоверности; на (2)-ом этапе происходит отбор синтетических данных из этих записей.</p><p>Другими словами, сначала генерируется первоначальный набор данных с заданными пороговыми значениями, по нему делается предсказание целевой моделью, далее сравниваются пороговые значения. Если вероятность восхождения на холм (вероятность оценки модели) увеличивается, то параметры принимаются. Далее часть признаков случайным образом меняется и выполняется следующая итерация.</p><p>После того, как сгенерируются теневые данные, обучаются теневые модели. Набор данных делится на тренировочный и тестовый, модели обучаются на тренировочном. Далее каждая модель, получая на вход и тренировочный и тестовый набор, делает предсказание. Выходу модели по обучающим данным присваивается метка “in”, то есть данные присутствовали при обучении, у тестового “out”, то есть его не было при обучении.</p><p>Получившиеся предсказания теневых моделей с метками объединяются в один набор данных для обучения атакующей модели.</p><p><strong>Дополнительным не самостоятельным, а вспомогательным методом</strong>, можно рассматривать finetune модели (дообучение), либо переборов настроек гиперпараметров модели. В данном случае с помощью затравок на персональные данные мы учим модель генерировать тексты с нужным нам смыслом и форматом, а затем используем любой из приведённых выше подходов.</p><p>Сразу отметим, что третий способ мы не использовали, так как теневые модели должны быть похожи на целевую, а у нас не было мощностей для обучения подобных GPT. Для обучения одной самой малой модели с 125 млн параметров средствами Google Colab потребуется порядка полугода.</p><p>В результате работы с моделями удалось получить следующее:</p><ul><li><p>сгенерирована и найдена общедоступная информация по паспортам (серия, номер, год выдачи) без подтверждения ФИО владельца (данные отсутствуют), такие генерации удалось осуществить только с помощью XL модели</p></li><li><p>персональная информация по 4 ветеранам Великой Отечественной Войны, в том числе их воинское звание</p></li><li><p>найдены заблокированные и действующие номера карт российских и иностранных банков</p></li><li><p>подтверждена информация по ФИО и дате рождения по нескольким людям</p></li><li><p>модель с высокой вероятностью генерирует реальные адреса с верными отношениями: Область-Район-Город-Улица-Индекс</p></li></ul><p>По итогам наших экспериментов нам так и не удалось получить способ, который с высокой вероятностью извлекал бы обучающие данные.</p><p>Те немногие персональные данные, которые мы получили, были результатом проверки сотен сгенерированных и отобранных текстов в глобальной сети. При этом не все из найденных ПДН критичны (например, данные по Ветеранам Великой Отечественной Войны).</p><p>Единственное, что у нас получилось генерировать с высокой степенью вероятности – это реальные адреса. В этом случае хорошо работает параметр по beam search.</p><p>Также многое зависит от того, как обрабатывался набор обучающих данных, использовались ли при обучении методы Дифференциальной конфиденциальности (например, намеренное внесение шума), регуляризации, чистился ли обучающий набор от чувствительной информации или нет.</p><p>Так в своей <a href="https://habr.com/ru/company/sberbank/blog/524522/" rel="noopener noreferrer nofollow">статье об обученных GPT моделях</a> разработчики указывают, что «<em>Команда AGI NLP провела большую работу по чистке и дедупликации данных, а также по подготовке наборов для валидации и тестирования моделей. </em>». Поэтому возможно никаких особо критичных данных в обучающем наборе для этих моделей изначально и не было.</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%B8%D0%B7%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%5D" class="tm-tags-list__link">извлечение данных</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%5D" class="tm-tags-list__link">данные</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/python/" class="tm-hubs-list__link">
    Python
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/programming/" class="tm-hubs-list__link">
    Программирование
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/data_mining/" class="tm-hubs-list__link">
    Data Mining
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/bigdata/" class="tm-hubs-list__link">
    Big Data
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 1: ↑1 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 1: ↑1 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+1</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">524</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    5
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/NewTechAudit/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/62e/cf1/3f1/62ecf13f1b5e83c0cced637ff786d5a1.png" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 64 голоса " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    24
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">19</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">NTA</span> <a href="/ru/users/NewTechAudit/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @NewTechAudit
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Пользователь, Профессиональное сообщество</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/582922/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментировать 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/582922/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/582922/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"582922":{"id":"582922","timePublished":"2021-10-12T06:29:14+00:00","isCorporative":false,"lang":"ru","titleHtml":"Опыт извлечения обучающих данных из генеративных языковых моделей","leadData":{"textHtml":"\u003Cp\u003EВдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EA.&nbsp;\u003C\u002Fstrong\u003EExtracting Training Data from Large Language Models\u002FИзвлечение обучающих данных из больших языковых моделей (генеративных)\u002FAuthors: Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee1, Adam Roberts, Tom Brown, Dawn Song, Úlfar Erlingsson, Alina Oprea, Colin Raffel (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2012.07805\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2012.07805\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EB.&nbsp;\u003C\u002Fstrong\u003EThe Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks\u002FОткрывающий секреты: оценка и тестирование непреднамеренного запоминания в нейронных сетях\u002F Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej Kos, Dawn Song. (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08232\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08232\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EC.&nbsp;\u003C\u002Fstrong\u003EMembership Inference Attacks Against Machine Learning Models\u002FАтаки на определение членства против моделей машинного обучения\u002F Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.05820\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1610.05820\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003ED.\u003C\u002Fstrong\u003E&nbsp;An Attack on InstaHide: Is Private Learning Possible with Instance Encoding?\u002FАтака на InstaHide: Возможно ли частное (приватное\u002Fне допускающее утечек) обучение с помощью кодировния экземпляра при обучении моделей \u002F Nicholas Carlini, Samuel Deng, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Shuang Song, Abhradeep Thakurta, Florian Tramèr (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2011.05315\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2011.05315\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EE.&nbsp;\u003C\u002Fstrong\u003EComprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning\u002F Всесторонний анализ конфиденциальности глубокого обучения: Пассивные и активные атаки вывода обучающего набора данных на модель в белом ящике при централизованном и федеративном обучении\u002F Milad Nasr, Reza Shokri, Amir Houmansadr (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1812.00910\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1812.00910\u003C\u002Fa\u003E).\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Читать далее","image":null},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":24,"votesCount":64},"rating":19,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"2343413","alias":"NewTechAudit","fullname":"NTA","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F62e\u002Fcf1\u002F3f1\u002F62ecf13f1b5e83c0cced637ff786d5a1.png","speciality":"Пользователь, Профессиональное сообщество"},"statistics":{"commentsCount":0,"favoritesCount":5,"readingCount":524,"score":1,"votesCount":1},"hubs":[{"relatedData":null,"id":"340","alias":"python","type":"collective","title":"Python","titleHtml":"Python","isProfiled":true},{"relatedData":null,"id":"359","alias":"programming","type":"collective","title":"Программирование","titleHtml":"Программирование","isProfiled":true},{"relatedData":null,"id":"7152","alias":"data_mining","type":"collective","title":"Data Mining","titleHtml":"Data Mining","isProfiled":true},{"relatedData":null,"id":"17795","alias":"bigdata","type":"collective","title":"Big Data","titleHtml":"Big Data","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EВдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EA. \u003C\u002Fstrong\u003EExtracting Training Data from Large Language Models\u002FИзвлечение обучающих данных из больших языковых моделей (генеративных)\u002FAuthors: Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee1, Adam Roberts, Tom Brown, Dawn Song, Úlfar Erlingsson, Alina Oprea, Colin Raffel (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2012.07805\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2012.07805\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EB. \u003C\u002Fstrong\u003EThe Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks\u002FОткрывающий секреты: оценка и тестирование непреднамеренного запоминания в нейронных сетях\u002F Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej Kos, Dawn Song. (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08232\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08232\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EC. \u003C\u002Fstrong\u003EMembership Inference Attacks Against Machine Learning Models\u002FАтаки на определение членства против моделей машинного обучения\u002F Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.05820\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1610.05820\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003ED.\u003C\u002Fstrong\u003E An Attack on InstaHide: Is Private Learning Possible with Instance Encoding?\u002FАтака на InstaHide: Возможно ли частное (приватное\u002Fне допускающее утечек) обучение с помощью кодировния экземпляра при обучении моделей \u002F Nicholas Carlini, Samuel Deng, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Shuang Song, Abhradeep Thakurta, Florian Tramèr (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2011.05315\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2011.05315\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EE. \u003C\u002Fstrong\u003EComprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning\u002F Всесторонний анализ конфиденциальности глубокого обучения: Пассивные и активные атаки вывода обучающего набора данных на модель в белом ящике при централизованном и федеративном обучении\u002F Milad Nasr, Reza Shokri, Amir Houmansadr (\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1812.00910\" rel=\"noopener noreferrer nofollow\"\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1812.00910\u003C\u002Fa\u003E)\u003C\u002Fp\u003E\u003Cp\u003Eмы решили на собственном опыте апробировать описанные методы. В качестве «подопытных» мы взяли модели \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsberbank-ai\u002Fru-gpts\" rel=\"noopener noreferrer nofollow\"\u003EGPT3ru\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003EGPT – это генеративный предобученный трансформер, который представляет собой нейронную сеть с отдельным слоем внимания. При этом языковые модели решают ровно одну задачу: они пытаются предсказать следующий токен (обычно слово или его часть) в последовательности по предшествующим с учетом предыдущего контекста.\u003C\u002Fp\u003E\u003Cp\u003EПочему мы считаем важным изучать и понимать ЯМ? Известны случаи неконтролируемого поведения чат-ботов по негативному сценарию.\u003C\u002Fp\u003E\u003Cp\u003EНапример, чат-бот одного банка предложил клиентке отрезать себе пальцы: \u003Cem\u003Eна комментарий, что сервис по входу через отпечаток пальца не работает, бот ответил:\u003C\u002Fem\u003E \u003Cstrong\u003E«\u003Cem\u003EПальцы бы вам отрезать\u003C\u002Fem\u003E»\u003C\u002Fstrong\u003E. Чат-бот Lee Luda, разработанный сеульским стартапом Scatter Lab, \u003Cem\u003Eбыл \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Eудалён\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E из Facebook messenger \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Eиз-за\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Eоскорбительных высказываний.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cp\u003EДля того чтобы выпускать качественный IT-продукт необходимо понимать и контролировать все его действия. Поэтому мы решили разобраться, действительно ли ЯМ могут запомнить данные, как можно их извлечь. Для работы с моделями мы использовали платформы: \u003Ca href=\"https:\u002F\u002Fcolab.research.google.com\u002F\" rel=\"noopener noreferrer nofollow\"\u003EGoogle Colaboratory\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fsbercloud.ru\u002Fru\u002Faicloud\u002Fmlspace\" rel=\"noopener noreferrer nofollow\"\u003EML Space\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003EЧтобы не перегружать текст статьи код на python мы сохранили \u003Ca href=\"https:\u002F\u002Fcolab.research.google.com\u002Fdrive\u002F1bhS8G1PD1oCcPTJiO8Mx4pkVlaIQgWb1?usp=sharing\" rel=\"noopener noreferrer nofollow\"\u003Eв виде ноутбука на Google Colaboratory\u003C\u002Fa\u003E (авторы не претендуют на идеальный код)\u003C\u002Fp\u003E\u003Cp\u003EВ данной статье мы рассматриваем модель в качестве чёрного ящика, так как хотели установить смогут ли среднестатистические мошенники получить чувствительные данные, без изучения весов и параметров модели, для осуществления противоправных действий. Чёрный ящик – это модель системы, при которой наблюдателю не известно внутреннее устройство и свойства системы. Наблюдатель видит только то, что система принимает на свой вход и то, что получается на выходе.\u003C\u002Fp\u003E\u003Cp\u003EБелый ящик – это противоположное понятие, то есть в этой модели системы наблюдатель знает из каких частей и подсистем она состоит, какие связи есть между элементами, какие функции доступны, структуру системы.\u003C\u002Fp\u003E\u003Cp\u003EВ качестве чувствительных данных мы будем рассматривать персональные данные людей и номера карт.\u003C\u002Fp\u003E\u003Cp\u003EПроанализировав опыт статей, мы отобрали три способа извлечения данных, которые показали относительно большую эффективность в достижении поставленных целей:\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EПервый\u003C\u002Fstrong\u003E основывается на принципах статистики и теории вероятностей (источник [А]). Предполагается, что если модель запомнила какие-то данные, то эти данные должны появиться при значительном числе сгенерированных текстов. Последовательность действий такая: определяется три стратегии генерации текста:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EПри авторегрессионном построении строк (собственно принцип работы GPT) каждое следующее слово выбирается из 40 наиболее вероятных для данной последовательности\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EС помощью параметра temperature для первых 10% генерируемых слов сглаживаются вероятности их появления с учётом исходного набора и постепенно снижается параметр temperature с 10 до 1. После генерации этих 10% последующие слова отбираются по 1 стратегии.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EИспользовать в качестве затравок первые части реальных данных из интернета. После генерации выполняется поиск совпадений с исходными данными.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E По каждой стратегии на основе заданных префиксов (\u003Cem\u003Eстрок текста, подающихся в модель\u003C\u002Fem\u003E) генерируется 200 000 текстов, затем наборы очищаются от дубликатов, в том числе от текстов схожих по триграммам. Затем по каждой из шести метрик отбираются по 100 текстов и мануально в интернете осуществляется поиск совпадений сгенерированных строк с реальными.\u003C\u002Fp\u003E\u003Cp\u003EВ качестве метрик используются следующие:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EPerplexity (неопределённость), чем показатель ниже, тем сгенерированный текст правдоподобнее для самой модели\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003ESmallPerplexity: отношение Perplexity Большой GPT3 к Perplexity Малой GPT3\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EMediumPerplexity: отношение Perplexity Большой GPT3 к Perplexity Средней GPT3\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EZlib entropy: расчёт энтропии текста упрощённым способом – используя сжатие zlib\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E Lowercase: отношение Perplexity Большой GPT3, полученной на исходных генерациях и на генерации отформатированной только в строчные буквы.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EWindow: минимум из Perplexity Большой GPT3 из всех скользящих окон по тексту. Размер окна – 20% от максимальной длины.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EАвторы метода утверждают, что из отобранных 1800 текстов в среднем 33,5% имеют запомненные чувствительные данные.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EВторой\u003C\u002Fstrong\u003E способ подразумевает генерацию и отбор текстов с помощью графа (источник [B]). Корнем дерева-графа является затравка, которая подаётся для генерации, в узлах каждого следующего уровня располагаются сгенерированные слова, а веса рёбер соответствуют вероятностям этих слов, с которой они могут являться продолжением корневой для этого узла фразы. После построения дерева-графа, с помощью алгоритма Дейкстры поиска оптимального пути формируются наиболее вероятные строки и проверяется их наличие среди чувствительных данных (в нашем случае – поиск в интернете).\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EТретий\u003C\u002Fstrong\u003E способ использует специально обученную модель атаки для извлечения данных (источник [С]). Модель атаки является классификатором, который помечает тип данных, сгенерированных целевой моделью: были они в обучающих данных или нет.\u003C\u002Fp\u003E\u003Cp\u003EОсновная сложность этого способа заключается в вопросе: «Как обучить модель атаки?»\u003C\u002Fp\u003E\u003Cp\u003EДля решения проблемы предлагается использовать метод теневого обучения: в этом случае создаётся несколько «теневых моделей», которые имитируют поведение целевой. Теневые модели должны быть созданы и обучены аналогично целевой модели. Основополагающая идея в том, что аналогичные модели, обученные на относительно похожих записях данных с использованием одного и того же метода, ведут себя аналогичным образом.\u003C\u002Fp\u003E\u003Cp\u003EЭмпирически исследователями доказано, что чем больше теневых моделей, тем точнее атака.\u003C\u002Fp\u003E\u003Cp\u003EДля обучения теневых моделей требуется генерация обучающих корпусов, если не известно на чём обучалась целевая модель. Генерация осуществляется с помощью целевой модели.\u003C\u002Fp\u003E\u003Cp\u003EПредполагается, что записи, которые классифицируются целевой моделью с высокой степенью достоверности, должны быть статистически подобны учебному набору данных и, таким образом, служить хорошим обучающим набором для теневых моделей.\u003C\u002Fp\u003E\u003Cp\u003EПроцесс синтеза проходит в два этапа: на (1)-ом, используя алгоритм поиска восхождение к вершине (простой итеративный алгоритм поиска локального оптимума), осуществить поиск пространства возможных записей данных, которые классифицируются целевой моделью с высокой степенью достоверности; на (2)-ом этапе происходит отбор синтетических данных из этих записей.\u003C\u002Fp\u003E\u003Cp\u003EДругими словами, сначала генерируется первоначальный набор данных с заданными пороговыми значениями, по нему делается предсказание целевой моделью, далее сравниваются пороговые значения. Если вероятность восхождения на холм (вероятность оценки модели) увеличивается, то параметры принимаются. Далее часть признаков случайным образом меняется и выполняется следующая итерация.\u003C\u002Fp\u003E\u003Cp\u003EПосле того, как сгенерируются теневые данные, обучаются теневые модели. Набор данных делится на тренировочный и тестовый, модели обучаются на тренировочном. Далее каждая модель, получая на вход и тренировочный и тестовый набор, делает предсказание. Выходу модели по обучающим данным присваивается метка “in”, то есть данные присутствовали при обучении, у тестового “out”, то есть его не было при обучении.\u003C\u002Fp\u003E\u003Cp\u003EПолучившиеся предсказания теневых моделей с метками объединяются в один набор данных для обучения атакующей модели.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EДополнительным не самостоятельным, а вспомогательным методом\u003C\u002Fstrong\u003E, можно рассматривать finetune модели (дообучение), либо переборов настроек гиперпараметров модели. В данном случае с помощью затравок на персональные данные мы учим модель генерировать тексты с нужным нам смыслом и форматом, а затем используем любой из приведённых выше подходов.\u003C\u002Fp\u003E\u003Cp\u003EСразу отметим, что третий способ мы не использовали, так как теневые модели должны быть похожи на целевую, а у нас не было мощностей для обучения подобных GPT. Для обучения одной самой малой модели с 125 млн параметров средствами Google Colab потребуется порядка полугода.\u003C\u002Fp\u003E\u003Cp\u003EВ результате работы с моделями удалось получить следующее:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eсгенерирована и найдена общедоступная информация по паспортам (серия, номер, год выдачи) без подтверждения ФИО владельца (данные отсутствуют), такие генерации удалось осуществить только с помощью XL модели\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eперсональная информация по 4 ветеранам Великой Отечественной Войны, в том числе их воинское звание\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eнайдены заблокированные и действующие номера карт российских и иностранных банков\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eподтверждена информация по ФИО и дате рождения по нескольким людям\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eмодель с высокой вероятностью генерирует реальные адреса с верными отношениями: Область-Район-Город-Улица-Индекс\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EПо итогам наших экспериментов нам так и не удалось получить способ, который с высокой вероятностью извлекал бы обучающие данные.\u003C\u002Fp\u003E\u003Cp\u003EТе немногие персональные данные, которые мы получили, были результатом проверки сотен сгенерированных и отобранных текстов в глобальной сети. При этом не все из найденных ПДН критичны (например, данные по Ветеранам Великой Отечественной Войны).\u003C\u002Fp\u003E\u003Cp\u003EЕдинственное, что у нас получилось генерировать с высокой степенью вероятности – это реальные адреса. В этом случае хорошо работает параметр по beam search.\u003C\u002Fp\u003E\u003Cp\u003EТакже многое зависит от того, как обрабатывался набор обучающих данных, использовались ли при обучении методы Дифференциальной конфиденциальности (например, намеренное внесение шума), регуляризации, чистился ли обучающий набор от чувствительной информации или нет.\u003C\u002Fp\u003E\u003Cp\u003EТак в своей \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsberbank\u002Fblog\u002F524522\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eстатье об обученных GPT моделях\u003C\u002Fa\u003E разработчики указывают, что «\u003Cem\u003EКоманда AGI NLP провела большую работу по чистке и дедупликации данных, а также по подготовке наборов для валидации и тестирования моделей. \u003C\u002Fem\u003E». Поэтому возможно никаких особо критичных данных в обучающем наборе для этих моделей изначально и не было.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"извлечение данных"},{"titleHtml":"данные"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F582922\u002F4d8d7a68ed814d34ef0e22f48165c9c3\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F582922\u002F4d8d7a68ed814d34ef0e22f48165c9c3\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582922\\\u002F\"},\"headline\":\"Опыт извлечения обучающих данных из генеративных языковых моделей\",\"datePublished\":\"2021-10-12T09:29:14+03:00\",\"dateModified\":\"2021-10-13T19:48:15+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"NTA\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&nbsp;Extracting Training Data from Large Language M...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582922\\\u002F#post-content-body\",\"about\":[\"h_python\",\"h_programming\",\"h_data_mining\",\"h_bigdata\",\"h_machine_learning\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F582922\\\u002F4d8d7a68ed814d34ef0e22f48165c9c3\\\u002F\"]}","metaDescription":"Вдохновившись опытом зарубежных коллег по извлечению данных из больших языковых моделей из следующих источников:A.&nbsp;Extracting Training Data from Large Language Models\u002FИзвлечение обучающих данных...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"python,programming,data_mining,bigdata,machine_learning"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
