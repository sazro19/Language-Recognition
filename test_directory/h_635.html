<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Изменить сохранения Spark Часть вторая: реализация партишенера / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/sberbank\/blog\/583018\/"},"headline":"Изменить сохранения Spark Часть вторая: реализация партишенера","datePublished":"2021-10-12T15:04:16+03:00","dateModified":"2021-10-15T11:34:30+03:00","author":{"@type":"Person","name":"Sber"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH\/BigData.Профессиональное сообщество SberProfi DWH\/BigData отвечает за развитие...","url":"https:\/\/habr.com\/ru\/company\/sberbank\/blog\/583018\/#post-content-body","about":["c_sberbank","h_db_admins","h_bigdata","f_develop","f_admin"],"image":["https:\/\/habr.com\/share\/publication\/583018\/1bf72fb4428e347e7a6cc8b4640a1cfc\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/964\/e1d\/99d\/964e1d99d9eebd2740a09ba7ca1be2dd.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/eab\/499\/e37\/eab499e37f38678093879d9be9b058f1.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Изменить сохранения Spark Часть вторая: реализация партишенера" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Изменить сохранения Spark Часть вторая: реализация партишенера" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Изменить сохранения Spark Часть вторая: реализация партишенера" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="583018" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-12T12:04:16.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/583018/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/sberbank/blog/583018/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/getpro/habr/upload_files/a1e/78b/13a/a1e78b13a83819b4dd3ffa494da3700b.jpg" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/583018/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="sberbank" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><div class="tm-company-card__branding tm-company-article__branding tm-company-card__branding_loading"><div class="tm-company-card__branding-placeholder"><!----></div> <img src="//habrastorage.org/getpro/habr/branding/6ac/725/4eb/6ac7254eb269ffa84589b75da04eb5ae.png" width="100%" class="tm-company-card__branding-image"></div></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"><div class="tm-company-card tm-company-article__company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/sberbank/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/company/9db/3c1/ec0/9db3c1ec02265b8bcbfdfb0d23d8b9f2.jpg" width="48" class="tm-entity-image__pic"></div></a> <a href="https://career.habr.com/companies/sberbank-russia" rel="noopener" target="_blank" class="tm-grade tm-company-card__rating"><div class="tm-rating"><div class="tm-rating__header"><svg height="24" width="24" class="tm-svg-img tm-svg-grade__icon"><title>Оценка компании на Хабр Карьере</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#grade"></use></svg> <div class="tm-rating__counter tm-rating__counter_variant-grade">4.07</div></div> <div class="tm-rating__text tm-rating__text_variant-grade">
    Оценка
  </div></div></a> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">229.68</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/sberbank/profile/" class="tm-company-card__name">
        Сбер
      </a> <div class="tm-company-card__description">Больше чем банк</div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/Sber/" title="Sber" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/b1f/595/703/b1f595703fffc92491048ef9b6882dff.png" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/Sber/" class="tm-user-info__username">
      Sber
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-12T12:04:16.000Z" title="2021-10-12, 15:04">12  октября   в 15:04</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Изменить сохранения Spark Часть вторая: реализация партишенера</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/sberbank/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании Сбер</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/db_admins/" class="tm-article-snippet__hubs-item-link"><span>Администрирование баз данных</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/bigdata/" class="tm-article-snippet__hubs-item-link"><span>Big Data</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><em>Автор:</em></strong><em> Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH/BigData.</em></p><p><em>Профессиональное сообщество SberProfi DWH/BigData отвечает за развитие компетенций в таких направлениях, как экосистема Hadoop, Teradata, Oracle DB, GreenPlum, а также BI инструментах Qlik, SAP BO, Tableau и др.</em></p><p>Начну описание партишенера с UML-диаграммы:</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 1. UML-диаграмма классов OrderBucketsPartitioner" title="Рисунок 1. UML-диаграмма классов OrderBucketsPartitioner" height="1061" data-src="https://habrastorage.org/getpro/habr/upload_files/964/e1d/99d/964e1d99d9eebd2740a09ba7ca1be2dd.png" data-width="821"/><figcaption>Рисунок 1. UML-диаграмма классов OrderBucketsPartitioner</figcaption></figure><p>Наверняка вы видели, как Spark разбирает запрос, строит план и выполняет его. Сопоставим эту схему с нашей конкретной реализацией (когда будете знакомиться с реализацией классов, возвращайтесь к этой схеме, чтобы увидеть соответствие):</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 2. Сопоставление схемы обработки запроса и конкретной реализации." title="Рисунок 2. Сопоставление схемы обработки запроса и конкретной реализации." height="192" data-src="https://habrastorage.org/getpro/habr/upload_files/eab/499/e37/eab499e37f38678093879d9be9b058f1.png" data-width="1082"/><figcaption>Рисунок 2. Сопоставление схемы обработки запроса и конкретной реализации.</figcaption></figure><p>Нужен метод, который позволил бы использовать партишенер для любого датафрейма. Пока не будем связываться с SQL (разве кто-то делает dataframe.repartition(...) с помощью SQL?).</p><p>Добавим такой метод в Scala Dataframe API, используя паттерн «Pimp my library».<br/> Для этого создадим новый объект ru.kalininskii.orderbucketing.OrderBucketing. Он будет содержать implicit class с пока единственным методом repartitionWithOrderAndSort:</p><details class="spoiler"><summary>OrderBucketing</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing
 
import org.apache.spark.sql.{Column, DataFrame, PlanHelper}
import org.apache.spark.sql.catalyst.expressions.{Ascending, Expression, SortOrder}
import ru.kalininskii.orderbucketing.plans.logical.RepartitionWithOrderAndSort
 
object OrderBucketing {
 
  implicit class DataFramePartOps(ds: DataFrame) {
    def repartitionWithOrderAndSort(numLines: Int,
                                     numPartitions: Int,
                                     orderColumn: Column,
                                     partitionColumns: Seq[Column],
                                     sortColumns: Seq[Column]): DataFrame = {
      def toSortOrder(col: Column): SortOrder = {
        col.expr match {
          case order: SortOrder => order.copy(direction = Ascending)
          case expr: Expression => SortOrder(expr, Ascending)
          case _ => throw new Exception(s"Can not get order from $col")
        }
      }
 
      val orderExpression = toSortOrder(orderColumn)
      val partitionExpressions = partitionColumns.map(_.expr)
      val sortExpressions = sortColumns.map(toSortOrder)
 
      val logicalPlan = RepartitionWithOrderAndSort(
        orderExpression,
        partitionExpressions,
        sortExpressions,
        numLines,
        numPartitions,
        None,
        ds.queryExecution.logical)
 
      PlanHelper.planToDF(ds.sparkSession, logicalPlan)
    }
  }
 
}</code></pre></div></details><p>Как можно видеть из кода выше, метод принимает аргумент partitionColumns: Seq[Column], в котором поля явного и неявного секционирования объединены. Так и должно быть, партишенер разделяет записи по секциям независимо от их внешнего представления. </p><p>Объект PlanHelper пока что также обойдётся одним методом, planToDF. Этот метод вызывает приватный метод для пакета org.apache.spark.sql, поэтому, чтобы он мог выполняться, объект тоже должен находиться в этом пакете:</p><details class="spoiler"><summary>PlanHelper</summary><div class="spoiler__content"><pre><code>package org.apache.spark.sql
 
import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan
 
object PlanHelper {
 
  def planToDF(spark: SparkSession, logicalPlan: LogicalPlan): DataFrame = {
    Dataset.ofRows(spark, logicalPlan)
  }
}</code></pre></div></details><p>Тип для описания одной секции RDD, а также ключа RDD, который понадобится нам в определённый момент, поместим в package object, чтобы он был доступен всему нашему пакету и не только</p><details class="spoiler"><summary>package object rangebucketing</summary><div class="spoiler__content"><pre><code>package ru.kalininskii
 
import org.apache.spark.sql.catalyst.InternalRow
 
package object rangebucketing {
  type BucketsDistribution = (Int, InternalRow, Either[(InternalRow, Seq[String]), (InternalRow, InternalRow, Int)])
  type OrderAndSortKey = (InternalRow, InternalRow, InternalRow)
}</code></pre></div></details><p>Теперь нужно определить планы, начиная с логического. И в них переопределить метод <em>simpleString</em>, так как иначе он выведет в план весь переданный объект <em>distribution. </em>Логический план для этого репартиционирования будет виден при использовании метода explain, и можно будет убедиться, что он действительно применяется. Кроме того, он встроен в формирование планов выполнения запросов и будет предоставлять информацию о физическом секционировании набора данных в переменной <em>partitioning</em><strong><em>.</em></strong></p><details class="spoiler"><summary>RepartitionWithOrderAndSort</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing.plans.logical
 
import org.apache.spark.sql.catalyst.expressions.{Expression, SortOrder}
import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, RepartitionOperation}
import ru.kalininskii.orderbucketing.BucketsDistribution
import ru.kalininskii.orderbucketing.plans.physical.OrderBucketsPartitioning
 
/**
 * Этот класс разделяет данные по условю уникальных точных значений [[Expression]]
 *
 * @param orderExpression      выражение, по интервалам значений которого будет производиться разделение
 *                             в пределах одного значения [[partitionExpressions]]
 * @param partitionExpressions выражения, по значениям которых будет производиться разделение.
 * @param sortExpressions      выражения, по значениям которых будет производиться локальная сортировка.
 * @param numLines             количество записей в одной секции RDD (и в записанном файле)
 * @param numPartitions        предполагаемое количество секций, может отличаться
 * @param distribution         информация об имеющемся распределении, которое надо воспроизвести
 * @param child                план получения набора данных, который нужно секционировать
 */
case class RepartitionWithOrderAndSort(
                                        orderExpression: SortOrder,
                                        partitionExpressions: Seq[Expression],
                                        sortExpressions: Seq[SortOrder],
                                        numLines: Int,
                                        numPartitions: Int,
                                        distribution: Option[Seq[BucketsDistribution]],
                                        child: LogicalPlan
                                      ) extends RepartitionOperation {
 
  override def nodeName: String = s"Repartition plan with " +
    s"${distribution.map(_ => "predefined").getOrElse("unknown")} distribution:"
 
  override def simpleString: String = {
    s"$nodeName ${partitionExpressions.mkString("partition by [", ", ", "], ")}" +
      s"global order by ${orderExpression.child}, " +
      s"${sortExpressions.map(_.child).mkString("local sort by [", ", ", "], ")}" +
      numLines + " rows per task, " + numPartitions + " initial tasks"
  }
 
  val partitioning: OrderBucketsPartitioning = OrderBucketsPartitioning(
    orderExpression, partitionExpressions, sortExpressions, numLines, numPartitions, distribution)
 
  override def maxRows: Option[Long] = child.maxRows
 
  override def shuffle: Boolean = true
}</code></pre></div></details><p>Класс <em>Partitioning </em>и его расширения в структуре пакетов Spark относятся к физическим планам (<em>org.apache.spark.sql.catalyst.plans.physical</em>), но скорее представляют собой контейнеры для характеристик конкретного датафрейма.</p><p>Все встроенные реализации создаются кейс классом (см. Термины и определения) <em>org.apache.spark.sql.catalyst.plans.logical.RepartitionByExpression, </em>получая значения полей, переданных в указанный кейс класс.</p><p>И в нашем случае, <em>OrderBucketsPartitioning</em> можно считать описанием операции над таблицей, прочитанной из файловой системы или объектного хранилища. Не будет ошибкой отнести класс к логическому плану, ведь метод <em>dataframe.explain(true)</em> именно его выводит в каждом дереве логического плана).</p><p>В реализации есть неприятный момент: трейт (см. Термины и определения) <em>Distribution   </em>в исходном коде Spark объявлен как <em>sealed</em>, а значит не может быть расширен. Поэтому в методе <em>satisfies0</em> я буду использовать <em>OrderedDistribution</em>, хотя она не лучшим образом подходит для описания полученного распределения.</p><details class="spoiler"><summary>OrderBucketsPartitioning</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing.plans.physical
 
import org.apache.spark.sql.catalyst.expressions.{Expression, SortOrder, Unevaluable}
import org.apache.spark.sql.catalyst.plans.physical.{Distribution, OrderedDistribution, Partitioning}
import org.apache.spark.sql.types.{DataType, IntegerType}
import ru.kalininskii.orderbucketing.BucketsDistribution
 
/**
 * Этот класс передаёт данные для партиционирования по диапазонам в пределах партиций
 *
 * @param orderExpression      выражение, по интервалам значений которого будет производиться разделение
 *                             в пределах одного значения [[partitionExpressions]]
 * @param partitionExpressions выражения, по значениям которых будет производиться разделение
 * @param sortExpressions      выражения, по значениям которых будет производиться локальная сортировка
 * @param numLines             количество записей в одной секции RDD (и в записанном файле)
 * @param numPartitions        предполагаемое количество секций, может отличаться
 * @param distribution         информация об имеющемся распределении, которое надо воспроизвести
 */
case class OrderBucketsPartitioning(
                                     orderExpression: SortOrder,
                                     partitionExpressions: Seq[Expression],
                                     sortExpressions: Seq[SortOrder],
                                     numLines: Int,
                                     numPartitions: Int,
                                     distribution: Option[Seq[BucketsDistribution]])
 
  extends Expression with Partitioning with Unevaluable {
 
  override def nodeName: String = s"Repartition with " +
    s"${distribution.map(_ => "predefined").getOrElse("unknown")} distribution:"
 
  override def simpleString: String = {
    s"$nodeName ${partitionExpressions.mkString("partition by [", ", ", "], ")}" +
      s"global order by ${orderExpression.child}, " +
      s"${sortExpressions.map(_.child).mkString("local sort by [", ", ", "], ")}" +
      numLines + " rows per task, " + numPartitions + " initial tasks"
  }
 
  override def children: Seq[Expression] = partitionExpressions :+ orderExpression
 
  override def nullable: Boolean = false
 
  override def dataType: DataType = IntegerType
 
  override def satisfies0(required: Distribution): Boolean = {
    super.satisfies0(required) || {
      required match {
        case o: OrderedDistribution =>
          orderExpression.semanticEquals(o.ordering.head)
        case _ => false
      }
    }
  }
}</code></pre></div></details><p>Далее два основных класса, <em>org.apache.spark.sql.execution.exchange.ShuffleExchangeOrderExec </em>и <em>org.apache.spark.sql.partitioning.OrderBucketsPartitioner</em>. Они используют методы с ограниченной видимостью, поэтому должны находиться в пределах пакета org.apache.spark.sql. Эти классы выполняют трансформации RDD, относятся к планам выполнения.</p><p>Основное <em>отличие org.apache.spark.sql.execution.exchange.ShuffleExchangeOrderExec</em> от оригинала заключается в том, что для семплирования используется RDD, в котором <em>MutablePair</em> использует обе части:</p><ul><li><p>первую - для значений полей секционирования ([P]);</p></li><li><p>вторую - для значения поля упорядочивания ([O]).</p></li></ul><p>С моей точки зрения, это уменьшит объём данных для дальнейшей обработки и позволит использовать полученные структуры для других наборов данных. Полученные структуры в любом случае должны быть переданы на драйвер, а затем переданы исполнителям (так работает broadcast), поэтому разумно с самого начала уменьшать их, насколько это возможно.</p><details class="spoiler"><summary>ShuffleExchangeOrderExec</summary><div class="spoiler__content"><pre><code>package org.apache.spark.sql.execution.exchange
 
import org.apache.spark._
import org.apache.spark.rdd.RDD
import org.apache.spark.serializer.Serializer
import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.catalyst.errors._
import org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering
import org.apache.spark.sql.catalyst.expressions.{Attribute, UnsafeProjection}
import org.apache.spark.sql.catalyst.plans.physical._
import org.apache.spark.sql.execution._
import org.apache.spark.sql.execution.metric.{SQLMetric, SQLMetrics}
import org.apache.spark.sql.partitioning.OrderBucketsPartitioner
import org.apache.spark.util.MutablePair
import ru.kalininskii.orderbucketing.OrderAndSortKey
import ru.kalininskii.orderbucketing.plans.physical.OrderBucketsPartitioning
 
import scala.reflect.ClassTag
 
/**
 * Выполняет shuffle, который описывается newPartitioning
 * Код частично заимствован из [[ShuffleExchangeExec]]
 */
case class ShuffleExchangeOrderExec(newPartitioning: OrderBucketsPartitioning,
                                    child: SparkPlan,
                                    partitioner: Option[Partitioner] = None) extends Exchange {
 
  override lazy val metrics: Map[String, SQLMetric] = Map(
    "dataSize" -> SQLMetrics.createSizeMetric(sparkContext, "data size"))
 
  override def nodeName: String = "ExchangeWithOrder"
 
  override def outputPartitioning: Partitioning = newPartitioning
 
  private val serializer: Serializer = SparkEnv.get
    .serializerManager.getSerializer(implicitly[ClassTag[OrderAndSortKey]],
    implicitly[ClassTag[InternalRow]])
 
  override protected def doPrepare(): Unit = {}
 
  /**
   * Возвращает зависимость RDD [[ShuffleDependency]], которая перемешает записи
   * по схеме, определенной в `newPartitioning`. Партиции RDD, свзязанные с
   * возвращенной ShuffleDependency будут входными данными для shuffle.
   */
  private[exchange] def prepareShuffleDependency()
  : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow] = {
    val rdd = child.execute()
 
    val part: Partitioner = partitioner
      .getOrElse(ShuffleExchangeOrderExec.preparePartitioner(rdd, child.output, newPartitioning))
 
    ShuffleExchangeOrderExec.prepareShuffleDependency(rdd, child.output, newPartitioning, serializer, part)
  }
 
  /**
   * Возвращает [[ShuffledOrderRDD]], а это и есть набор данных после перемешивания.
   * [[ShuffledOrderRDD]], как и прочие наследники ShuffledRDD, основан на переданной [[ShuffleDependency]]
   */
  private[exchange] def preparePostShuffleRDD(
                                               shuffleDependency
                                               : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow]
                                             ): ShuffledOrderRDD = {
    new ShuffledOrderRDD(shuffleDependency)
  }
 
  /**
   * ShuffledOrderRDD может быть кеширован для переиспользования
   */
  private var cachedShuffleRDD: ShuffledOrderRDD = _
 
  protected override def doExecute(): RDD[InternalRow] = attachTree(this, "execute") {
    // Returns the same ShuffleRowRDD if this plan is used by multiple plans.
    if (cachedShuffleRDD == null) {
      cachedShuffleRDD = preparePostShuffleRDD(prepareShuffleDependency())
    }
    cachedShuffleRDD
  }
 
}
 
 
object ShuffleExchangeOrderExec {
 
  def preparePartitioner(rdd: RDD[InternalRow],
                         outputAttributes: Seq[Attribute],
                         partitioning: OrderBucketsPartitioning): Partitioner = {
    // Internally, ValuesAndRangePartitioner runs a job on the RDD that samples keys to compute
    // partition bounds. To get accurate samples, we need to copy the mutable keys.
    val rddForSampling = rdd.mapPartitionsInternal { iter =>
      val projectionPart = UnsafeProjection.create(partitioning.partitionExpressions, outputAttributes)
      val projectionOrder = UnsafeProjection.create(partitioning.orderExpression.child :: Nil, outputAttributes)
      val mutablePair = new MutablePair[InternalRow, InternalRow]()
      iter.map(row => mutablePair.update(projectionPart(row).copy(), projectionOrder(row).copy()))
    }
    implicit val ordering: LazilyGeneratedOrdering =
      new LazilyGeneratedOrdering(Seq(partitioning.orderExpression),
        outputAttributes.filter(_.references equals partitioning.orderExpression.child.references))
 
    new OrderBucketsPartitioner(
      rddForSampling,
      partitioning.numLines,
      partitioning.numPartitions,
      partitioning.distribution)
  }
 
  private def getPartitionKeyExtractor(outputAttributes: Seq[Attribute],
                                       partitioning: OrderBucketsPartitioning,
                                       i: Int): InternalRow => OrderAndSortKey = {
    val projectionPart = UnsafeProjection.create(partitioning.partitionExpressions, outputAttributes)
    val projectionOrder = UnsafeProjection.create(partitioning.orderExpression.child :: Nil, outputAttributes)
    val projectionSort = UnsafeProjection.create(partitioning.sortExpressions.map(_.child), outputAttributes)
    row => (projectionPart(row), projectionOrder(row), projectionSort(row).copy())
  }
 
  /**
   * Возвращает зависимость RDD [[ShuffleDependency]], которая перемешает записи
   * по схеме, определенной в `newPartitioning`. Партиции RDD, свзязанные с
   * возвращенной ShuffleDependency будут входными данными для shuffle.
   */
  private def prepareShuffleDependency(rdd: RDD[InternalRow],
                                       outputAttributes: Seq[Attribute],
                                       partitioning: OrderBucketsPartitioning,
                                       serializer: Serializer,
                                       part: Partitioner
                                      )
  : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow] = {
    val rddWithKeys: RDD[Product2[OrderAndSortKey, InternalRow]] = {
      rdd.mapPartitionsWithIndexInternal((i, iter) => {
        val mutablePair = new MutablePair[OrderAndSortKey, InternalRow]()
        val keyGen = getPartitionKeyExtractor(outputAttributes, partitioning, i)
        iter.map { row => mutablePair.update(keyGen(row), row.copy) }
      })
    }
 
    def keyOrdering[A &lt;: Product3[InternalRow, InternalRow, InternalRow]]: Ordering[A] = {
      val allExprs = outputAttributes
        .filter(attr => partitioning.sortExpressions.map(_.child.references).contains(attr.references))
      implicit val sortOrdering: Ordering[InternalRow] =
        new LazilyGeneratedOrdering(partitioning.sortExpressions, allExprs)
      Ordering.by(_._3)
    }
 
    implicit val order: Ordering[OrderAndSortKey] = keyOrdering
 
    // Now, we manually create a ShuffleDependency.
    new ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow](
      rddWithKeys,
      part,
      serializer,
      Some(order)
    )
  }
}</code></pre></div></details><p>Для того, чтобы не менять схему датафрейма и скрыть подробности реализации секционирования и сортировки, используется класс <em>org.apache.spark.sql.execution.exchange.ShuffledOrderRDD</em></p><details class="spoiler"><summary>ShuffledOrderRDD</summary><div class="spoiler__content"><pre><code>package org.apache.spark.sql.execution.exchange
 
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.execution.{CoalescedPartitioner, ShuffledRowRDDPartition}
import org.apache.spark._
import ru.kalininskii.orderbucketing.OrderAndSortKey
 
/**
 * Специализированный класс-наследник [[org.apache.spark.rdd.ShuffledRDD]]
 * Поддерживает локальную сортировку по указанным полям
 */
class ShuffledOrderRDD(var dependency: ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow])
  extends RDD[InternalRow](dependency.rdd.context, Nil) {
 
  private[this] val numPreShufflePartitions = dependency.partitioner.numPartitions
 
  private[this] val partitionStartIndices: Array[Int] = (0 until numPreShufflePartitions).toArray
 
  private[this] val part: Partitioner =
    new CoalescedPartitioner(dependency.partitioner, partitionStartIndices)
 
  override def getDependencies: Seq[Dependency[_]] = List(dependency)
 
  override val partitioner: Option[Partitioner] = Some(part)
 
  override def getPartitions: Array[Partition] = {
    assert(partitionStartIndices.length == part.numPartitions)
    Array.tabulate[Partition](partitionStartIndices.length) { i =>
      val startIndex = partitionStartIndices(i)
      val endIndex =
        if (i &lt; partitionStartIndices.length - 1) {
          partitionStartIndices(i + 1)
        } else {
          numPreShufflePartitions
        }
      new ShuffledRowRDDPartition(i, startIndex, endIndex)
    }
  }
 
  override def getPreferredLocations(partition: Partition): Seq[String] = {
    val tracker = SparkEnv.get.mapOutputTracker.asInstanceOf[MapOutputTrackerMaster]
    val dep = dependencies.head.asInstanceOf[ShuffleDependency[_, _, _]]
    tracker.getPreferredLocationsForShuffle(dep, partition.index)
  }
 
  override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = {
    val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition]
    // The range of pre-shuffle partitions that we are fetching at here is
    // [startPreShufflePartitionIndex, endPreShufflePartitionIndex - 1].
    val reader =
    SparkEnv.get.shuffleManager.getReader(
      dependency.shuffleHandle,
      shuffledRowPartition.startPreShufflePartitionIndex,
      shuffledRowPartition.endPreShufflePartitionIndex,
      context)
    reader.read().asInstanceOf[Iterator[Product2[OrderAndSortKey, InternalRow]]].map(_._2)
  }
 
  override def clearDependencies() {
    super.clearDependencies()
    dependency = null
  }
}</code></pre></div></details><p>И вот, долгожданный класс, который будет определять границы и отыскивать номер партиции RDD.</p><p>Основным полем в нём является <strong>private</strong> <strong>var</strong> <em>rangeBounds</em>: Map[P, (Array[O], Int)].<br/> Это карта, ключом которой является InternalRow со значениями полей секционирования, а значением – кортеж из массива верхних границ партиций RDD (тоже InternalRow, но с другим содержимым) и стартового номера партиции для секции (в дальнейшем может называться "смещение").</p><p>Сэмплинг производится стандартным способом (RDD.sample), поэтому может упускать значения из маленьких партиций. Напомню, что класс создавался для обработки больших объемов данных, поэтому может неэффективно работать на нескольких десятках или сотнях строк.</p><p>Отбор границ также производится в RDD, при этом количество партиций RDD для каждой секции, явной или неявной, определяется динамически на основании собранной информации о количестве строк в сэмпле.</p><p>После получения всех отобранных границ, на драйвере выполняется алгоритм со следующими инвариантами:</p><ol><li><p>Нулевая партиция резервируется для не вошедших в статистику ключей (секций Hive и неявных секций). В случаях, когда нулевая партиция получает слишком большой объём данных, измените поля явного и неявного секционирования или откажитесь от них полностью;</p></li><li><p>Значения явных и неявных секций могут следовать в неотсортированном порядке, но этот порядок должен был зафиксирован с использованием переменной "смещения". Смещение - это значение типа Int, оно входит в кортежMap[P, (Array[O], <em>Int</em>)];</p></li><li><p>Стартовый номер секции – смещение, начинается с одного (см. п.1 – нулевая партиция зарезервирована, и для каждого следующего ключа прирастает на количество границ + 1, что соответствует реальному количеству партиций для секции (см. п.4);</p></li><li><p>Массив значений поля упорядочивания не содержит самой последней верхней границы, это логично, чтобы не создавать всегда пустую дополнительную секцию.</p></li></ol><p>Поиск партиции осуществляется сначала по ключу карты (конкретное значение всех полей секционирования), затем в массиве значений, последовательным или двоичным поиском, в зависимости от длины массива. Все записи, для которых ключ отсутствует в карте, отправляются в нулевую партицию RDD, что может привести к неприемлемо большому объёму этой партиции, если поля явного или неявного партиционирования выбраны неудачно и имеют слишком высокую селективность. В этом случае лучше не секционировать таблицу вообще, оставив только разделение на бакеты по полю упорядочивания.</p><p>Выбор границы одной партиции RDD, начиная с прототипа, осуществляется так: значения меньше либо равные верхней границе (она, как мы помним, определена заранее и известна), и больше, чем предыдущая верхняя граница, или предыдущая верхняя граница отсутствует (это первый файл в явной или неявной секции).</p><p>Я знаком с концепцией интервального секционирования в Oracle, и между этими двумя реализациями есть отличие в строгости неравенств. В Oracle секции определяются по условию «меньше конкретного значения» и неявному условию «больше или равно предыдущего конкретного значения».</p><p>Это связано с тем, что секционирование Oracle работает с конкретными интервалами: для времени это чаще всего сутки, для числовых значений – миллионы или миллиарды и так далее.</p><p>Поэтому очень удобно, к примеру, что можно указать для разделения по суткам: values less than ‘2021-12-01 00:00:00’ – при этом видно, что в новую партицию попадёт начало суток (и месяца), а сколь угодно близкое, но меньшее значение будет в партиции, относящейся к ‘2021-11-30’.</p><p>В нашем случае дело совсем в другом: пользователь ничего не должен знать об интервалах и файлах, его интересуют только конкретные данные и это задача явного секционирования (первый уровень).</p><p>Таким образом, задача разделения интервалов значений – обеспечить примерно равный размер файлов, лёгкость нахождения нужных файлов и совершенно прозрачное взаимодействие, если пользователь обращается напрямую к традиционным структурам. Поэтому границы интервалов определяются «на лету», хранятся в отдельной структуре и сопоставлены с физическими файлами. Каждая секция имеет свой индивидуальный набор границ. Кроме того, укажем на достаточно важный момент: если одну из границ, в нашем случае, верхнюю, мы определяем явно, то другая, нижняя граница не очень важна, но лучше, чтобы её можно было легко найти, если в дальнейшем она будет отсутствовать в карте данных. Для нижней границы это действительно так, потому что значение нужно прочитать из начала файла или из начала сегмента данных, в случае колоночного формата хранения.</p><details class="spoiler"><summary>OrderBucketsPartitioner</summary><div class="spoiler__content"><pre><code>package org.apache.spark.sql.partitioning
 
import java.io.{IOException, ObjectInputStream, ObjectOutputStream}
 
import org.apache.spark.{Partitioner, SparkEnv}
import org.apache.spark.rdd.RDD
import org.apache.spark.serializer.JavaSerializer
import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.util.{CollectionsUtils, Utils}
 
import scala.collection.mutable.ArrayBuffer
import scala.reflect.ClassTag
import scala.util.hashing.byteswap32
 
/**
 * Наследник [[org.apache.spark.Partitioner]] который разделяет по точным значениям некоторых выражений (полей).
 * И интервалов значений одного выражения (поля)
 *
 * @note The actual number of partitions created by the RangePartitioner might not be the same
 *       as the `partitions` parameter, in the case where the number of sampled records is less than
 *       the value of `partitions`.
 */
class OrderBucketsPartitioner[P: ClassTag, O: Ordering : ClassTag
](rdd: RDD[_ &lt;: Product2[P, O]],
  val numLines: Int,
  val partitions: Int,
  val distribution: Option[Seq[(Int, P, Either[(O, Seq[String]), (O, O, Int)])]])
  extends Partitioner {
 
  // We allow partitions = 0, which happens when sorting an empty RDD under the default settings.
  require(partitions >= 0, s"Number of partitions cannot be negative but found $partitions.")
 
  private var ordering = implicitly[Ordering[O]]
 
  private def getDistribution: Option[Map[P, (Array[O], Int)]] = distribution flatMap {
    case Seq() => None
    case distr =>
      val (inner, outer) = distr.partition(_._3.isLeft)
 
      //внешние границы из распределения.
      val (singleFileBounds, manyFileBounds): (Seq[(P, (Int, (O, O, Int)))], Seq[(P, (Int, (O, O, Int)))]) =
        outer
          .map { case (index, p, right) => (p, (index, right.right.get)) }
          .partition { case (_, (_, (_, _, filesNum))) => filesNum == 1 }
      //Нужно определить внутренние границы, только для тех, где больше одного файла
      val outerBounds: Map[P, Seq[(Int, (O, O, Int))]] = manyFileBounds
        .groupBy(_._1)
        .map { case (p, values) => p -> values.map(bounds => bounds._2) }
      // границы единичных файлов уже определены
      val singleBounds: Array[(P, Array[(Int, Array[O])])] = singleFileBounds
        .groupBy(_._1)
        .map { case (p, values) =>
          (p, values.map(bounds => (bounds._2._1, Array(bounds._2._2._2))).toArray) }
        .toArray
 
      //внутренние границы получаются из rdd фильтром, сэмплированием, обработкой
      val innerBounds: Array[(P, Array[(Int, Array[O])])] =
        OrderBucketsPartitioner.getInnerBounds(rdd, numLines, partitions, outerBounds)
 
      //заранее определённые внутренние границы
      val givenBounds: Array[(P, Array[(Int, Array[O])])] = inner
        .map { case (index, p, left) => (p, (index, Array(left.left.get._1))) }
        .groupBy(_._1)
        .map { case (p, values) => p -> values.map(bounds => bounds._2).toArray }
        .toArray
 
      //теперь оба массива склеиваются, группируются, получаем все границы,
      // отсортированные по возрастанию, без самой верхней,
      val fixedBounds: Map[P, (Array[O], Int)] = (givenBounds ++ innerBounds ++ singleBounds)
        .groupBy(_._1)
        .map { case (p, values) =>
          val (indexes, bounds) = values.flatMap(_._2).unzip
          p -> (bounds.flatten.sorted.init,
            indexes.min)
        }
 
      Some(fixedBounds)
  }
 
  // Карта с массивами верхних границ для первых (partitions - 1) партиций
  private var rangeBounds: Map[P, (Array[O], Int)] = getDistribution.getOrElse {
    if (partitions &lt;= 1) {
      Map.empty[P, (Array[O], Int)]
    } else {
      val groupedBounds = OrderBucketsPartitioner.getBounds(rdd, numLines, partitions)
 
      //индексы смещений, чтобы обеспечить уникальный номер партиции, если массив границ пустой, то это одна партиция
      val overallIndex = groupedBounds.scanLeft(1) { case (sum, (_, orders)) => sum + math.max(orders.length + 1, 1) }
 
      groupedBounds
        .zip(overallIndex)
        .map { case ((part, orders), index) => (part, (orders, index)) }
        .toMap
    }
  }
 
  def getRangeBounds: Map[P, (Array[O], Int)] = rangeBounds
 
  //весь массив плюс одна нулевая партиция для не попавших в сэмпл тасков
  // партиции, не попавшие в сэмплы должны быть небольшими, поэтому ничего страшного не будет
  // даже если они попадут в один таск, так будет даже лучше - меньше файлов
  def numPartitions: Int = rangeBounds.values.map(_._1.length + 1).sum + 1
 
  private var binarySearch: (Array[O], O) => Int = CollectionsUtils.makeBinarySearch[O]
 
  def getPartition(key: Any): Int = {
    val (p, k, _) = key.asInstanceOf[(P, O, InternalRow)]
    val (bounds, shift) = rangeBounds.getOrElse(p, (Array.empty[O], 0))
    var partition = 0
    if (bounds.length &lt; 16) {
      // If we have less than 16 partitions naive search
      while (partition &lt; bounds.length &amp;&amp; ordering.gt(k, bounds(partition))) {
        partition += 1
      }
    } else {
      // метод бинарного поиска определён только один раз
      partition = binarySearch(bounds, k)
      // binarySearch either returns the match location or -[insertion point]-1
      if (partition &lt; 0) {
        partition = -partition - 1
      }
      if (partition > bounds.length) {
        partition = bounds.length
      }
    }
    shift + partition
  }
 
  override def equals(other: Any): Boolean = other match {
    case r: OrderBucketsPartitioner[_, _] =>
      r.rangeBounds == rangeBounds
    case _ =>
      false
  }
 
  override def hashCode(): Int = {
    val prime = 31
    var result = 1
    var i = 0
    val arr = rangeBounds.values.map(_._1).toArray.flatten
    while (i &lt; arr.length) {
      result = prime * result + arr(i).hashCode()
      i += 1
    }
    result = prime * result
    result
  }
 
  @throws(classOf[IOException])
  private def writeObject(out: ObjectOutputStream): Unit = Utils.tryOrIOException {
    val sfactory = SparkEnv.get.serializer
    sfactory match {
      case _: JavaSerializer => out.defaultWriteObject()
      case _ =>
        out.writeObject(ordering)
        out.writeObject(binarySearch)
 
        val ser = sfactory.newInstance()
        Utils.serializeViaNestedStream(out, ser) { stream =>
          stream.writeObject(scala.reflect.classTag[Map[P, (Array[O], Int)]])
          stream.writeObject(rangeBounds)
        }
    }
  }
 
  @throws(classOf[IOException])
  private def readObject(in: ObjectInputStream): Unit = Utils.tryOrIOException {
    val sfactory = SparkEnv.get.serializer
    sfactory match {
      case _: JavaSerializer => in.defaultReadObject()
      case _ =>
        ordering = in.readObject().asInstanceOf[Ordering[O]]
        binarySearch = in.readObject().asInstanceOf[(Array[O], O) => Int]
 
        val ser = sfactory.newInstance()
        Utils.deserializeViaNestedStream(in, ser) { ds =>
          implicit val classTag: ClassTag[Map[P, (Array[O], Int)]] = ds.readObject[ClassTag[Map[P, (Array[O], Int)]]]()
          rangeBounds = ds.readObject[Map[P, (Array[O], Int)]]()
        }
    }
  }
}
 
object OrderBucketsPartitioner {
 
  /**
   * Рассчитывает коэффициент сэмлирования используя обратную логарифмическую пропорцию,
   * чем больше набор данных, тем меньше часть, которая будет взята из него
   *
   * @param numLines - количество записей в файле - опасное предположение, но сделать его можно
   * @param numParts - приблизительно оцененное количество партиций
   */
  private def getSampleCoefficient(numLines: Int, numParts: Int): Double = {
    val numLinesD = numLines.toDouble
    (1e4 / (numLinesD * math.log(numLinesD * numParts))) min 1.0
  }
 
  /**
   * возвращаяет сэмпл RDD
   *
   * @param rdd               - основной набор данных
   * @param sampleCoefficient - 0 &lt; коэффициент &lt;= 1.0
   */
  private def getSampleRDD[O: Ordering : ClassTag,
    P: ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],
                 sampleCoefficient: Double): RDD[_ &lt;: Product2[P, O]] = {
    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = if (sampleCoefficient &lt; 1.0) {
      val seed = byteswap32(-rdd.id - 1)
      rdd.sample(withReplacement = false, sampleCoefficient, seed)
    } else {
      rdd
    }
    sampledRdd
  }
 
  /**
   * выполняется в каждой партиции сэмлпа RDD
   * получает верхние границы для каждого файла (таска, партиции RDD)
   *
   * @param iter     неотсортированный итератор со значениями партиций и поля упорядочивания
   * @param initStep шаг, равный желаемому количеству записей в одном файле
   * @param weight   количество реальных записей на строку сэмпла
   * @return границы
   */
  private def determineBoundsWithinPartition[P: ClassTag, O: Ordering : ClassTag
  ](iter: Iterator[(P, O)],
    weight: Double,
    initStep: Int): Iterator[(P, Array[O])] = {
    prepareMap(iter)
      .map { case (p, ordered) =>
        val partitions: Int = math.ceil(ordered.length * weight / initStep).intValue()
        val bounds: Array[O] = extractBounds(ordered, partitions, weight)
        (p, bounds)
      }.iterator
  }
 
  private def prepareMap[O: Ordering : ClassTag, P: ClassTag](iter: Iterator[(P, O)]): Map[P, Array[O]] = {
    val mappedParts = iter.toArray
      .groupBy(_._1)
      .map { case (p, opArray) => (p, opArray.map(_._2).sorted) }
    mappedParts
  }
 
  //отбор самих значений
  private def extractBounds[O: Ordering : ClassTag](values: Array[O],
                                                    partitions: Int,
                                                    weight: Double)(implicit ordering: Ordering[O]): Array[O] = {
    val numCandidates = values.length
    val partCount = numCandidates * weight
    var cumWeight = 0.0
    val step: Int = (partCount / partitions).intValue()
    var target = step
    val innerBounds = ArrayBuffer.empty[O]
    var i = 0
    var j = 0
    var prevInnerBound = Option.empty[O]
 
    while ((i &lt; numCandidates) &amp;&amp; (j &lt; partitions - 1)) {
      val key = values(i)
      cumWeight += weight
      if (cumWeight >= target) {
        // Skip duplicate values.
        if (prevInnerBound.isEmpty || ordering.gt(key, prevInnerBound.get)) {
          innerBounds += key
          target += step
          j += 1
          prevInnerBound = Some(key)
        }
      }
      i += 1
    }
    innerBounds.toArray
  }
 
  /**
   * сэмплирует RDD и получает карту, где ключи - значения полей партиционирования,
   * значения - массивы с верхними границами поля упорядочивания
   *
   * @param rdd      основной набор данных
   * @param numLines желаемое количество записей в одном файле
   * @param numParts предполагаемое количество записей
   * @return границы
   */
  private def getBounds[P: ClassTag, O: Ordering : ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],
                                                             numLines: Int,
                                                             numParts: Int): Array[(P, Array[O])] = {
    val sampleCoefficient = getSampleCoefficient(numLines, numParts) //rdd.partitions.length
 
    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = getSampleRDD(rdd, sampleCoefficient)
 
    val weight = 1.0 / sampleCoefficient
    sampledRdd
      .map(row => (row._1, row._2))
      .partitionBy(new Partitioner {
        override def numPartitions: Int = numParts
 
        override def getPartition(key: Any): Int = Utils.nonNegativeMod(key.hashCode, numParts)
      })
      .mapPartitions(iter => determineBoundsWithinPartition(iter, weight, numLines))
      .collect()
  }
 
 
  /**
   * фильтрует RDD на равенство полей к нужным значениям и по нахождению в пределах внешних границ
   *
   * @param rdd    основной набор данных
   * @param bounds границы RDD
   * @return тщательно отфильтрованный RDD
   */
  private def filterRDDByOuterBounds[P: ClassTag, O: Ordering : ClassTag
  ](rdd: RDD[_ &lt;: Product2[P, O]],
    bounds: Map[P, Seq[(Int, (O, O, Int))]]): RDD[_ &lt;: Product2[P, O]] = {
    val ordering = implicitly[Ordering[O]]
    //получаем Option[Array[Tuple3]] и проверяем exists
    rdd
      .filter { item =>
        bounds
          .get(item._1)
          .exists(_.exists(b => ordering.lteq(b._2._1, item._2) &amp;&amp; ordering.lteq(item._2, b._2._2)))
      }
  }
 
  /**
   * выполняется в каждой партиции сэмлпа RDD
   * получает верхние границы для каждого файла (таска, партиции RDD)
   *
   * @param iter     неотсортированный итератор со значениями партиций и поля упорядочивания
   * @param initStep шаг, равный желаемому количеству записей в одном файле
   * @param weight   количество реальных записей на строку сэмпла
   * @return границы
   */
  private def determineInnerBoundsWithinPartition[P: ClassTag, O: Ordering : ClassTag
  ](iter: Iterator[(P, O)],
    weight: Double,
    initStep: Int,
    outerBounds: Map[P, Seq[(Int, (O, O, Int))]]): Iterator[(P, Array[(Int, Array[O])])] = {
    val ordering = implicitly[Ordering[O]]
 
    prepareMap(iter)
      .map { case (p, orderedValues) =>
        (p, outerBounds(p).toArray.map { case (index, (lowerO, upperO, partitions)) =>
          val ordered = orderedValues
            .dropWhile(ordering.lt(_, lowerO))
            .takeWhile(ordering.lteq(_, upperO))
 
          val innerBounds: Array[O] = extractBounds(ordered, partitions, weight)
 
          (index, innerBounds :+ upperO)
        })
      }.iterator
  }
 
  /**
   * сэмплирует RDD и получает карту, где ключи - значения полей партиционирования,
   * значения - массивы с верхними границами поля упорядочивания
   * Важно, чтобы можно было использовать верхние границы в пределах партиции,
   * чтобы не допустить поглощения возможных внутренних партиций
   *
   * @param rdd      основной набор данных
   * @param numLines желаемое количество записей в одном файле
   * @param numParts предполагаемое количество записей
   * @param bounds   внешние границы RDD
   * @return границы
   */
  private def getInnerBounds[P: ClassTag, O: Ordering : ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],
                                                                  numLines: Int,
                                                                  numParts: Int,
                                                                  bounds: Map[P, Seq[(Int, (O, O, Int))]]
                                                                 ): Array[(P, Array[(Int, Array[O])])] = {
    val sampleCoefficient = getSampleCoefficient(numLines, numParts) //rdd.partitions.length
 
    val filterRdd: RDD[_ &lt;: Product2[P, O]] = filterRDDByOuterBounds(rdd, bounds)
    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = getSampleRDD(filterRdd, sampleCoefficient)
 
    val weight = 1.0 / sampleCoefficient
    sampledRdd
      .map(row => (row._1, row._2))
      .partitionBy(new Partitioner {
        override def numPartitions: Int = numParts
 
        override def getPartition(key: Any): Int = Utils.nonNegativeMod(key.hashCode, bounds.size)
      })
      .mapPartitions(iter => determineInnerBoundsWithinPartition(iter, weight, numLines, bounds))
      .collect()
  }
}</code></pre></div></details><p>Чтобы связать физический план и само выполнение, нам нужно будет создать объект, расширяющий SparkStrategy.</p><details class="spoiler"><summary>RepartitionStrategy</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.rangebucketing.strategy
 
import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan
import org.apache.spark.sql.execution.{SparkPlan, SparkStrategy, exchange}
import ru.kalininskii.rangebucketing.plans.logical.RepartitionByRangeBuckets
 
object RepartitionStrategy extends SparkStrategy {
  override def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match {
    case r: RepartitionByRangeBuckets =>
      exchange.ShuffleExchangeBucketsExec(r.partitioning, planLater(r.child)) :: Nil
    case _ => Nil
  }
}</code></pre></div></details><p>Теперь можно сделать инъекцию расширения в SparkSession:</p><details class="spoiler"><summary>Extension injection</summary><div class="spoiler__content"><pre><code>spark = SparkSession
  .builder()
  .appName("PARTITION_TEST")
  .master("local[*]")
  .config(sparkConf)
  .withExtensions(e => {
    e.injectPlannerStrategy(_ => RepartitionStrategy)
  })
  .getOrCreate()</code></pre></div></details><p>Если инъекции или способа реализации партишенера не будет, то мы увидим такую ошибку:</p><details class="spoiler"><summary>Сообщение об ошибке</summary><div class="spoiler__content"><pre><code>assertion failed: No plan for RepartitionWithOrderAndSort [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24
+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]
   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)
         +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]

java.lang.AssertionError: assertion failed: No plan for RepartitionWithOrderAndSort [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24
+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]
   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)
         +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]

         at scala.Predef$.assert(Predef.scala:170)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:78)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:75)
         at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
         at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
         at scala.collection.Iterator$class.foreach(Iterator.scala:891)
         at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
         at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
         at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:75)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:67)
         at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
         at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
         at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
         at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:72)
         at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:68)
         at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:77)
         at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:77)
         at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
         at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
         at org.apache.spark.sql.execution.QueryExecution.stringOrError(QueryExecution.scala:99)
         at org.apache.spark.sql.execution.QueryExecution.toString(QueryExecution.scala:207)
         at org.apache.spark.sql.execution.command.ExplainCommand.run(commands.scala:167)
         at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)
         at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)
         at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)
         at org.apache.spark.sql.Dataset.explain(Dataset.scala:485)
         at ru.kalininskii.rangebucketing.RangeBucketingPartitionTest$$anonfun$1.apply(RangeBucketingPartitionTest.scala:49)
         at ru.kalininskii.rangebucketing.RangeBucketingPartitionTest$$anonfun$1.apply(RangeBucketingPartitionTest.scala:42)</code></pre></div></details><p><em>Сгенерируем набор данных с псевдослучайными значениями и применим к нему созданный партишенер</em>: </p><details class="spoiler"><summary>Датафрейм</summary><div class="spoiler__content"><pre><code>    val dataFrameSource = getRandomDF(0, rangeLimit, 3, 0).persist()
      .withColumn("ts_part", fn.expr("substring(ts,0,10)"))
 
    dataFrameSource.printSchema()
 
    val dfRep = dataFrameSource
      .repartitionWithOrderAndSort(numLines, rangeLimit / numLines,
        fn.col("event_time"), List(fn.col("ts_part")), List(fn.col("id")))
      .persist()
 
    dfRep.explain(true)</code></pre></div></details><p>В планах выполнения видны новые пункты, на всех этапах их можно отследить</p><details class="spoiler"><summary>План запроса с применением партишенера</summary><div class="spoiler__content"><pre><code>== Parsed Logical Plan ==
'Repartition with unknown distribution: ['ts_part], 'id ASC NULLS FIRST, 4000, 24
+- 'Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, 'substring('ts, 0, 10) AS ts_part#55]
   +- Project [_1#6 AS id#13, _2#7 AS name#14, _3#8 AS amount#15, _4#9 AS value#16, _5#10 AS divider#17, _6#11 AS ts#18]
      +- LocalRelation [_1#6, _2#7, _3#8, _4#9, _5#10, _6#11]

== Analyzed Logical Plan ==
id: int, name: string, amount: decimal(38,18), value: decimal(38,18), divider: string, ts: timestamp, ts_part: string
Repartition with unknown distribution: [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24
+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]
   +- Project [_1#6 AS id#13, _2#7 AS name#14, _3#8 AS amount#15, _4#9 AS value#16, _5#10 AS divider#17, _6#11 AS ts#18]
      +- LocalRelation [_1#6, _2#7, _3#8, _4#9, _5#10, _6#11]

== Optimized Logical Plan ==
InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55], StorageLevel(disk, memory, deserialized, 1 replicas)
   +- ExchangeByRangeBuckets repartition with unknown distribution:(ts_part#55, id#13 ASC NULLS FIRST, 4000, 24, None)
      +- *(1) Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]
         +- InMemoryTableScan [amount#15, divider#17, id#13, name#14, ts#18, value#16]
               +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)
                     +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]

== Physical Plan ==
InMemoryTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55]
   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55], StorageLevel(disk, memory, deserialized, 1 replicas)
         +- ExchangeByRangeBuckets repartition with unknown distribution:(ts_part#55, id#13 ASC NULLS FIRST, 4000, 24, None)
            +- *(1) Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]
               +- InMemoryTableScan [amount#15, divider#17, id#13, name#14, ts#18, value#16]
                     +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)
                           +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]</code></pre></div></details><p>Тесты должны показать, что классы планов на самом деле используются (простые юнит-тесты планов Spark):</p><details class="spoiler"><summary>Использование классов </summary><div class="spoiler__content"><pre><code>    val logicalPlanString = "Repartition plan with unknown distribution: " +
      "partition by ['ts_part], " +
      "global order by 'event_time, " +
      "local sort by ['id], " +
      "4000 rows per task, 24 initial tasks"
 
    val analyzedPlanString = "Repartition plan with unknown distribution: " +
      "partition by [ts_part#64], " +
      "global order by event_time#21, " +
      "local sort by [id#15], " +
      "4000 rows per task, 24 initial tasks"
 
    val sparkPlanString = "ExchangeWithOrder Repartition with unknown distribution: " +
      "partition by [ts_part#64], " +
      "global order by event_time#21, " +
      "local sort by [id#15], " +
      "4000 rows per task, 24 initial tasks"
 
    assert(dfRep.queryExecution.logical.toString contains logicalPlanString)
    assert(dfRep.queryExecution.analyzed.toString contains analyzedPlanString)
    assert(dfRep.queryExecution.sparkPlan.toString contains sparkPlanString)</code></pre></div></details><p>Количество секций всегда будет равно 28</p><details class="spoiler"><summary>Количество партиций RDD</summary><div class="spoiler__content"><pre><code>println(dfRep.rdd.getNumPartitions)
28
dfRep.rdd.getNumPartitions should be(28)</code></pre></div></details><p>Выведем датафрейм с номерами партиций, нулевая партиция должна отсутствовать, потому что не содержит ни одного значения. Количество – колонка «cnt_» - всегда немного меньше и количество достаточно равномерное, отклонение, как правило, остаётся в пределах пяти процентов.</p><details class="spoiler"><summary>Количество записей в партициях RDD</summary><div class="spoiler__content"><pre><code>+----------+-----------+-----------------------+-----------------------+----+
|ts_part   |rdd_part_id|range_min_event_time   |range_max_event_time   |cnt_|
+----------+-----------+-----------------------+-----------------------+----+
|2021-09-05|10         |2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3672|
|2021-09-05|11         |2021-09-05 21:57:56.455|2021-09-05 21:57:56.547|3400|
|2021-09-05|12         |2021-09-05 21:57:56.548|2021-09-05 21:57:56.642|3761|
|2021-09-05|13         |2021-09-05 21:57:56.643|2021-09-06 21:57:56.447|3601|
|2021-09-05|14         |2021-09-06 21:57:56.448|2021-09-06 21:57:56.544|3601|
|2021-09-05|15         |2021-09-06 21:57:56.545|2021-09-06 21:57:56.641|3856|
|2021-09-05|16         |2021-09-06 21:57:56.642|2021-09-07 21:57:56.449|3711|
|2021-09-05|17         |2021-09-07 21:57:56.45 |2021-09-07 21:57:56.549|3703|
|2021-09-05|18         |2021-09-07 21:57:56.55 |2021-09-07 21:57:56.647|3776|
|2021-09-06|19         |2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3763|
|2021-09-06|20         |2021-09-05 21:57:56.455|2021-09-05 21:57:56.564|3916|
|2021-09-06|21         |2021-09-05 21:57:56.565|2021-09-06 21:57:56.241|3557|
|2021-09-06|22         |2021-09-06 21:57:56.242|2021-09-06 21:57:56.459|3721|
|2021-09-06|23         |2021-09-06 21:57:56.46 |2021-09-06 21:57:56.563|3714|
|2021-09-06|24         |2021-09-06 21:57:56.564|2021-09-07 21:57:56.246|3520|
|2021-09-06|25         |2021-09-07 21:57:56.247|2021-09-07 21:57:56.455|3671|
|2021-09-06|26         |2021-09-07 21:57:56.456|2021-09-07 21:57:56.556|3716|
|2021-09-06|27         |2021-09-07 21:57:56.557|2021-09-07 21:57:56.647|3670|
|2021-09-07|1          |2021-09-05 21:57:56.188|2021-09-05 21:57:56.454|3690|
|2021-09-07|2          |2021-09-05 21:57:56.455|2021-09-05 21:57:56.556|3704|
|2021-09-07|3          |2021-09-05 21:57:56.557|2021-09-05 21:57:56.644|3601|
|2021-09-07|4          |2021-09-05 21:57:56.645|2021-09-06 21:57:56.45 |3685|
|2021-09-07|5          |2021-09-06 21:57:56.451|2021-09-06 21:57:56.55 |3767|
|2021-09-07|6          |2021-09-06 21:57:56.551|2021-09-06 21:57:56.644|3846|
|2021-09-07|7          |2021-09-06 21:57:56.645|2021-09-07 21:57:56.452|3782|
|2021-09-07|8          |2021-09-07 21:57:56.453|2021-09-07 21:57:56.555|3775|
|2021-09-07|9          |2021-09-07 21:57:56.556|2021-09-07 21:57:56.647|3820|
+----------+-----------+-----------------------+-----------------------+----+</code></pre></div></details><p>Сохраним и выведем, чтобы убедиться, что все файлы соответствуют исходными секциям</p><details class="spoiler"><summary>Проверка соответствия</summary><div class="spoiler__content"><pre><code>dfRep
      .withColumn("rdd_part_id", fn.spark_partition_id())
      .groupBy(fn.col("ts_part") as "ts_part", fn.col("rdd_part_id"))
      .agg(fn.min("event_time") as "range_min_event_time",
        fn.max("event_time") as "range_max_event_time",
        fn.count(fn.lit(0)) as "cnt_")
      .orderBy("ts_part", "rdd_part_id")
      .show(100, false)
 
    dfRep
      .sortWithinPartitions(fn.col("id"))
      .write
      .mode(SaveMode.Overwrite)
      .partitionBy("ts_part")
      .format("parquet")
      .option("path", "/test/pa/sometable/snp")
      .saveAsTable("testschema.sometable")
 
    val dfT = spark.table("testschema.sometable")
 
    println(dfT.count)
 
    dfT
      .withColumn("file_name",
        fn.regexp_replace(fn.input_file_name(), ".*/test/pa/sometable/snp", ""))
      .groupBy(fn.col("ts_part") as "ts_part", fn.col("file_name"))
      .agg(fn.min("event_time") as "range_min_event_time",
        fn.max("event_time") as "range_max_event_time",
        fn.count(fn.lit(0)) as "cnt_")
      .orderBy("file_name")
      .show(100, false)
</code></pre><pre><code>+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+
|ts_part   |file_name                                                                              |range_min_event_time   |range_max_event_time   |cnt_|
+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+
|2021-09-05|/ts_part=2021-09-05/part-00010-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3672|
|2021-09-05|/ts_part=2021-09-05/part-00011-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.547|3400|
|2021-09-05|/ts_part=2021-09-05/part-00012-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.548|2021-09-05 21:57:56.642|3761|
|2021-09-05|/ts_part=2021-09-05/part-00013-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.643|2021-09-06 21:57:56.447|3601|
|2021-09-05|/ts_part=2021-09-05/part-00014-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.448|2021-09-06 21:57:56.544|3601|
|2021-09-05|/ts_part=2021-09-05/part-00015-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.545|2021-09-06 21:57:56.641|3856|
|2021-09-05|/ts_part=2021-09-05/part-00016-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.642|2021-09-07 21:57:56.449|3711|
|2021-09-05|/ts_part=2021-09-05/part-00017-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.45 |2021-09-07 21:57:56.549|3703|
|2021-09-05|/ts_part=2021-09-05/part-00018-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.55 |2021-09-07 21:57:56.647|3776|
|2021-09-06|/ts_part=2021-09-06/part-00019-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3763|
|2021-09-06|/ts_part=2021-09-06/part-00020-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.564|3916|
|2021-09-06|/ts_part=2021-09-06/part-00021-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.565|2021-09-06 21:57:56.241|3557|
|2021-09-06|/ts_part=2021-09-06/part-00022-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.242|2021-09-06 21:57:56.459|3721|
|2021-09-06|/ts_part=2021-09-06/part-00023-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.46 |2021-09-06 21:57:56.563|3714|
|2021-09-06|/ts_part=2021-09-06/part-00024-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.564|2021-09-07 21:57:56.246|3520|
|2021-09-06|/ts_part=2021-09-06/part-00025-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.247|2021-09-07 21:57:56.455|3671|
|2021-09-06|/ts_part=2021-09-06/part-00026-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.456|2021-09-07 21:57:56.556|3716|
|2021-09-06|/ts_part=2021-09-06/part-00027-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.557|2021-09-07 21:57:56.647|3670|
|2021-09-07|/ts_part=2021-09-07/part-00001-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.188|2021-09-05 21:57:56.454|3690|
|2021-09-07|/ts_part=2021-09-07/part-00002-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.556|3704|
|2021-09-07|/ts_part=2021-09-07/part-00003-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.557|2021-09-05 21:57:56.644|3601|
|2021-09-07|/ts_part=2021-09-07/part-00004-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.645|2021-09-06 21:57:56.45 |3685|
|2021-09-07|/ts_part=2021-09-07/part-00005-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.451|2021-09-06 21:57:56.55 |3767|
|2021-09-07|/ts_part=2021-09-07/part-00006-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.551|2021-09-06 21:57:56.644|3846|
|2021-09-07|/ts_part=2021-09-07/part-00007-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.645|2021-09-07 21:57:56.452|3782|
|2021-09-07|/ts_part=2021-09-07/part-00008-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.453|2021-09-07 21:57:56.555|3775|
|2021-09-07|/ts_part=2021-09-07/part-00009-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.556|2021-09-07 21:57:56.647|3820|
+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+</code></pre></div></details><p> Как видим, интервалы сохранились, для этого не потребовалось никаких дополнительных действий. Количество файлов для этого случая всегда на один меньше, чем количество секций в RDD. Однако в общем случае это не так, ведь в нулевую секцию могут попасть данные из очень небольших физических партиций. dfT.inputFiles.length should <em>be</em>(dfRep.<em>rdd</em>.getNumPartitions - 1)</p><p>Количество записей осталось прежним:</p><details class="spoiler"><summary>Количество записей в сохраненных файлах</summary><div class="spoiler__content"><pre><code>val savedCount = dfT.count
savedCount shouldEqual rangeLimit</code></pre></div></details><p>И схема датафрейма не изменилась, партишенер не меняет порядок полей и их типы.</p><details class="spoiler"><summary>Схемы совпадают</summary><div class="spoiler__content"><pre><code>dfT.printSchema()</code></pre><pre><code>root
 |-- id: integer (nullable = true)
 |-- name: string (nullable = true)
 |-- amount: decimal(38,18) (nullable = true)
 |-- value: decimal(38,18) (nullable = true)
 |-- divider: string (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- event_time: timestamp (nullable = true)
 |-- ts_part: string (nullable = true)</code></pre><pre><code>dfT.schema should be (dataFrameSource.schema)</code></pre></div></details><p> Для того, чтобы убедиться, что сортировка работает, выведем все записи с "id" меньшим 32, без дополнительной сортировки. Мы увидим, что в пределах файла записи отсортированы по возрастанию поля "id", несмотря на то, что были специально перемешаны при создании датафрейма.</p><details class="spoiler"><summary>Проверка локальной сортировки</summary><div class="spoiler__content"><pre><code>dfT
  .withColumn("file_name",
    fn.regexp_replace(fn.input_file_name(), ".*/test/pa/sometable/snp", ""))
  .select("id", "file_name")
  .where("id &lt; 32")
  .show(32, false)</code></pre><pre><code>+---+---------------------------------------------------------------------------------------+
|id |file_name                                                                              |
+---+---------------------------------------------------------------------------------------+
|9  |/ts_part=2021-09-06/part-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|15 |/ts_part=2021-09-06/part-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|19 |/ts_part=2021-09-06/part-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|25 |/ts_part=2021-09-07/part-00004-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|4  |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|13 |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|14 |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|16 |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|28 |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|31 |/ts_part=2021-09-07/part-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|8  |/ts_part=2021-09-05/part-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|12 |/ts_part=2021-09-05/part-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|21 |/ts_part=2021-09-05/part-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|30 |/ts_part=2021-09-05/part-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|10 |/ts_part=2021-09-05/part-00015-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|27 |/ts_part=2021-09-05/part-00015-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|0  |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|1  |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|3  |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|20 |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|22 |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|26 |/ts_part=2021-09-06/part-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|18 |/ts_part=2021-09-07/part-00001-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|5  |/ts_part=2021-09-05/part-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|6  |/ts_part=2021-09-05/part-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|23 |/ts_part=2021-09-05/part-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|24 |/ts_part=2021-09-05/part-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|29 |/ts_part=2021-09-05/part-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|2  |/ts_part=2021-09-06/part-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|7  |/ts_part=2021-09-06/part-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|11 |/ts_part=2021-09-06/part-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
|17 |/ts_part=2021-09-06/part-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|
+---+---------------------------------------------------------------------------------------+</code></pre></div></details><p>Добавлю полные тестовые классы и pom.xml для сборки Maven:</p><details class="spoiler"><summary>Тесты</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing

import java.sql.Timestamp
import java.time.LocalDateTime

import org.apache.spark.sql.{SaveMode, functions => fn}
import org.scalatest.flatspec.AnyFlatSpec
import org.scalatest.matchers.should.Matchers._
import ru.kalininskii.orderbucketing.OrderBucketing._

import scala.util.Random

class OrderPartitionTest extends AnyFlatSpec with SparkBuilder {

  val rangeLimit = 99999
  val seed = 111
  val numLines = 4000

  private def getRandomDF(start: Int, limit: Int, days: Int, daysMinus: Int) = {
    val rnd = new Random()
    rnd.setSeed(seed)

    val sparkSession = spark
    import sparkSession.implicits._

    val list = Range(start, limit)
      .toList
      .map(id => (Option(id), //id, Option для nullable = true
        rnd.alphanumeric.take(rnd.nextInt(32)).mkString, //name
        BigDecimal(rnd.nextInt().abs * rnd.nextDouble()), //amount
        BigDecimal(rnd.nextLong().abs.longValue()), //value
        rnd.alphanumeric.take(rnd.nextInt(3)).mkString, //divider
        Timestamp.valueOf(LocalDateTime.now().minusSeconds((rnd.nextInt(days).abs max daysMinus) * 24 * 60 * 60)), //ts
        Timestamp.valueOf(LocalDateTime.now().minusSeconds((rnd.nextInt(days).abs max daysMinus) * 24 * 60 * 60)) //event_time
      ))

    Random.shuffle(list).toDF("id", "name", "amount", "value", "divider", "ts", "event_time")

  }

  override def beforeAll() {
    super.beforeAll()
    spark.sql("create database if not exists testschema location '/test'")
  }

  "Range buckets partitioner" must "partition correctly" in {
    val dataFrameSource = getRandomDF(0, rangeLimit, 3, 0).persist()
      .withColumn("ts_part", fn.expr("substring(ts,0,10)"))

    dataFrameSource.printSchema()

    val dfRep = dataFrameSource
      .repartitionWithOrderAndSort(numLines, rangeLimit / numLines,
        fn.col("event_time"), List(fn.col("ts_part")), List(fn.col("id")))
      .persist()

    dfRep.explain(true)

    val logicalPlanString = "Repartition plan with unknown distribution: " +
      "partition by ['ts_part], " +
      "global order by 'event_time, " +
      "local sort by ['id], " +
      "4000 rows per task, 24 initial tasks"

    val analyzedPlanString = "Repartition plan with unknown distribution: " +
      "partition by [ts_part#64], " +
      "global order by event_time#21, " +
      "local sort by [id#15], " +
      "4000 rows per task, 24 initial tasks"

    val sparkPlanString = "ExchangeWithOrder Repartition with unknown distribution: " +
      "partition by [ts_part#64], " +
      "global order by event_time#21, " +
      "local sort by [id#15], " +
      "4000 rows per task, 24 initial tasks"

    assert(dfRep.queryExecution.logical.toString contains logicalPlanString)
    assert(dfRep.queryExecution.analyzed.toString contains analyzedPlanString)
    assert(dfRep.queryExecution.sparkPlan.toString contains sparkPlanString)

    println(dfRep.rdd.getNumPartitions)

    dfRep.rdd.getNumPartitions should be(28)

    dfRep
      .withColumn("rdd_part_id", fn.spark_partition_id())
      .groupBy(fn.col("ts_part") as "ts_part", fn.col("rdd_part_id"))
      .agg(fn.min("event_time") as "range_min_event_time",
        fn.max("event_time") as "range_max_event_time",
        fn.count(fn.lit(0)) as "cnt_")
      .orderBy("ts_part", "rdd_part_id")
      .show(100, false)

    dfRep
      .sortWithinPartitions(fn.col("id"))
      .write
      .mode(SaveMode.Overwrite)
      .partitionBy("ts_part")
      .format("parquet")
      .option("path", "/test/pa/sometable/snp")
      .saveAsTable("testschema.sometable")

    val dfT = spark.table("testschema.sometable")

    val savedCount = dfT.count
    savedCount shouldEqual rangeLimit

    dfT
      .withColumn("file_name",
        fn.regexp_replace(fn.input_file_name(), ".*/test/pa/sometable/snp", ""))
      .groupBy(fn.col("ts_part") as "ts_part", fn.col("file_name"))
      .agg(fn.min("event_time") as "range_min_event_time",
        fn.max("event_time") as "range_max_event_time",
        fn.count(fn.lit(0)) as "cnt_")
      .orderBy("file_name")
      .show(100, false)

    dfT.printSchema()

    dfT.inputFiles.length should be(dfRep.rdd.getNumPartitions - 1)

    dfT.schema should be(dataFrameSource.schema)

    dfT
      .withColumn("file_name",
        fn.regexp_replace(fn.input_file_name(), ".*/test/pa/sometable/snp", ""))
      .select("id", "file_name")
      .where("id &lt; 32")
      .show(32, false)

  }
}</code></pre></div></details><details class="spoiler"><summary>Создание Hadoop Minicluster для тестов</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing
 
import java.io.File
import java.nio.file.Files
 
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.FileUtil
import org.apache.hadoop.hdfs.MiniDFSCluster
import org.apache.log4j.{Level, Logger}
import org.scalatest.{BeforeAndAfterAll, TestSuite}
 
trait MiniHdfsBuilder extends BeforeAndAfterAll {
  this: TestSuite =>
 
  val baseDir: File = Files.createTempDirectory("test_hdfs").toFile.getAbsoluteFile
 
  val fsConf: Configuration = new Configuration()
  fsConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, baseDir.getAbsolutePath)
 
  val builder: MiniDFSCluster.Builder = new MiniDFSCluster.Builder(fsConf)
  var hdfsCluster: MiniDFSCluster = _
 
  override def beforeAll() {
    super.beforeAll()
 
    Logger.getLogger("org.apache.hadoop").setLevel(Level.WARN)
    Logger.getLogger("org.apache.spark").setLevel(Level.WARN)
    Logger.getLogger("org.spark_project.jetty.server").setLevel(Level.WARN)
 
    hdfsCluster = builder.build()
  }
 
  override def afterAll() {
    try {
      super.afterAll()
    }
    finally {
      hdfsCluster.shutdown()
      FileUtil.fullyDelete(baseDir)
    }
  }
}</code></pre></div></details><details class="spoiler"><summary>Создание SparkSession для тестов</summary><div class="spoiler__content"><pre><code>package ru.kalininskii.orderbucketing
import java.io.File
 
import org.apache.hadoop.fs.FileUtil
import org.apache.hadoop.hdfs.DistributedFileSystem
import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession
import org.scalatest.TestSuite
import ru.kalininskii.orderbucketing.strategy.RepartitionStrategy
 
trait SparkBuilder extends MiniHdfsBuilder {
  this: TestSuite =>
  var fileSystem: DistributedFileSystem = _
 
  var spark: SparkSession = _
 
  override def beforeAll() {
    super.beforeAll()
    //сессия уже может быть создана, поэтому нужно попробовать ее найти и остановить
    spark = SparkSession
      .builder()
      .appName("DUMMY")
      .master("local[*]")
      .getOrCreate()
 
    spark.stop()
 
    fileSystem = hdfsCluster.getFileSystem()
 
    val sparkConf = new SparkConf().setMaster("local[*]").setAppName("RANGE BUCKET TEST")
    sparkConf.set("fs.defaultFS", fileSystem.getUri.toString)
 
    spark = SparkSession
      .builder()
      .appName("PARTITION_TEST")
      .master("local[*]")
      .config(sparkConf)
      .withExtensions(e => {
        e.injectPlannerStrategy(_ => RepartitionStrategy)
      })
      .getOrCreate()
 
    spark.sparkContext.setLogLevel("WARN")
  }
 
  override def afterAll(): Unit = {
    spark.stop()
    FileUtil.fullyDelete(new File("./metastore_db"))
    FileUtil.fullyDelete(new File("./spark-warehouse"))
    FileUtil.fullyDelete(new File("./derby.log"))
    FileUtil.fullyDelete(new File("./chk"))
 
    super.afterAll()
  }
}</code></pre></div></details><details class="spoiler"><summary>pom.xml для Maven</summary><div class="spoiler__content"><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    &lt;modelVersion>4.0.0&lt;/modelVersion>
 
    &lt;groupId>fine-grained&lt;/groupId>
    &lt;artifactId>range-bucketing&lt;/artifactId>
    &lt;version>0.1-SNAPSHOT&lt;/version>
 
    &lt;properties>
        &lt;spark.version>2.4.0&lt;/spark.version>
        &lt;hadoop.version>3.1.1&lt;/hadoop.version>
        &lt;scala.version>2.11.8&lt;/scala.version>
        &lt;maven.compiler.source>1.8&lt;/maven.compiler.source>
        &lt;maven.compiler.target>1.8&lt;/maven.compiler.target>
        &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding>
    &lt;/properties>
 
    &lt;dependencies>
        &lt;dependency>
            &lt;groupId>org.apache.spark&lt;/groupId>
            &lt;artifactId>spark-core_2.11&lt;/artifactId>
            &lt;version>${spark.version}&lt;/version>
            &lt;scope>provided&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.apache.spark&lt;/groupId>
            &lt;artifactId>spark-sql_2.11&lt;/artifactId>
            &lt;version>${spark.version}&lt;/version>
            &lt;scope>provided&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.scala-lang&lt;/groupId>
            &lt;artifactId>scala-library&lt;/artifactId>
            &lt;version>${scala.version}&lt;/version>
            &lt;scope>provided&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.apache.hadoop&lt;/groupId>
            &lt;artifactId>hadoop-minicluster&lt;/artifactId>
            &lt;version>${hadoop.version}&lt;/version>
            &lt;scope>test&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.apache.spark&lt;/groupId>
            &lt;artifactId>spark-hive_2.11&lt;/artifactId>
            &lt;version>${spark.version}&lt;/version>
            &lt;scope>test&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.scalatest&lt;/groupId>
            &lt;artifactId>scalatest_2.11&lt;/artifactId>
            &lt;version>3.1.1&lt;/version>
            &lt;scope>test&lt;/scope>
        &lt;/dependency>
        &lt;dependency>
            &lt;groupId>org.scalactic&lt;/groupId>
            &lt;artifactId>scalactic_2.11&lt;/artifactId>
            &lt;version>3.1.1&lt;/version>
            &lt;scope>test&lt;/scope>
        &lt;/dependency>
    &lt;/dependencies>
 
    &lt;build>
        &lt;!--   Java sources path:     -->
        &lt;!--        &lt;resources>-->
        &lt;!--            &lt;resource>-->
        &lt;!--                &lt;directory>src/main/scala&lt;/directory>-->
        &lt;!--            &lt;/resource>-->
        &lt;!--        &lt;/resources>-->
        &lt;!--   For JaCoCo:     -->
        &lt;sourceDirectory>src/main/scala&lt;/sourceDirectory>
        &lt;finalName>${project.artifactId}&lt;/finalName>
        &lt;plugins>
            &lt;!-- display active profile in compile phase -->
            &lt;plugin>
                &lt;groupId>org.apache.maven.plugins&lt;/groupId>
                &lt;artifactId>maven-help-plugin&lt;/artifactId>
                &lt;version>3.2.0&lt;/version>
                &lt;executions>
                    &lt;execution>
                        &lt;id>show-profiles&lt;/id>
                        &lt;phase>compile&lt;/phase>
                        &lt;goals>
                            &lt;goal>active-profiles&lt;/goal>
                        &lt;/goals>
                    &lt;/execution>
                &lt;/executions>
            &lt;/plugin>
            &lt;plugin>
                &lt;groupId>org.apache.maven.plugins&lt;/groupId>
                &lt;artifactId>maven-jar-plugin&lt;/artifactId>
                &lt;version>3.2.0&lt;/version>
                &lt;configuration>
                    &lt;archive>
                        &lt;manifest>
                            &lt;addDefaultImplementationEntries>true&lt;/addDefaultImplementationEntries>
                            &lt;addDefaultSpecificationEntries>true&lt;/addDefaultSpecificationEntries>
                        &lt;/manifest>
                    &lt;/archive>
                &lt;/configuration>
            &lt;/plugin>
            &lt;!-- scala and java mix compilation -->
            &lt;plugin>
                &lt;groupId>net.alchim31.maven&lt;/groupId>
                &lt;artifactId>scala-maven-plugin&lt;/artifactId>
                &lt;version>3.2.2&lt;/version>
                &lt;executions>
                    &lt;execution>
                        &lt;goals>
                            &lt;goal>compile&lt;/goal>
                            &lt;goal>testCompile&lt;/goal>
                        &lt;/goals>
                    &lt;/execution>
                &lt;/executions>
                &lt;configuration>
                    &lt;scalaVersion>${scala.version}&lt;/scalaVersion>
                &lt;/configuration>
            &lt;/plugin>
 
            &lt;plugin>
                &lt;groupId>org.apache.maven.plugins&lt;/groupId>
                &lt;artifactId>maven-surefire-plugin&lt;/artifactId>
                &lt;version>2.7&lt;/version>
                &lt;configuration>
                    &lt;skipTests>true&lt;/skipTests>
                &lt;/configuration>
            &lt;/plugin>
            &lt;plugin>
                &lt;groupId>org.scalatest&lt;/groupId>
                &lt;artifactId>scalatest-maven-plugin&lt;/artifactId>
                &lt;version>1.0&lt;/version>
                &lt;executions>
                    &lt;execution>
                        &lt;id>test&lt;/id>
                        &lt;goals>
                            &lt;goal>test&lt;/goal>
                        &lt;/goals>
                    &lt;/execution>
                &lt;/executions>
            &lt;/plugin>
            &lt;plugin>
                &lt;groupId>org.jacoco&lt;/groupId>
                &lt;artifactId>jacoco-maven-plugin&lt;/artifactId>
                &lt;version>0.8.5&lt;/version>
                &lt;executions>
                    &lt;execution>
                        &lt;goals>
                            &lt;goal>prepare-agent&lt;/goal>
                        &lt;/goals>
                    &lt;/execution>
                    &lt;!-- attached to Maven test phase -->
                    &lt;execution>
                        &lt;id>report&lt;/id>
                        &lt;phase>test&lt;/phase>
                        &lt;goals>
                            &lt;goal>report&lt;/goal>
                        &lt;/goals>
                    &lt;/execution>
                &lt;/executions>
            &lt;/plugin>
        &lt;/plugins>
    &lt;/build>
 
&lt;/project></code></pre></div></details><p>На этом статья закончена, а наша работа продолжается. Разработка расширения Spark требует множества решений, и не всегда они простые. Это видно и в исходном коде Spark, я думаю, разработчики сейчас реализовали бы многое иначе.</p><p>В любом случае, мы не обязаны пользоваться только существующими средствами, можно разработать что-то своё. Если вы хотите преобразовать данные, используя Spark, то можете выбрать готовое решение (HashPartitioner, RangePartitioner). И всё же, если если вы поняли, что нужно специфическое распределение данных, то не бойтесь сделать партишенер для своих нужд, и я уверен, что он будет лучше и полезнее!</p><p>Не пытайтесь заставить машину работать быстрее, постарайтесь сделать так, чтобы машина не выполняла ненужную работу, а нужной работы было как можно меньше. Тогда это будет не преждевременная, а осознанная и нужная оптимизация.</p><p>В следующей статье мы разберём сам DataSource, предназначенный для чтения данных, и средства работы с метаданными.</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bspark%5D" class="tm-tags-list__link">spark</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B%5D" class="tm-tags-list__link">таблицы</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bdata%5D" class="tm-tags-list__link">data</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/company/sberbank/blog/" class="tm-hubs-list__link router-link-active">
    Блог компании Сбер
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/db_admins/" class="tm-hubs-list__link">
    Администрирование баз данных
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/bigdata/" class="tm-hubs-list__link">
    Big Data
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 7: ↑6 и ↓1</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 7: ↑6 и ↓1" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+5</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">708</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    15
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/sberbank/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/company/9db/3c1/ec0/9db3c1ec02265b8bcbfdfb0d23d8b9f2.jpg" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/sberbank/profile/" class="tm-company-snippet__title">Сбер</a> <div class="tm-company-snippet__description">Больше чем банк</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <!----> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/Sber/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/b1f/595/703/b1f595703fffc92491048ef9b6882dff.png" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 35 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    1
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">26.8</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/Sber/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @Sber
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Пользователь</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/sberbank/blog/583018/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментировать 
    </span></a> <!----></div></div></div>  <!---->  <!----> <!----></div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="1841-11-11T21:29:43.000Z" title="1841-11-12, 00:00">12  ноября  1841</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    Россия
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="http://www.sber.ru/" target="_blank" class="tm-company-basic-info__link">
      www.sber.ru
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    свыше 10 000 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2011-02-08T10:09:33.000Z" title="2011-02-08, 13:09">8  февраля  2011</time></dd></dl> <!----></div></div> <!----></section> <div class="tm-company-widgets"></div> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/sberbank/blog/583018/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/sberbank/blog/583018/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"583018":{"id":"583018","timePublished":"2021-10-12T12:04:16+00:00","isCorporative":true,"lang":"ru","titleHtml":"Изменить сохранения Spark Часть вторая: реализация партишенера","leadData":{"textHtml":"\u003Cp\u003EИзменить сохранения Spark! Часть вторая: реализация партишенера!\u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa1e\u002F78b\u002F13a\u002Fa1e78b13a83819b4dd3ffa494da3700b.jpg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa1e\u002F78b\u002F13a\u002Fa1e78b13a83819b4dd3ffa494da3700b.jpg","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":1,"votesCount":35},"rating":26.8,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"1713571","alias":"Sber","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fb1f\u002F595\u002F703\u002Fb1f595703fffc92491048ef9b6882dff.png","speciality":"Пользователь"},"statistics":{"commentsCount":0,"favoritesCount":15,"readingCount":708,"score":5,"votesCount":7},"hubs":[{"relatedData":null,"id":"17155","alias":"sberbank","type":"corporative","title":"Блог компании Сбер","titleHtml":"Блог компании Сбер","isProfiled":false},{"relatedData":null,"id":"17681","alias":"db_admins","type":"collective","title":"Администрирование баз данных","titleHtml":"Администрирование баз данных","isProfiled":true},{"relatedData":null,"id":"17795","alias":"bigdata","type":"collective","title":"Big Data","titleHtml":"Big Data","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"6","alias":"admin","title":"Администрирование"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EАвтор:\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH\u002FBigData.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cem\u003EПрофессиональное сообщество SberProfi DWH\u002FBigData отвечает за развитие компетенций в таких направлениях, как экосистема Hadoop, Teradata, Oracle DB, GreenPlum, а также BI инструментах Qlik, SAP BO, Tableau и др.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cp\u003EНачну описание партишенера с UML-диаграммы:\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 1. UML-диаграмма классов OrderBucketsPartitioner\" title=\"Рисунок 1. UML-диаграмма классов OrderBucketsPartitioner\" height=\"1061\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F964\u002Fe1d\u002F99d\u002F964e1d99d9eebd2740a09ba7ca1be2dd.png\" data-width=\"821\"\u002F\u003E\u003Cfigcaption\u003EРисунок 1. UML-диаграмма классов OrderBucketsPartitioner\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНаверняка вы видели, как Spark разбирает запрос, строит план и выполняет его. Сопоставим эту схему с нашей конкретной реализацией (когда будете знакомиться с реализацией классов, возвращайтесь к этой схеме, чтобы увидеть соответствие):\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 2. Сопоставление схемы обработки запроса и конкретной реализации.\" title=\"Рисунок 2. Сопоставление схемы обработки запроса и конкретной реализации.\" height=\"192\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Feab\u002F499\u002Fe37\u002Feab499e37f38678093879d9be9b058f1.png\" data-width=\"1082\"\u002F\u003E\u003Cfigcaption\u003EРисунок 2. Сопоставление схемы обработки запроса и конкретной реализации.\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНужен метод, который позволил бы использовать партишенер для любого датафрейма. Пока не будем связываться с SQL (разве кто-то делает dataframe.repartition(...) с помощью SQL?).\u003C\u002Fp\u003E\u003Cp\u003EДобавим такой метод в Scala Dataframe API, используя паттерн «Pimp my library».\u003Cbr\u002F\u003E Для этого создадим новый объект ru.kalininskii.orderbucketing.OrderBucketing. Он будет содержать implicit class с пока единственным методом repartitionWithOrderAndSort:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EOrderBucketing\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing\n \nimport org.apache.spark.sql.{Column, DataFrame, PlanHelper}\nimport org.apache.spark.sql.catalyst.expressions.{Ascending, Expression, SortOrder}\nimport ru.kalininskii.orderbucketing.plans.logical.RepartitionWithOrderAndSort\n \nobject OrderBucketing {\n \n  implicit class DataFramePartOps(ds: DataFrame) {\n    def repartitionWithOrderAndSort(numLines: Int,\n                                     numPartitions: Int,\n                                     orderColumn: Column,\n                                     partitionColumns: Seq[Column],\n                                     sortColumns: Seq[Column]): DataFrame = {\n      def toSortOrder(col: Column): SortOrder = {\n        col.expr match {\n          case order: SortOrder =\u003E order.copy(direction = Ascending)\n          case expr: Expression =\u003E SortOrder(expr, Ascending)\n          case _ =\u003E throw new Exception(s\"Can not get order from $col\")\n        }\n      }\n \n      val orderExpression = toSortOrder(orderColumn)\n      val partitionExpressions = partitionColumns.map(_.expr)\n      val sortExpressions = sortColumns.map(toSortOrder)\n \n      val logicalPlan = RepartitionWithOrderAndSort(\n        orderExpression,\n        partitionExpressions,\n        sortExpressions,\n        numLines,\n        numPartitions,\n        None,\n        ds.queryExecution.logical)\n \n      PlanHelper.planToDF(ds.sparkSession, logicalPlan)\n    }\n  }\n \n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EКак можно видеть из кода выше, метод принимает аргумент partitionColumns: Seq[Column], в котором поля явного и неявного секционирования объединены. Так и должно быть, партишенер разделяет записи по секциям независимо от их внешнего представления. \u003C\u002Fp\u003E\u003Cp\u003EОбъект PlanHelper пока что также обойдётся одним методом, planToDF. Этот метод вызывает приватный метод для пакета org.apache.spark.sql, поэтому, чтобы он мог выполняться, объект тоже должен находиться в этом пакете:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EPlanHelper\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage org.apache.spark.sql\n \nimport org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \nobject PlanHelper {\n \n  def planToDF(spark: SparkSession, logicalPlan: LogicalPlan): DataFrame = {\n    Dataset.ofRows(spark, logicalPlan)\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EТип для описания одной секции RDD, а также ключа RDD, который понадобится нам в определённый момент, поместим в package object, чтобы он был доступен всему нашему пакету и не только\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003Epackage object rangebucketing\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii\n \nimport org.apache.spark.sql.catalyst.InternalRow\n \npackage object rangebucketing {\n  type BucketsDistribution = (Int, InternalRow, Either[(InternalRow, Seq[String]), (InternalRow, InternalRow, Int)])\n  type OrderAndSortKey = (InternalRow, InternalRow, InternalRow)\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EТеперь нужно определить планы, начиная с логического. И в них переопределить метод \u003Cem\u003EsimpleString\u003C\u002Fem\u003E, так как иначе он выведет в план весь переданный объект \u003Cem\u003Edistribution. \u003C\u002Fem\u003EЛогический план для этого репартиционирования будет виден при использовании метода explain, и можно будет убедиться, что он действительно применяется. Кроме того, он встроен в формирование планов выполнения запросов и будет предоставлять информацию о физическом секционировании набора данных в переменной \u003Cem\u003Epartitioning\u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003ERepartitionWithOrderAndSort\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing.plans.logical\n \nimport org.apache.spark.sql.catalyst.expressions.{Expression, SortOrder}\nimport org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, RepartitionOperation}\nimport ru.kalininskii.orderbucketing.BucketsDistribution\nimport ru.kalininskii.orderbucketing.plans.physical.OrderBucketsPartitioning\n \n\u002F**\n * Этот класс разделяет данные по условю уникальных точных значений [[Expression]]\n *\n * @param orderExpression      выражение, по интервалам значений которого будет производиться разделение\n *                             в пределах одного значения [[partitionExpressions]]\n * @param partitionExpressions выражения, по значениям которых будет производиться разделение.\n * @param sortExpressions      выражения, по значениям которых будет производиться локальная сортировка.\n * @param numLines             количество записей в одной секции RDD (и в записанном файле)\n * @param numPartitions        предполагаемое количество секций, может отличаться\n * @param distribution         информация об имеющемся распределении, которое надо воспроизвести\n * @param child                план получения набора данных, который нужно секционировать\n *\u002F\ncase class RepartitionWithOrderAndSort(\n                                        orderExpression: SortOrder,\n                                        partitionExpressions: Seq[Expression],\n                                        sortExpressions: Seq[SortOrder],\n                                        numLines: Int,\n                                        numPartitions: Int,\n                                        distribution: Option[Seq[BucketsDistribution]],\n                                        child: LogicalPlan\n                                      ) extends RepartitionOperation {\n \n  override def nodeName: String = s\"Repartition plan with \" +\n    s\"${distribution.map(_ =\u003E \"predefined\").getOrElse(\"unknown\")} distribution:\"\n \n  override def simpleString: String = {\n    s\"$nodeName ${partitionExpressions.mkString(\"partition by [\", \", \", \"], \")}\" +\n      s\"global order by ${orderExpression.child}, \" +\n      s\"${sortExpressions.map(_.child).mkString(\"local sort by [\", \", \", \"], \")}\" +\n      numLines + \" rows per task, \" + numPartitions + \" initial tasks\"\n  }\n \n  val partitioning: OrderBucketsPartitioning = OrderBucketsPartitioning(\n    orderExpression, partitionExpressions, sortExpressions, numLines, numPartitions, distribution)\n \n  override def maxRows: Option[Long] = child.maxRows\n \n  override def shuffle: Boolean = true\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EКласс \u003Cem\u003EPartitioning \u003C\u002Fem\u003Eи его расширения в структуре пакетов Spark относятся к физическим планам (\u003Cem\u003Eorg.apache.spark.sql.catalyst.plans.physical\u003C\u002Fem\u003E), но скорее представляют собой контейнеры для характеристик конкретного датафрейма.\u003C\u002Fp\u003E\u003Cp\u003EВсе встроенные реализации создаются кейс классом (см. Термины и определения) \u003Cem\u003Eorg.apache.spark.sql.catalyst.plans.logical.RepartitionByExpression, \u003C\u002Fem\u003Eполучая значения полей, переданных в указанный кейс класс.\u003C\u002Fp\u003E\u003Cp\u003EИ в нашем случае, \u003Cem\u003EOrderBucketsPartitioning\u003C\u002Fem\u003E можно считать описанием операции над таблицей, прочитанной из файловой системы или объектного хранилища. Не будет ошибкой отнести класс к логическому плану, ведь метод \u003Cem\u003Edataframe.explain(true)\u003C\u002Fem\u003E именно его выводит в каждом дереве логического плана).\u003C\u002Fp\u003E\u003Cp\u003EВ реализации есть неприятный момент: трейт (см. Термины и определения) \u003Cem\u003EDistribution   \u003C\u002Fem\u003Eв исходном коде Spark объявлен как \u003Cem\u003Esealed\u003C\u002Fem\u003E, а значит не может быть расширен. Поэтому в методе \u003Cem\u003Esatisfies0\u003C\u002Fem\u003E я буду использовать \u003Cem\u003EOrderedDistribution\u003C\u002Fem\u003E, хотя она не лучшим образом подходит для описания полученного распределения.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EOrderBucketsPartitioning\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing.plans.physical\n \nimport org.apache.spark.sql.catalyst.expressions.{Expression, SortOrder, Unevaluable}\nimport org.apache.spark.sql.catalyst.plans.physical.{Distribution, OrderedDistribution, Partitioning}\nimport org.apache.spark.sql.types.{DataType, IntegerType}\nimport ru.kalininskii.orderbucketing.BucketsDistribution\n \n\u002F**\n * Этот класс передаёт данные для партиционирования по диапазонам в пределах партиций\n *\n * @param orderExpression      выражение, по интервалам значений которого будет производиться разделение\n *                             в пределах одного значения [[partitionExpressions]]\n * @param partitionExpressions выражения, по значениям которых будет производиться разделение\n * @param sortExpressions      выражения, по значениям которых будет производиться локальная сортировка\n * @param numLines             количество записей в одной секции RDD (и в записанном файле)\n * @param numPartitions        предполагаемое количество секций, может отличаться\n * @param distribution         информация об имеющемся распределении, которое надо воспроизвести\n *\u002F\ncase class OrderBucketsPartitioning(\n                                     orderExpression: SortOrder,\n                                     partitionExpressions: Seq[Expression],\n                                     sortExpressions: Seq[SortOrder],\n                                     numLines: Int,\n                                     numPartitions: Int,\n                                     distribution: Option[Seq[BucketsDistribution]])\n \n  extends Expression with Partitioning with Unevaluable {\n \n  override def nodeName: String = s\"Repartition with \" +\n    s\"${distribution.map(_ =\u003E \"predefined\").getOrElse(\"unknown\")} distribution:\"\n \n  override def simpleString: String = {\n    s\"$nodeName ${partitionExpressions.mkString(\"partition by [\", \", \", \"], \")}\" +\n      s\"global order by ${orderExpression.child}, \" +\n      s\"${sortExpressions.map(_.child).mkString(\"local sort by [\", \", \", \"], \")}\" +\n      numLines + \" rows per task, \" + numPartitions + \" initial tasks\"\n  }\n \n  override def children: Seq[Expression] = partitionExpressions :+ orderExpression\n \n  override def nullable: Boolean = false\n \n  override def dataType: DataType = IntegerType\n \n  override def satisfies0(required: Distribution): Boolean = {\n    super.satisfies0(required) || {\n      required match {\n        case o: OrderedDistribution =\u003E\n          orderExpression.semanticEquals(o.ordering.head)\n        case _ =\u003E false\n      }\n    }\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EДалее два основных класса, \u003Cem\u003Eorg.apache.spark.sql.execution.exchange.ShuffleExchangeOrderExec \u003C\u002Fem\u003Eи \u003Cem\u003Eorg.apache.spark.sql.partitioning.OrderBucketsPartitioner\u003C\u002Fem\u003E. Они используют методы с ограниченной видимостью, поэтому должны находиться в пределах пакета org.apache.spark.sql. Эти классы выполняют трансформации RDD, относятся к планам выполнения.\u003C\u002Fp\u003E\u003Cp\u003EОсновное \u003Cem\u003Eотличие org.apache.spark.sql.execution.exchange.ShuffleExchangeOrderExec\u003C\u002Fem\u003E от оригинала заключается в том, что для семплирования используется RDD, в котором \u003Cem\u003EMutablePair\u003C\u002Fem\u003E использует обе части:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eпервую - для значений полей секционирования ([P]);\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eвторую - для значения поля упорядочивания ([O]).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EС моей точки зрения, это уменьшит объём данных для дальнейшей обработки и позволит использовать полученные структуры для других наборов данных. Полученные структуры в любом случае должны быть переданы на драйвер, а затем переданы исполнителям (так работает broadcast), поэтому разумно с самого начала уменьшать их, насколько это возможно.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EShuffleExchangeOrderExec\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage org.apache.spark.sql.execution.exchange\n \nimport org.apache.spark._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.serializer.Serializer\nimport org.apache.spark.sql.catalyst.InternalRow\nimport org.apache.spark.sql.catalyst.errors._\nimport org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering\nimport org.apache.spark.sql.catalyst.expressions.{Attribute, UnsafeProjection}\nimport org.apache.spark.sql.catalyst.plans.physical._\nimport org.apache.spark.sql.execution._\nimport org.apache.spark.sql.execution.metric.{SQLMetric, SQLMetrics}\nimport org.apache.spark.sql.partitioning.OrderBucketsPartitioner\nimport org.apache.spark.util.MutablePair\nimport ru.kalininskii.orderbucketing.OrderAndSortKey\nimport ru.kalininskii.orderbucketing.plans.physical.OrderBucketsPartitioning\n \nimport scala.reflect.ClassTag\n \n\u002F**\n * Выполняет shuffle, который описывается newPartitioning\n * Код частично заимствован из [[ShuffleExchangeExec]]\n *\u002F\ncase class ShuffleExchangeOrderExec(newPartitioning: OrderBucketsPartitioning,\n                                    child: SparkPlan,\n                                    partitioner: Option[Partitioner] = None) extends Exchange {\n \n  override lazy val metrics: Map[String, SQLMetric] = Map(\n    \"dataSize\" -\u003E SQLMetrics.createSizeMetric(sparkContext, \"data size\"))\n \n  override def nodeName: String = \"ExchangeWithOrder\"\n \n  override def outputPartitioning: Partitioning = newPartitioning\n \n  private val serializer: Serializer = SparkEnv.get\n    .serializerManager.getSerializer(implicitly[ClassTag[OrderAndSortKey]],\n    implicitly[ClassTag[InternalRow]])\n \n  override protected def doPrepare(): Unit = {}\n \n  \u002F**\n   * Возвращает зависимость RDD [[ShuffleDependency]], которая перемешает записи\n   * по схеме, определенной в `newPartitioning`. Партиции RDD, свзязанные с\n   * возвращенной ShuffleDependency будут входными данными для shuffle.\n   *\u002F\n  private[exchange] def prepareShuffleDependency()\n  : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow] = {\n    val rdd = child.execute()\n \n    val part: Partitioner = partitioner\n      .getOrElse(ShuffleExchangeOrderExec.preparePartitioner(rdd, child.output, newPartitioning))\n \n    ShuffleExchangeOrderExec.prepareShuffleDependency(rdd, child.output, newPartitioning, serializer, part)\n  }\n \n  \u002F**\n   * Возвращает [[ShuffledOrderRDD]], а это и есть набор данных после перемешивания.\n   * [[ShuffledOrderRDD]], как и прочие наследники ShuffledRDD, основан на переданной [[ShuffleDependency]]\n   *\u002F\n  private[exchange] def preparePostShuffleRDD(\n                                               shuffleDependency\n                                               : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow]\n                                             ): ShuffledOrderRDD = {\n    new ShuffledOrderRDD(shuffleDependency)\n  }\n \n  \u002F**\n   * ShuffledOrderRDD может быть кеширован для переиспользования\n   *\u002F\n  private var cachedShuffleRDD: ShuffledOrderRDD = _\n \n  protected override def doExecute(): RDD[InternalRow] = attachTree(this, \"execute\") {\n    \u002F\u002F Returns the same ShuffleRowRDD if this plan is used by multiple plans.\n    if (cachedShuffleRDD == null) {\n      cachedShuffleRDD = preparePostShuffleRDD(prepareShuffleDependency())\n    }\n    cachedShuffleRDD\n  }\n \n}\n \n \nobject ShuffleExchangeOrderExec {\n \n  def preparePartitioner(rdd: RDD[InternalRow],\n                         outputAttributes: Seq[Attribute],\n                         partitioning: OrderBucketsPartitioning): Partitioner = {\n    \u002F\u002F Internally, ValuesAndRangePartitioner runs a job on the RDD that samples keys to compute\n    \u002F\u002F partition bounds. To get accurate samples, we need to copy the mutable keys.\n    val rddForSampling = rdd.mapPartitionsInternal { iter =\u003E\n      val projectionPart = UnsafeProjection.create(partitioning.partitionExpressions, outputAttributes)\n      val projectionOrder = UnsafeProjection.create(partitioning.orderExpression.child :: Nil, outputAttributes)\n      val mutablePair = new MutablePair[InternalRow, InternalRow]()\n      iter.map(row =\u003E mutablePair.update(projectionPart(row).copy(), projectionOrder(row).copy()))\n    }\n    implicit val ordering: LazilyGeneratedOrdering =\n      new LazilyGeneratedOrdering(Seq(partitioning.orderExpression),\n        outputAttributes.filter(_.references equals partitioning.orderExpression.child.references))\n \n    new OrderBucketsPartitioner(\n      rddForSampling,\n      partitioning.numLines,\n      partitioning.numPartitions,\n      partitioning.distribution)\n  }\n \n  private def getPartitionKeyExtractor(outputAttributes: Seq[Attribute],\n                                       partitioning: OrderBucketsPartitioning,\n                                       i: Int): InternalRow =\u003E OrderAndSortKey = {\n    val projectionPart = UnsafeProjection.create(partitioning.partitionExpressions, outputAttributes)\n    val projectionOrder = UnsafeProjection.create(partitioning.orderExpression.child :: Nil, outputAttributes)\n    val projectionSort = UnsafeProjection.create(partitioning.sortExpressions.map(_.child), outputAttributes)\n    row =\u003E (projectionPart(row), projectionOrder(row), projectionSort(row).copy())\n  }\n \n  \u002F**\n   * Возвращает зависимость RDD [[ShuffleDependency]], которая перемешает записи\n   * по схеме, определенной в `newPartitioning`. Партиции RDD, свзязанные с\n   * возвращенной ShuffleDependency будут входными данными для shuffle.\n   *\u002F\n  private def prepareShuffleDependency(rdd: RDD[InternalRow],\n                                       outputAttributes: Seq[Attribute],\n                                       partitioning: OrderBucketsPartitioning,\n                                       serializer: Serializer,\n                                       part: Partitioner\n                                      )\n  : ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow] = {\n    val rddWithKeys: RDD[Product2[OrderAndSortKey, InternalRow]] = {\n      rdd.mapPartitionsWithIndexInternal((i, iter) =\u003E {\n        val mutablePair = new MutablePair[OrderAndSortKey, InternalRow]()\n        val keyGen = getPartitionKeyExtractor(outputAttributes, partitioning, i)\n        iter.map { row =\u003E mutablePair.update(keyGen(row), row.copy) }\n      })\n    }\n \n    def keyOrdering[A &lt;: Product3[InternalRow, InternalRow, InternalRow]]: Ordering[A] = {\n      val allExprs = outputAttributes\n        .filter(attr =\u003E partitioning.sortExpressions.map(_.child.references).contains(attr.references))\n      implicit val sortOrdering: Ordering[InternalRow] =\n        new LazilyGeneratedOrdering(partitioning.sortExpressions, allExprs)\n      Ordering.by(_._3)\n    }\n \n    implicit val order: Ordering[OrderAndSortKey] = keyOrdering\n \n    \u002F\u002F Now, we manually create a ShuffleDependency.\n    new ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow](\n      rddWithKeys,\n      part,\n      serializer,\n      Some(order)\n    )\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EДля того, чтобы не менять схему датафрейма и скрыть подробности реализации секционирования и сортировки, используется класс \u003Cem\u003Eorg.apache.spark.sql.execution.exchange.ShuffledOrderRDD\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EShuffledOrderRDD\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage org.apache.spark.sql.execution.exchange\n \nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.catalyst.InternalRow\nimport org.apache.spark.sql.execution.{CoalescedPartitioner, ShuffledRowRDDPartition}\nimport org.apache.spark._\nimport ru.kalininskii.orderbucketing.OrderAndSortKey\n \n\u002F**\n * Специализированный класс-наследник [[org.apache.spark.rdd.ShuffledRDD]]\n * Поддерживает локальную сортировку по указанным полям\n *\u002F\nclass ShuffledOrderRDD(var dependency: ShuffleDependency[OrderAndSortKey, InternalRow, InternalRow])\n  extends RDD[InternalRow](dependency.rdd.context, Nil) {\n \n  private[this] val numPreShufflePartitions = dependency.partitioner.numPartitions\n \n  private[this] val partitionStartIndices: Array[Int] = (0 until numPreShufflePartitions).toArray\n \n  private[this] val part: Partitioner =\n    new CoalescedPartitioner(dependency.partitioner, partitionStartIndices)\n \n  override def getDependencies: Seq[Dependency[_]] = List(dependency)\n \n  override val partitioner: Option[Partitioner] = Some(part)\n \n  override def getPartitions: Array[Partition] = {\n    assert(partitionStartIndices.length == part.numPartitions)\n    Array.tabulate[Partition](partitionStartIndices.length) { i =\u003E\n      val startIndex = partitionStartIndices(i)\n      val endIndex =\n        if (i &lt; partitionStartIndices.length - 1) {\n          partitionStartIndices(i + 1)\n        } else {\n          numPreShufflePartitions\n        }\n      new ShuffledRowRDDPartition(i, startIndex, endIndex)\n    }\n  }\n \n  override def getPreferredLocations(partition: Partition): Seq[String] = {\n    val tracker = SparkEnv.get.mapOutputTracker.asInstanceOf[MapOutputTrackerMaster]\n    val dep = dependencies.head.asInstanceOf[ShuffleDependency[_, _, _]]\n    tracker.getPreferredLocationsForShuffle(dep, partition.index)\n  }\n \n  override def compute(split: Partition, context: TaskContext): Iterator[InternalRow] = {\n    val shuffledRowPartition = split.asInstanceOf[ShuffledRowRDDPartition]\n    \u002F\u002F The range of pre-shuffle partitions that we are fetching at here is\n    \u002F\u002F [startPreShufflePartitionIndex, endPreShufflePartitionIndex - 1].\n    val reader =\n    SparkEnv.get.shuffleManager.getReader(\n      dependency.shuffleHandle,\n      shuffledRowPartition.startPreShufflePartitionIndex,\n      shuffledRowPartition.endPreShufflePartitionIndex,\n      context)\n    reader.read().asInstanceOf[Iterator[Product2[OrderAndSortKey, InternalRow]]].map(_._2)\n  }\n \n  override def clearDependencies() {\n    super.clearDependencies()\n    dependency = null\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EИ вот, долгожданный класс, который будет определять границы и отыскивать номер партиции RDD.\u003C\u002Fp\u003E\u003Cp\u003EОсновным полем в нём является \u003Cstrong\u003Eprivate\u003C\u002Fstrong\u003E \u003Cstrong\u003Evar\u003C\u002Fstrong\u003E \u003Cem\u003ErangeBounds\u003C\u002Fem\u003E: Map[P, (Array[O], Int)].\u003Cbr\u002F\u003E Это карта, ключом которой является InternalRow со значениями полей секционирования, а значением – кортеж из массива верхних границ партиций RDD (тоже InternalRow, но с другим содержимым) и стартового номера партиции для секции (в дальнейшем может называться \"смещение\").\u003C\u002Fp\u003E\u003Cp\u003EСэмплинг производится стандартным способом (RDD.sample), поэтому может упускать значения из маленьких партиций. Напомню, что класс создавался для обработки больших объемов данных, поэтому может неэффективно работать на нескольких десятках или сотнях строк.\u003C\u002Fp\u003E\u003Cp\u003EОтбор границ также производится в RDD, при этом количество партиций RDD для каждой секции, явной или неявной, определяется динамически на основании собранной информации о количестве строк в сэмпле.\u003C\u002Fp\u003E\u003Cp\u003EПосле получения всех отобранных границ, на драйвере выполняется алгоритм со следующими инвариантами:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003EНулевая партиция резервируется для не вошедших в статистику ключей (секций Hive и неявных секций). В случаях, когда нулевая партиция получает слишком большой объём данных, измените поля явного и неявного секционирования или откажитесь от них полностью;\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EЗначения явных и неявных секций могут следовать в неотсортированном порядке, но этот порядок должен был зафиксирован с использованием переменной \"смещения\". Смещение - это значение типа Int, оно входит в кортежMap[P, (Array[O], \u003Cem\u003EInt\u003C\u002Fem\u003E)];\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EСтартовый номер секции – смещение, начинается с одного (см. п.1 – нулевая партиция зарезервирована, и для каждого следующего ключа прирастает на количество границ + 1, что соответствует реальному количеству партиций для секции (см. п.4);\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EМассив значений поля упорядочивания не содержит самой последней верхней границы, это логично, чтобы не создавать всегда пустую дополнительную секцию.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EПоиск партиции осуществляется сначала по ключу карты (конкретное значение всех полей секционирования), затем в массиве значений, последовательным или двоичным поиском, в зависимости от длины массива. Все записи, для которых ключ отсутствует в карте, отправляются в нулевую партицию RDD, что может привести к неприемлемо большому объёму этой партиции, если поля явного или неявного партиционирования выбраны неудачно и имеют слишком высокую селективность. В этом случае лучше не секционировать таблицу вообще, оставив только разделение на бакеты по полю упорядочивания.\u003C\u002Fp\u003E\u003Cp\u003EВыбор границы одной партиции RDD, начиная с прототипа, осуществляется так: значения меньше либо равные верхней границе (она, как мы помним, определена заранее и известна), и больше, чем предыдущая верхняя граница, или предыдущая верхняя граница отсутствует (это первый файл в явной или неявной секции).\u003C\u002Fp\u003E\u003Cp\u003EЯ знаком с концепцией интервального секционирования в Oracle, и между этими двумя реализациями есть отличие в строгости неравенств. В Oracle секции определяются по условию «меньше конкретного значения» и неявному условию «больше или равно предыдущего конкретного значения».\u003C\u002Fp\u003E\u003Cp\u003EЭто связано с тем, что секционирование Oracle работает с конкретными интервалами: для времени это чаще всего сутки, для числовых значений – миллионы или миллиарды и так далее.\u003C\u002Fp\u003E\u003Cp\u003EПоэтому очень удобно, к примеру, что можно указать для разделения по суткам: values less than ‘2021-12-01 00:00:00’ – при этом видно, что в новую партицию попадёт начало суток (и месяца), а сколь угодно близкое, но меньшее значение будет в партиции, относящейся к ‘2021-11-30’.\u003C\u002Fp\u003E\u003Cp\u003EВ нашем случае дело совсем в другом: пользователь ничего не должен знать об интервалах и файлах, его интересуют только конкретные данные и это задача явного секционирования (первый уровень).\u003C\u002Fp\u003E\u003Cp\u003EТаким образом, задача разделения интервалов значений – обеспечить примерно равный размер файлов, лёгкость нахождения нужных файлов и совершенно прозрачное взаимодействие, если пользователь обращается напрямую к традиционным структурам. Поэтому границы интервалов определяются «на лету», хранятся в отдельной структуре и сопоставлены с физическими файлами. Каждая секция имеет свой индивидуальный набор границ. Кроме того, укажем на достаточно важный момент: если одну из границ, в нашем случае, верхнюю, мы определяем явно, то другая, нижняя граница не очень важна, но лучше, чтобы её можно было легко найти, если в дальнейшем она будет отсутствовать в карте данных. Для нижней границы это действительно так, потому что значение нужно прочитать из начала файла или из начала сегмента данных, в случае колоночного формата хранения.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EOrderBucketsPartitioner\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage org.apache.spark.sql.partitioning\n \nimport java.io.{IOException, ObjectInputStream, ObjectOutputStream}\n \nimport org.apache.spark.{Partitioner, SparkEnv}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.serializer.JavaSerializer\nimport org.apache.spark.sql.catalyst.InternalRow\nimport org.apache.spark.util.{CollectionsUtils, Utils}\n \nimport scala.collection.mutable.ArrayBuffer\nimport scala.reflect.ClassTag\nimport scala.util.hashing.byteswap32\n \n\u002F**\n * Наследник [[org.apache.spark.Partitioner]] который разделяет по точным значениям некоторых выражений (полей).\n * И интервалов значений одного выражения (поля)\n *\n * @note The actual number of partitions created by the RangePartitioner might not be the same\n *       as the `partitions` parameter, in the case where the number of sampled records is less than\n *       the value of `partitions`.\n *\u002F\nclass OrderBucketsPartitioner[P: ClassTag, O: Ordering : ClassTag\n](rdd: RDD[_ &lt;: Product2[P, O]],\n  val numLines: Int,\n  val partitions: Int,\n  val distribution: Option[Seq[(Int, P, Either[(O, Seq[String]), (O, O, Int)])]])\n  extends Partitioner {\n \n  \u002F\u002F We allow partitions = 0, which happens when sorting an empty RDD under the default settings.\n  require(partitions \u003E= 0, s\"Number of partitions cannot be negative but found $partitions.\")\n \n  private var ordering = implicitly[Ordering[O]]\n \n  private def getDistribution: Option[Map[P, (Array[O], Int)]] = distribution flatMap {\n    case Seq() =\u003E None\n    case distr =\u003E\n      val (inner, outer) = distr.partition(_._3.isLeft)\n \n      \u002F\u002Fвнешние границы из распределения.\n      val (singleFileBounds, manyFileBounds): (Seq[(P, (Int, (O, O, Int)))], Seq[(P, (Int, (O, O, Int)))]) =\n        outer\n          .map { case (index, p, right) =\u003E (p, (index, right.right.get)) }\n          .partition { case (_, (_, (_, _, filesNum))) =\u003E filesNum == 1 }\n      \u002F\u002FНужно определить внутренние границы, только для тех, где больше одного файла\n      val outerBounds: Map[P, Seq[(Int, (O, O, Int))]] = manyFileBounds\n        .groupBy(_._1)\n        .map { case (p, values) =\u003E p -\u003E values.map(bounds =\u003E bounds._2) }\n      \u002F\u002F границы единичных файлов уже определены\n      val singleBounds: Array[(P, Array[(Int, Array[O])])] = singleFileBounds\n        .groupBy(_._1)\n        .map { case (p, values) =\u003E\n          (p, values.map(bounds =\u003E (bounds._2._1, Array(bounds._2._2._2))).toArray) }\n        .toArray\n \n      \u002F\u002Fвнутренние границы получаются из rdd фильтром, сэмплированием, обработкой\n      val innerBounds: Array[(P, Array[(Int, Array[O])])] =\n        OrderBucketsPartitioner.getInnerBounds(rdd, numLines, partitions, outerBounds)\n \n      \u002F\u002Fзаранее определённые внутренние границы\n      val givenBounds: Array[(P, Array[(Int, Array[O])])] = inner\n        .map { case (index, p, left) =\u003E (p, (index, Array(left.left.get._1))) }\n        .groupBy(_._1)\n        .map { case (p, values) =\u003E p -\u003E values.map(bounds =\u003E bounds._2).toArray }\n        .toArray\n \n      \u002F\u002Fтеперь оба массива склеиваются, группируются, получаем все границы,\n      \u002F\u002F отсортированные по возрастанию, без самой верхней,\n      val fixedBounds: Map[P, (Array[O], Int)] = (givenBounds ++ innerBounds ++ singleBounds)\n        .groupBy(_._1)\n        .map { case (p, values) =\u003E\n          val (indexes, bounds) = values.flatMap(_._2).unzip\n          p -\u003E (bounds.flatten.sorted.init,\n            indexes.min)\n        }\n \n      Some(fixedBounds)\n  }\n \n  \u002F\u002F Карта с массивами верхних границ для первых (partitions - 1) партиций\n  private var rangeBounds: Map[P, (Array[O], Int)] = getDistribution.getOrElse {\n    if (partitions &lt;= 1) {\n      Map.empty[P, (Array[O], Int)]\n    } else {\n      val groupedBounds = OrderBucketsPartitioner.getBounds(rdd, numLines, partitions)\n \n      \u002F\u002Fиндексы смещений, чтобы обеспечить уникальный номер партиции, если массив границ пустой, то это одна партиция\n      val overallIndex = groupedBounds.scanLeft(1) { case (sum, (_, orders)) =\u003E sum + math.max(orders.length + 1, 1) }\n \n      groupedBounds\n        .zip(overallIndex)\n        .map { case ((part, orders), index) =\u003E (part, (orders, index)) }\n        .toMap\n    }\n  }\n \n  def getRangeBounds: Map[P, (Array[O], Int)] = rangeBounds\n \n  \u002F\u002Fвесь массив плюс одна нулевая партиция для не попавших в сэмпл тасков\n  \u002F\u002F партиции, не попавшие в сэмплы должны быть небольшими, поэтому ничего страшного не будет\n  \u002F\u002F даже если они попадут в один таск, так будет даже лучше - меньше файлов\n  def numPartitions: Int = rangeBounds.values.map(_._1.length + 1).sum + 1\n \n  private var binarySearch: (Array[O], O) =\u003E Int = CollectionsUtils.makeBinarySearch[O]\n \n  def getPartition(key: Any): Int = {\n    val (p, k, _) = key.asInstanceOf[(P, O, InternalRow)]\n    val (bounds, shift) = rangeBounds.getOrElse(p, (Array.empty[O], 0))\n    var partition = 0\n    if (bounds.length &lt; 16) {\n      \u002F\u002F If we have less than 16 partitions naive search\n      while (partition &lt; bounds.length &amp;&amp; ordering.gt(k, bounds(partition))) {\n        partition += 1\n      }\n    } else {\n      \u002F\u002F метод бинарного поиска определён только один раз\n      partition = binarySearch(bounds, k)\n      \u002F\u002F binarySearch either returns the match location or -[insertion point]-1\n      if (partition &lt; 0) {\n        partition = -partition - 1\n      }\n      if (partition \u003E bounds.length) {\n        partition = bounds.length\n      }\n    }\n    shift + partition\n  }\n \n  override def equals(other: Any): Boolean = other match {\n    case r: OrderBucketsPartitioner[_, _] =\u003E\n      r.rangeBounds == rangeBounds\n    case _ =\u003E\n      false\n  }\n \n  override def hashCode(): Int = {\n    val prime = 31\n    var result = 1\n    var i = 0\n    val arr = rangeBounds.values.map(_._1).toArray.flatten\n    while (i &lt; arr.length) {\n      result = prime * result + arr(i).hashCode()\n      i += 1\n    }\n    result = prime * result\n    result\n  }\n \n  @throws(classOf[IOException])\n  private def writeObject(out: ObjectOutputStream): Unit = Utils.tryOrIOException {\n    val sfactory = SparkEnv.get.serializer\n    sfactory match {\n      case _: JavaSerializer =\u003E out.defaultWriteObject()\n      case _ =\u003E\n        out.writeObject(ordering)\n        out.writeObject(binarySearch)\n \n        val ser = sfactory.newInstance()\n        Utils.serializeViaNestedStream(out, ser) { stream =\u003E\n          stream.writeObject(scala.reflect.classTag[Map[P, (Array[O], Int)]])\n          stream.writeObject(rangeBounds)\n        }\n    }\n  }\n \n  @throws(classOf[IOException])\n  private def readObject(in: ObjectInputStream): Unit = Utils.tryOrIOException {\n    val sfactory = SparkEnv.get.serializer\n    sfactory match {\n      case _: JavaSerializer =\u003E in.defaultReadObject()\n      case _ =\u003E\n        ordering = in.readObject().asInstanceOf[Ordering[O]]\n        binarySearch = in.readObject().asInstanceOf[(Array[O], O) =\u003E Int]\n \n        val ser = sfactory.newInstance()\n        Utils.deserializeViaNestedStream(in, ser) { ds =\u003E\n          implicit val classTag: ClassTag[Map[P, (Array[O], Int)]] = ds.readObject[ClassTag[Map[P, (Array[O], Int)]]]()\n          rangeBounds = ds.readObject[Map[P, (Array[O], Int)]]()\n        }\n    }\n  }\n}\n \nobject OrderBucketsPartitioner {\n \n  \u002F**\n   * Рассчитывает коэффициент сэмлирования используя обратную логарифмическую пропорцию,\n   * чем больше набор данных, тем меньше часть, которая будет взята из него\n   *\n   * @param numLines - количество записей в файле - опасное предположение, но сделать его можно\n   * @param numParts - приблизительно оцененное количество партиций\n   *\u002F\n  private def getSampleCoefficient(numLines: Int, numParts: Int): Double = {\n    val numLinesD = numLines.toDouble\n    (1e4 \u002F (numLinesD * math.log(numLinesD * numParts))) min 1.0\n  }\n \n  \u002F**\n   * возвращаяет сэмпл RDD\n   *\n   * @param rdd               - основной набор данных\n   * @param sampleCoefficient - 0 &lt; коэффициент &lt;= 1.0\n   *\u002F\n  private def getSampleRDD[O: Ordering : ClassTag,\n    P: ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],\n                 sampleCoefficient: Double): RDD[_ &lt;: Product2[P, O]] = {\n    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = if (sampleCoefficient &lt; 1.0) {\n      val seed = byteswap32(-rdd.id - 1)\n      rdd.sample(withReplacement = false, sampleCoefficient, seed)\n    } else {\n      rdd\n    }\n    sampledRdd\n  }\n \n  \u002F**\n   * выполняется в каждой партиции сэмлпа RDD\n   * получает верхние границы для каждого файла (таска, партиции RDD)\n   *\n   * @param iter     неотсортированный итератор со значениями партиций и поля упорядочивания\n   * @param initStep шаг, равный желаемому количеству записей в одном файле\n   * @param weight   количество реальных записей на строку сэмпла\n   * @return границы\n   *\u002F\n  private def determineBoundsWithinPartition[P: ClassTag, O: Ordering : ClassTag\n  ](iter: Iterator[(P, O)],\n    weight: Double,\n    initStep: Int): Iterator[(P, Array[O])] = {\n    prepareMap(iter)\n      .map { case (p, ordered) =\u003E\n        val partitions: Int = math.ceil(ordered.length * weight \u002F initStep).intValue()\n        val bounds: Array[O] = extractBounds(ordered, partitions, weight)\n        (p, bounds)\n      }.iterator\n  }\n \n  private def prepareMap[O: Ordering : ClassTag, P: ClassTag](iter: Iterator[(P, O)]): Map[P, Array[O]] = {\n    val mappedParts = iter.toArray\n      .groupBy(_._1)\n      .map { case (p, opArray) =\u003E (p, opArray.map(_._2).sorted) }\n    mappedParts\n  }\n \n  \u002F\u002Fотбор самих значений\n  private def extractBounds[O: Ordering : ClassTag](values: Array[O],\n                                                    partitions: Int,\n                                                    weight: Double)(implicit ordering: Ordering[O]): Array[O] = {\n    val numCandidates = values.length\n    val partCount = numCandidates * weight\n    var cumWeight = 0.0\n    val step: Int = (partCount \u002F partitions).intValue()\n    var target = step\n    val innerBounds = ArrayBuffer.empty[O]\n    var i = 0\n    var j = 0\n    var prevInnerBound = Option.empty[O]\n \n    while ((i &lt; numCandidates) &amp;&amp; (j &lt; partitions - 1)) {\n      val key = values(i)\n      cumWeight += weight\n      if (cumWeight \u003E= target) {\n        \u002F\u002F Skip duplicate values.\n        if (prevInnerBound.isEmpty || ordering.gt(key, prevInnerBound.get)) {\n          innerBounds += key\n          target += step\n          j += 1\n          prevInnerBound = Some(key)\n        }\n      }\n      i += 1\n    }\n    innerBounds.toArray\n  }\n \n  \u002F**\n   * сэмплирует RDD и получает карту, где ключи - значения полей партиционирования,\n   * значения - массивы с верхними границами поля упорядочивания\n   *\n   * @param rdd      основной набор данных\n   * @param numLines желаемое количество записей в одном файле\n   * @param numParts предполагаемое количество записей\n   * @return границы\n   *\u002F\n  private def getBounds[P: ClassTag, O: Ordering : ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],\n                                                             numLines: Int,\n                                                             numParts: Int): Array[(P, Array[O])] = {\n    val sampleCoefficient = getSampleCoefficient(numLines, numParts) \u002F\u002Frdd.partitions.length\n \n    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = getSampleRDD(rdd, sampleCoefficient)\n \n    val weight = 1.0 \u002F sampleCoefficient\n    sampledRdd\n      .map(row =\u003E (row._1, row._2))\n      .partitionBy(new Partitioner {\n        override def numPartitions: Int = numParts\n \n        override def getPartition(key: Any): Int = Utils.nonNegativeMod(key.hashCode, numParts)\n      })\n      .mapPartitions(iter =\u003E determineBoundsWithinPartition(iter, weight, numLines))\n      .collect()\n  }\n \n \n  \u002F**\n   * фильтрует RDD на равенство полей к нужным значениям и по нахождению в пределах внешних границ\n   *\n   * @param rdd    основной набор данных\n   * @param bounds границы RDD\n   * @return тщательно отфильтрованный RDD\n   *\u002F\n  private def filterRDDByOuterBounds[P: ClassTag, O: Ordering : ClassTag\n  ](rdd: RDD[_ &lt;: Product2[P, O]],\n    bounds: Map[P, Seq[(Int, (O, O, Int))]]): RDD[_ &lt;: Product2[P, O]] = {\n    val ordering = implicitly[Ordering[O]]\n    \u002F\u002Fполучаем Option[Array[Tuple3]] и проверяем exists\n    rdd\n      .filter { item =\u003E\n        bounds\n          .get(item._1)\n          .exists(_.exists(b =\u003E ordering.lteq(b._2._1, item._2) &amp;&amp; ordering.lteq(item._2, b._2._2)))\n      }\n  }\n \n  \u002F**\n   * выполняется в каждой партиции сэмлпа RDD\n   * получает верхние границы для каждого файла (таска, партиции RDD)\n   *\n   * @param iter     неотсортированный итератор со значениями партиций и поля упорядочивания\n   * @param initStep шаг, равный желаемому количеству записей в одном файле\n   * @param weight   количество реальных записей на строку сэмпла\n   * @return границы\n   *\u002F\n  private def determineInnerBoundsWithinPartition[P: ClassTag, O: Ordering : ClassTag\n  ](iter: Iterator[(P, O)],\n    weight: Double,\n    initStep: Int,\n    outerBounds: Map[P, Seq[(Int, (O, O, Int))]]): Iterator[(P, Array[(Int, Array[O])])] = {\n    val ordering = implicitly[Ordering[O]]\n \n    prepareMap(iter)\n      .map { case (p, orderedValues) =\u003E\n        (p, outerBounds(p).toArray.map { case (index, (lowerO, upperO, partitions)) =\u003E\n          val ordered = orderedValues\n            .dropWhile(ordering.lt(_, lowerO))\n            .takeWhile(ordering.lteq(_, upperO))\n \n          val innerBounds: Array[O] = extractBounds(ordered, partitions, weight)\n \n          (index, innerBounds :+ upperO)\n        })\n      }.iterator\n  }\n \n  \u002F**\n   * сэмплирует RDD и получает карту, где ключи - значения полей партиционирования,\n   * значения - массивы с верхними границами поля упорядочивания\n   * Важно, чтобы можно было использовать верхние границы в пределах партиции,\n   * чтобы не допустить поглощения возможных внутренних партиций\n   *\n   * @param rdd      основной набор данных\n   * @param numLines желаемое количество записей в одном файле\n   * @param numParts предполагаемое количество записей\n   * @param bounds   внешние границы RDD\n   * @return границы\n   *\u002F\n  private def getInnerBounds[P: ClassTag, O: Ordering : ClassTag](rdd: RDD[_ &lt;: Product2[P, O]],\n                                                                  numLines: Int,\n                                                                  numParts: Int,\n                                                                  bounds: Map[P, Seq[(Int, (O, O, Int))]]\n                                                                 ): Array[(P, Array[(Int, Array[O])])] = {\n    val sampleCoefficient = getSampleCoefficient(numLines, numParts) \u002F\u002Frdd.partitions.length\n \n    val filterRdd: RDD[_ &lt;: Product2[P, O]] = filterRDDByOuterBounds(rdd, bounds)\n    val sampledRdd: RDD[_ &lt;: Product2[P, O]] = getSampleRDD(filterRdd, sampleCoefficient)\n \n    val weight = 1.0 \u002F sampleCoefficient\n    sampledRdd\n      .map(row =\u003E (row._1, row._2))\n      .partitionBy(new Partitioner {\n        override def numPartitions: Int = numParts\n \n        override def getPartition(key: Any): Int = Utils.nonNegativeMod(key.hashCode, bounds.size)\n      })\n      .mapPartitions(iter =\u003E determineInnerBoundsWithinPartition(iter, weight, numLines, bounds))\n      .collect()\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EЧтобы связать физический план и само выполнение, нам нужно будет создать объект, расширяющий SparkStrategy.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003ERepartitionStrategy\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.rangebucketing.strategy\n \nimport org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\nimport org.apache.spark.sql.execution.{SparkPlan, SparkStrategy, exchange}\nimport ru.kalininskii.rangebucketing.plans.logical.RepartitionByRangeBuckets\n \nobject RepartitionStrategy extends SparkStrategy {\n  override def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match {\n    case r: RepartitionByRangeBuckets =\u003E\n      exchange.ShuffleExchangeBucketsExec(r.partitioning, planLater(r.child)) :: Nil\n    case _ =\u003E Nil\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EТеперь можно сделать инъекцию расширения в SparkSession:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EExtension injection\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Espark = SparkSession\n  .builder()\n  .appName(\"PARTITION_TEST\")\n  .master(\"local[*]\")\n  .config(sparkConf)\n  .withExtensions(e =\u003E {\n    e.injectPlannerStrategy(_ =\u003E RepartitionStrategy)\n  })\n  .getOrCreate()\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EЕсли инъекции или способа реализации партишенера не будет, то мы увидим такую ошибку:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EСообщение об ошибке\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Eassertion failed: No plan for RepartitionWithOrderAndSort [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24\n+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]\n   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)\n         +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]\n\njava.lang.AssertionError: assertion failed: No plan for RepartitionWithOrderAndSort [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24\n+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]\n   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)\n         +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]\n\n         at scala.Predef$.assert(Predef.scala:170)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:78)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:75)\n         at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n         at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n         at scala.collection.Iterator$class.foreach(Iterator.scala:891)\n         at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n         at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n         at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:75)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:67)\n         at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n         at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n         at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n         at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:72)\n         at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:68)\n         at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:77)\n         at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:77)\n         at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)\n         at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)\n         at org.apache.spark.sql.execution.QueryExecution.stringOrError(QueryExecution.scala:99)\n         at org.apache.spark.sql.execution.QueryExecution.toString(QueryExecution.scala:207)\n         at org.apache.spark.sql.execution.command.ExplainCommand.run(commands.scala:167)\n         at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n         at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n         at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)\n         at org.apache.spark.sql.Dataset.explain(Dataset.scala:485)\n         at ru.kalininskii.rangebucketing.RangeBucketingPartitionTest$$anonfun$1.apply(RangeBucketingPartitionTest.scala:49)\n         at ru.kalininskii.rangebucketing.RangeBucketingPartitionTest$$anonfun$1.apply(RangeBucketingPartitionTest.scala:42)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003E\u003Cem\u003EСгенерируем набор данных с псевдослучайными значениями и применим к нему созданный партишенер\u003C\u002Fem\u003E: \u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EДатафрейм\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003E    val dataFrameSource = getRandomDF(0, rangeLimit, 3, 0).persist()\n      .withColumn(\"ts_part\", fn.expr(\"substring(ts,0,10)\"))\n \n    dataFrameSource.printSchema()\n \n    val dfRep = dataFrameSource\n      .repartitionWithOrderAndSort(numLines, rangeLimit \u002F numLines,\n        fn.col(\"event_time\"), List(fn.col(\"ts_part\")), List(fn.col(\"id\")))\n      .persist()\n \n    dfRep.explain(true)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EВ планах выполнения видны новые пункты, на всех этапах их можно отследить\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EПлан запроса с применением партишенера\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003E== Parsed Logical Plan ==\n'Repartition with unknown distribution: ['ts_part], 'id ASC NULLS FIRST, 4000, 24\n+- 'Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, 'substring('ts, 0, 10) AS ts_part#55]\n   +- Project [_1#6 AS id#13, _2#7 AS name#14, _3#8 AS amount#15, _4#9 AS value#16, _5#10 AS divider#17, _6#11 AS ts#18]\n      +- LocalRelation [_1#6, _2#7, _3#8, _4#9, _5#10, _6#11]\n\n== Analyzed Logical Plan ==\nid: int, name: string, amount: decimal(38,18), value: decimal(38,18), divider: string, ts: timestamp, ts_part: string\nRepartition with unknown distribution: [ts_part#55], id#13 ASC NULLS FIRST, 4000, 24\n+- Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]\n   +- Project [_1#6 AS id#13, _2#7 AS name#14, _3#8 AS amount#15, _4#9 AS value#16, _5#10 AS divider#17, _6#11 AS ts#18]\n      +- LocalRelation [_1#6, _2#7, _3#8, _4#9, _5#10, _6#11]\n\n== Optimized Logical Plan ==\nInMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55], StorageLevel(disk, memory, deserialized, 1 replicas)\n   +- ExchangeByRangeBuckets repartition with unknown distribution:(ts_part#55, id#13 ASC NULLS FIRST, 4000, 24, None)\n      +- *(1) Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]\n         +- InMemoryTableScan [amount#15, divider#17, id#13, name#14, ts#18, value#16]\n               +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)\n                     +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]\n\n== Physical Plan ==\nInMemoryTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55]\n   +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18, ts_part#55], StorageLevel(disk, memory, deserialized, 1 replicas)\n         +- ExchangeByRangeBuckets repartition with unknown distribution:(ts_part#55, id#13 ASC NULLS FIRST, 4000, 24, None)\n            +- *(1) Project [id#13, name#14, amount#15, value#16, divider#17, ts#18, substring(cast(ts#18 as string), 0, 10) AS ts_part#55]\n               +- InMemoryTableScan [amount#15, divider#17, id#13, name#14, ts#18, value#16]\n                     +- InMemoryRelation [id#13, name#14, amount#15, value#16, divider#17, ts#18], StorageLevel(disk, memory, deserialized, 1 replicas)\n                           +- LocalTableScan [id#13, name#14, amount#15, value#16, divider#17, ts#18]\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EТесты должны показать, что классы планов на самом деле используются (простые юнит-тесты планов Spark):\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EИспользование классов \u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003E    val logicalPlanString = \"Repartition plan with unknown distribution: \" +\n      \"partition by ['ts_part], \" +\n      \"global order by 'event_time, \" +\n      \"local sort by ['id], \" +\n      \"4000 rows per task, 24 initial tasks\"\n \n    val analyzedPlanString = \"Repartition plan with unknown distribution: \" +\n      \"partition by [ts_part#64], \" +\n      \"global order by event_time#21, \" +\n      \"local sort by [id#15], \" +\n      \"4000 rows per task, 24 initial tasks\"\n \n    val sparkPlanString = \"ExchangeWithOrder Repartition with unknown distribution: \" +\n      \"partition by [ts_part#64], \" +\n      \"global order by event_time#21, \" +\n      \"local sort by [id#15], \" +\n      \"4000 rows per task, 24 initial tasks\"\n \n    assert(dfRep.queryExecution.logical.toString contains logicalPlanString)\n    assert(dfRep.queryExecution.analyzed.toString contains analyzedPlanString)\n    assert(dfRep.queryExecution.sparkPlan.toString contains sparkPlanString)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EКоличество секций всегда будет равно 28\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКоличество партиций RDD\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Eprintln(dfRep.rdd.getNumPartitions)\n28\ndfRep.rdd.getNumPartitions should be(28)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EВыведем датафрейм с номерами партиций, нулевая партиция должна отсутствовать, потому что не содержит ни одного значения. Количество – колонка «cnt_» - всегда немного меньше и количество достаточно равномерное, отклонение, как правило, остаётся в пределах пяти процентов.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКоличество записей в партициях RDD\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003E+----------+-----------+-----------------------+-----------------------+----+\n|ts_part   |rdd_part_id|range_min_event_time   |range_max_event_time   |cnt_|\n+----------+-----------+-----------------------+-----------------------+----+\n|2021-09-05|10         |2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3672|\n|2021-09-05|11         |2021-09-05 21:57:56.455|2021-09-05 21:57:56.547|3400|\n|2021-09-05|12         |2021-09-05 21:57:56.548|2021-09-05 21:57:56.642|3761|\n|2021-09-05|13         |2021-09-05 21:57:56.643|2021-09-06 21:57:56.447|3601|\n|2021-09-05|14         |2021-09-06 21:57:56.448|2021-09-06 21:57:56.544|3601|\n|2021-09-05|15         |2021-09-06 21:57:56.545|2021-09-06 21:57:56.641|3856|\n|2021-09-05|16         |2021-09-06 21:57:56.642|2021-09-07 21:57:56.449|3711|\n|2021-09-05|17         |2021-09-07 21:57:56.45 |2021-09-07 21:57:56.549|3703|\n|2021-09-05|18         |2021-09-07 21:57:56.55 |2021-09-07 21:57:56.647|3776|\n|2021-09-06|19         |2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3763|\n|2021-09-06|20         |2021-09-05 21:57:56.455|2021-09-05 21:57:56.564|3916|\n|2021-09-06|21         |2021-09-05 21:57:56.565|2021-09-06 21:57:56.241|3557|\n|2021-09-06|22         |2021-09-06 21:57:56.242|2021-09-06 21:57:56.459|3721|\n|2021-09-06|23         |2021-09-06 21:57:56.46 |2021-09-06 21:57:56.563|3714|\n|2021-09-06|24         |2021-09-06 21:57:56.564|2021-09-07 21:57:56.246|3520|\n|2021-09-06|25         |2021-09-07 21:57:56.247|2021-09-07 21:57:56.455|3671|\n|2021-09-06|26         |2021-09-07 21:57:56.456|2021-09-07 21:57:56.556|3716|\n|2021-09-06|27         |2021-09-07 21:57:56.557|2021-09-07 21:57:56.647|3670|\n|2021-09-07|1          |2021-09-05 21:57:56.188|2021-09-05 21:57:56.454|3690|\n|2021-09-07|2          |2021-09-05 21:57:56.455|2021-09-05 21:57:56.556|3704|\n|2021-09-07|3          |2021-09-05 21:57:56.557|2021-09-05 21:57:56.644|3601|\n|2021-09-07|4          |2021-09-05 21:57:56.645|2021-09-06 21:57:56.45 |3685|\n|2021-09-07|5          |2021-09-06 21:57:56.451|2021-09-06 21:57:56.55 |3767|\n|2021-09-07|6          |2021-09-06 21:57:56.551|2021-09-06 21:57:56.644|3846|\n|2021-09-07|7          |2021-09-06 21:57:56.645|2021-09-07 21:57:56.452|3782|\n|2021-09-07|8          |2021-09-07 21:57:56.453|2021-09-07 21:57:56.555|3775|\n|2021-09-07|9          |2021-09-07 21:57:56.556|2021-09-07 21:57:56.647|3820|\n+----------+-----------+-----------------------+-----------------------+----+\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EСохраним и выведем, чтобы убедиться, что все файлы соответствуют исходными секциям\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EПроверка соответствия\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003EdfRep\n      .withColumn(\"rdd_part_id\", fn.spark_partition_id())\n      .groupBy(fn.col(\"ts_part\") as \"ts_part\", fn.col(\"rdd_part_id\"))\n      .agg(fn.min(\"event_time\") as \"range_min_event_time\",\n        fn.max(\"event_time\") as \"range_max_event_time\",\n        fn.count(fn.lit(0)) as \"cnt_\")\n      .orderBy(\"ts_part\", \"rdd_part_id\")\n      .show(100, false)\n \n    dfRep\n      .sortWithinPartitions(fn.col(\"id\"))\n      .write\n      .mode(SaveMode.Overwrite)\n      .partitionBy(\"ts_part\")\n      .format(\"parquet\")\n      .option(\"path\", \"\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\")\n      .saveAsTable(\"testschema.sometable\")\n \n    val dfT = spark.table(\"testschema.sometable\")\n \n    println(dfT.count)\n \n    dfT\n      .withColumn(\"file_name\",\n        fn.regexp_replace(fn.input_file_name(), \".*\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\", \"\"))\n      .groupBy(fn.col(\"ts_part\") as \"ts_part\", fn.col(\"file_name\"))\n      .agg(fn.min(\"event_time\") as \"range_min_event_time\",\n        fn.max(\"event_time\") as \"range_max_event_time\",\n        fn.count(fn.lit(0)) as \"cnt_\")\n      .orderBy(\"file_name\")\n      .show(100, false)\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cpre\u003E\u003Ccode\u003E+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+\n|ts_part   |file_name                                                                              |range_min_event_time   |range_max_event_time   |cnt_|\n+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00010-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3672|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00011-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.547|3400|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00012-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.548|2021-09-05 21:57:56.642|3761|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00013-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.643|2021-09-06 21:57:56.447|3601|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00014-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.448|2021-09-06 21:57:56.544|3601|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00015-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.545|2021-09-06 21:57:56.641|3856|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00016-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.642|2021-09-07 21:57:56.449|3711|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00017-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.45 |2021-09-07 21:57:56.549|3703|\n|2021-09-05|\u002Fts_part=2021-09-05\u002Fpart-00018-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.55 |2021-09-07 21:57:56.647|3776|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00019-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.186|2021-09-05 21:57:56.454|3763|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00020-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.564|3916|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00021-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.565|2021-09-06 21:57:56.241|3557|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00022-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.242|2021-09-06 21:57:56.459|3721|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00023-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.46 |2021-09-06 21:57:56.563|3714|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00024-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.564|2021-09-07 21:57:56.246|3520|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00025-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.247|2021-09-07 21:57:56.455|3671|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00026-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.456|2021-09-07 21:57:56.556|3716|\n|2021-09-06|\u002Fts_part=2021-09-06\u002Fpart-00027-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.557|2021-09-07 21:57:56.647|3670|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00001-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.188|2021-09-05 21:57:56.454|3690|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00002-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.455|2021-09-05 21:57:56.556|3704|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00003-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.557|2021-09-05 21:57:56.644|3601|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00004-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-05 21:57:56.645|2021-09-06 21:57:56.45 |3685|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00005-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.451|2021-09-06 21:57:56.55 |3767|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00006-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.551|2021-09-06 21:57:56.644|3846|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00007-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-06 21:57:56.645|2021-09-07 21:57:56.452|3782|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00008-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.453|2021-09-07 21:57:56.555|3775|\n|2021-09-07|\u002Fts_part=2021-09-07\u002Fpart-00009-28321a07-711d-4936-b305-680199f90649.c000.snappy.parquet|2021-09-07 21:57:56.556|2021-09-07 21:57:56.647|3820|\n+----------+---------------------------------------------------------------------------------------+-----------------------+-----------------------+----+\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003E Как видим, интервалы сохранились, для этого не потребовалось никаких дополнительных действий. Количество файлов для этого случая всегда на один меньше, чем количество секций в RDD. Однако в общем случае это не так, ведь в нулевую секцию могут попасть данные из очень небольших физических партиций. dfT.inputFiles.length should \u003Cem\u003Ebe\u003C\u002Fem\u003E(dfRep.\u003Cem\u003Erdd\u003C\u002Fem\u003E.getNumPartitions - 1)\u003C\u002Fp\u003E\u003Cp\u003EКоличество записей осталось прежним:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EКоличество записей в сохраненных файлах\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Eval savedCount = dfT.count\nsavedCount shouldEqual rangeLimit\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EИ схема датафрейма не изменилась, партишенер не меняет порядок полей и их типы.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EСхемы совпадают\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003EdfT.printSchema()\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cpre\u003E\u003Ccode\u003Eroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- amount: decimal(38,18) (nullable = true)\n |-- value: decimal(38,18) (nullable = true)\n |-- divider: string (nullable = true)\n |-- ts: timestamp (nullable = true)\n |-- event_time: timestamp (nullable = true)\n |-- ts_part: string (nullable = true)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cpre\u003E\u003Ccode\u003EdfT.schema should be (dataFrameSource.schema)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003E Для того, чтобы убедиться, что сортировка работает, выведем все записи с \"id\" меньшим 32, без дополнительной сортировки. Мы увидим, что в пределах файла записи отсортированы по возрастанию поля \"id\", несмотря на то, что были специально перемешаны при создании датафрейма.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EПроверка локальной сортировки\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003EdfT\n  .withColumn(\"file_name\",\n    fn.regexp_replace(fn.input_file_name(), \".*\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\", \"\"))\n  .select(\"id\", \"file_name\")\n  .where(\"id &lt; 32\")\n  .show(32, false)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cpre\u003E\u003Ccode\u003E+---+---------------------------------------------------------------------------------------+\n|id |file_name                                                                              |\n+---+---------------------------------------------------------------------------------------+\n|9  |\u002Fts_part=2021-09-06\u002Fpart-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|15 |\u002Fts_part=2021-09-06\u002Fpart-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|19 |\u002Fts_part=2021-09-06\u002Fpart-00022-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|25 |\u002Fts_part=2021-09-07\u002Fpart-00004-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|4  |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|13 |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|14 |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|16 |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|28 |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|31 |\u002Fts_part=2021-09-07\u002Fpart-00006-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|8  |\u002Fts_part=2021-09-05\u002Fpart-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|12 |\u002Fts_part=2021-09-05\u002Fpart-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|21 |\u002Fts_part=2021-09-05\u002Fpart-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|30 |\u002Fts_part=2021-09-05\u002Fpart-00012-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|10 |\u002Fts_part=2021-09-05\u002Fpart-00015-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|27 |\u002Fts_part=2021-09-05\u002Fpart-00015-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|0  |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|1  |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|3  |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|20 |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|22 |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|26 |\u002Fts_part=2021-09-06\u002Fpart-00024-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|18 |\u002Fts_part=2021-09-07\u002Fpart-00001-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|5  |\u002Fts_part=2021-09-05\u002Fpart-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|6  |\u002Fts_part=2021-09-05\u002Fpart-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|23 |\u002Fts_part=2021-09-05\u002Fpart-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|24 |\u002Fts_part=2021-09-05\u002Fpart-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|29 |\u002Fts_part=2021-09-05\u002Fpart-00010-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|2  |\u002Fts_part=2021-09-06\u002Fpart-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|7  |\u002Fts_part=2021-09-06\u002Fpart-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|11 |\u002Fts_part=2021-09-06\u002Fpart-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n|17 |\u002Fts_part=2021-09-06\u002Fpart-00019-ec8ffbb5-474a-4ce1-bcdb-cc5665800031.c000.snappy.parquet|\n+---+---------------------------------------------------------------------------------------+\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EДобавлю полные тестовые классы и pom.xml для сборки Maven:\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EТесты\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing\n\nimport java.sql.Timestamp\nimport java.time.LocalDateTime\n\nimport org.apache.spark.sql.{SaveMode, functions =\u003E fn}\nimport org.scalatest.flatspec.AnyFlatSpec\nimport org.scalatest.matchers.should.Matchers._\nimport ru.kalininskii.orderbucketing.OrderBucketing._\n\nimport scala.util.Random\n\nclass OrderPartitionTest extends AnyFlatSpec with SparkBuilder {\n\n  val rangeLimit = 99999\n  val seed = 111\n  val numLines = 4000\n\n  private def getRandomDF(start: Int, limit: Int, days: Int, daysMinus: Int) = {\n    val rnd = new Random()\n    rnd.setSeed(seed)\n\n    val sparkSession = spark\n    import sparkSession.implicits._\n\n    val list = Range(start, limit)\n      .toList\n      .map(id =\u003E (Option(id), \u002F\u002Fid, Option для nullable = true\n        rnd.alphanumeric.take(rnd.nextInt(32)).mkString, \u002F\u002Fname\n        BigDecimal(rnd.nextInt().abs * rnd.nextDouble()), \u002F\u002Famount\n        BigDecimal(rnd.nextLong().abs.longValue()), \u002F\u002Fvalue\n        rnd.alphanumeric.take(rnd.nextInt(3)).mkString, \u002F\u002Fdivider\n        Timestamp.valueOf(LocalDateTime.now().minusSeconds((rnd.nextInt(days).abs max daysMinus) * 24 * 60 * 60)), \u002F\u002Fts\n        Timestamp.valueOf(LocalDateTime.now().minusSeconds((rnd.nextInt(days).abs max daysMinus) * 24 * 60 * 60)) \u002F\u002Fevent_time\n      ))\n\n    Random.shuffle(list).toDF(\"id\", \"name\", \"amount\", \"value\", \"divider\", \"ts\", \"event_time\")\n\n  }\n\n  override def beforeAll() {\n    super.beforeAll()\n    spark.sql(\"create database if not exists testschema location '\u002Ftest'\")\n  }\n\n  \"Range buckets partitioner\" must \"partition correctly\" in {\n    val dataFrameSource = getRandomDF(0, rangeLimit, 3, 0).persist()\n      .withColumn(\"ts_part\", fn.expr(\"substring(ts,0,10)\"))\n\n    dataFrameSource.printSchema()\n\n    val dfRep = dataFrameSource\n      .repartitionWithOrderAndSort(numLines, rangeLimit \u002F numLines,\n        fn.col(\"event_time\"), List(fn.col(\"ts_part\")), List(fn.col(\"id\")))\n      .persist()\n\n    dfRep.explain(true)\n\n    val logicalPlanString = \"Repartition plan with unknown distribution: \" +\n      \"partition by ['ts_part], \" +\n      \"global order by 'event_time, \" +\n      \"local sort by ['id], \" +\n      \"4000 rows per task, 24 initial tasks\"\n\n    val analyzedPlanString = \"Repartition plan with unknown distribution: \" +\n      \"partition by [ts_part#64], \" +\n      \"global order by event_time#21, \" +\n      \"local sort by [id#15], \" +\n      \"4000 rows per task, 24 initial tasks\"\n\n    val sparkPlanString = \"ExchangeWithOrder Repartition with unknown distribution: \" +\n      \"partition by [ts_part#64], \" +\n      \"global order by event_time#21, \" +\n      \"local sort by [id#15], \" +\n      \"4000 rows per task, 24 initial tasks\"\n\n    assert(dfRep.queryExecution.logical.toString contains logicalPlanString)\n    assert(dfRep.queryExecution.analyzed.toString contains analyzedPlanString)\n    assert(dfRep.queryExecution.sparkPlan.toString contains sparkPlanString)\n\n    println(dfRep.rdd.getNumPartitions)\n\n    dfRep.rdd.getNumPartitions should be(28)\n\n    dfRep\n      .withColumn(\"rdd_part_id\", fn.spark_partition_id())\n      .groupBy(fn.col(\"ts_part\") as \"ts_part\", fn.col(\"rdd_part_id\"))\n      .agg(fn.min(\"event_time\") as \"range_min_event_time\",\n        fn.max(\"event_time\") as \"range_max_event_time\",\n        fn.count(fn.lit(0)) as \"cnt_\")\n      .orderBy(\"ts_part\", \"rdd_part_id\")\n      .show(100, false)\n\n    dfRep\n      .sortWithinPartitions(fn.col(\"id\"))\n      .write\n      .mode(SaveMode.Overwrite)\n      .partitionBy(\"ts_part\")\n      .format(\"parquet\")\n      .option(\"path\", \"\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\")\n      .saveAsTable(\"testschema.sometable\")\n\n    val dfT = spark.table(\"testschema.sometable\")\n\n    val savedCount = dfT.count\n    savedCount shouldEqual rangeLimit\n\n    dfT\n      .withColumn(\"file_name\",\n        fn.regexp_replace(fn.input_file_name(), \".*\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\", \"\"))\n      .groupBy(fn.col(\"ts_part\") as \"ts_part\", fn.col(\"file_name\"))\n      .agg(fn.min(\"event_time\") as \"range_min_event_time\",\n        fn.max(\"event_time\") as \"range_max_event_time\",\n        fn.count(fn.lit(0)) as \"cnt_\")\n      .orderBy(\"file_name\")\n      .show(100, false)\n\n    dfT.printSchema()\n\n    dfT.inputFiles.length should be(dfRep.rdd.getNumPartitions - 1)\n\n    dfT.schema should be(dataFrameSource.schema)\n\n    dfT\n      .withColumn(\"file_name\",\n        fn.regexp_replace(fn.input_file_name(), \".*\u002Ftest\u002Fpa\u002Fsometable\u002Fsnp\", \"\"))\n      .select(\"id\", \"file_name\")\n      .where(\"id &lt; 32\")\n      .show(32, false)\n\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EСоздание Hadoop Minicluster для тестов\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing\n \nimport java.io.File\nimport java.nio.file.Files\n \nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileUtil\nimport org.apache.hadoop.hdfs.MiniDFSCluster\nimport org.apache.log4j.{Level, Logger}\nimport org.scalatest.{BeforeAndAfterAll, TestSuite}\n \ntrait MiniHdfsBuilder extends BeforeAndAfterAll {\n  this: TestSuite =\u003E\n \n  val baseDir: File = Files.createTempDirectory(\"test_hdfs\").toFile.getAbsoluteFile\n \n  val fsConf: Configuration = new Configuration()\n  fsConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, baseDir.getAbsolutePath)\n \n  val builder: MiniDFSCluster.Builder = new MiniDFSCluster.Builder(fsConf)\n  var hdfsCluster: MiniDFSCluster = _\n \n  override def beforeAll() {\n    super.beforeAll()\n \n    Logger.getLogger(\"org.apache.hadoop\").setLevel(Level.WARN)\n    Logger.getLogger(\"org.apache.spark\").setLevel(Level.WARN)\n    Logger.getLogger(\"org.spark_project.jetty.server\").setLevel(Level.WARN)\n \n    hdfsCluster = builder.build()\n  }\n \n  override def afterAll() {\n    try {\n      super.afterAll()\n    }\n    finally {\n      hdfsCluster.shutdown()\n      FileUtil.fullyDelete(baseDir)\n    }\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EСоздание SparkSession для тестов\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003Epackage ru.kalininskii.orderbucketing\nimport java.io.File\n \nimport org.apache.hadoop.fs.FileUtil\nimport org.apache.hadoop.hdfs.DistributedFileSystem\nimport org.apache.spark.SparkConf\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.TestSuite\nimport ru.kalininskii.orderbucketing.strategy.RepartitionStrategy\n \ntrait SparkBuilder extends MiniHdfsBuilder {\n  this: TestSuite =\u003E\n  var fileSystem: DistributedFileSystem = _\n \n  var spark: SparkSession = _\n \n  override def beforeAll() {\n    super.beforeAll()\n    \u002F\u002Fсессия уже может быть создана, поэтому нужно попробовать ее найти и остановить\n    spark = SparkSession\n      .builder()\n      .appName(\"DUMMY\")\n      .master(\"local[*]\")\n      .getOrCreate()\n \n    spark.stop()\n \n    fileSystem = hdfsCluster.getFileSystem()\n \n    val sparkConf = new SparkConf().setMaster(\"local[*]\").setAppName(\"RANGE BUCKET TEST\")\n    sparkConf.set(\"fs.defaultFS\", fileSystem.getUri.toString)\n \n    spark = SparkSession\n      .builder()\n      .appName(\"PARTITION_TEST\")\n      .master(\"local[*]\")\n      .config(sparkConf)\n      .withExtensions(e =\u003E {\n        e.injectPlannerStrategy(_ =\u003E RepartitionStrategy)\n      })\n      .getOrCreate()\n \n    spark.sparkContext.setLogLevel(\"WARN\")\n  }\n \n  override def afterAll(): Unit = {\n    spark.stop()\n    FileUtil.fullyDelete(new File(\".\u002Fmetastore_db\"))\n    FileUtil.fullyDelete(new File(\".\u002Fspark-warehouse\"))\n    FileUtil.fullyDelete(new File(\".\u002Fderby.log\"))\n    FileUtil.fullyDelete(new File(\".\u002Fchk\"))\n \n    super.afterAll()\n  }\n}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003Epom.xml для Maven\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Cpre\u003E\u003Ccode\u003E&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?\u003E\n&lt;project xmlns=\"http:\u002F\u002Fmaven.apache.org\u002FPOM\u002F4.0.0\"\n         xmlns:xsi=\"http:\u002F\u002Fwww.w3.org\u002F2001\u002FXMLSchema-instance\"\n         xsi:schemaLocation=\"http:\u002F\u002Fmaven.apache.org\u002FPOM\u002F4.0.0 http:\u002F\u002Fmaven.apache.org\u002Fxsd\u002Fmaven-4.0.0.xsd\"\u003E\n    &lt;modelVersion\u003E4.0.0&lt;\u002FmodelVersion\u003E\n \n    &lt;groupId\u003Efine-grained&lt;\u002FgroupId\u003E\n    &lt;artifactId\u003Erange-bucketing&lt;\u002FartifactId\u003E\n    &lt;version\u003E0.1-SNAPSHOT&lt;\u002Fversion\u003E\n \n    &lt;properties\u003E\n        &lt;spark.version\u003E2.4.0&lt;\u002Fspark.version\u003E\n        &lt;hadoop.version\u003E3.1.1&lt;\u002Fhadoop.version\u003E\n        &lt;scala.version\u003E2.11.8&lt;\u002Fscala.version\u003E\n        &lt;maven.compiler.source\u003E1.8&lt;\u002Fmaven.compiler.source\u003E\n        &lt;maven.compiler.target\u003E1.8&lt;\u002Fmaven.compiler.target\u003E\n        &lt;project.build.sourceEncoding\u003EUTF-8&lt;\u002Fproject.build.sourceEncoding\u003E\n    &lt;\u002Fproperties\u003E\n \n    &lt;dependencies\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.apache.spark&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Espark-core_2.11&lt;\u002FartifactId\u003E\n            &lt;version\u003E${spark.version}&lt;\u002Fversion\u003E\n            &lt;scope\u003Eprovided&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.apache.spark&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Espark-sql_2.11&lt;\u002FartifactId\u003E\n            &lt;version\u003E${spark.version}&lt;\u002Fversion\u003E\n            &lt;scope\u003Eprovided&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.scala-lang&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Escala-library&lt;\u002FartifactId\u003E\n            &lt;version\u003E${scala.version}&lt;\u002Fversion\u003E\n            &lt;scope\u003Eprovided&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.apache.hadoop&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Ehadoop-minicluster&lt;\u002FartifactId\u003E\n            &lt;version\u003E${hadoop.version}&lt;\u002Fversion\u003E\n            &lt;scope\u003Etest&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.apache.spark&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Espark-hive_2.11&lt;\u002FartifactId\u003E\n            &lt;version\u003E${spark.version}&lt;\u002Fversion\u003E\n            &lt;scope\u003Etest&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.scalatest&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Escalatest_2.11&lt;\u002FartifactId\u003E\n            &lt;version\u003E3.1.1&lt;\u002Fversion\u003E\n            &lt;scope\u003Etest&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n        &lt;dependency\u003E\n            &lt;groupId\u003Eorg.scalactic&lt;\u002FgroupId\u003E\n            &lt;artifactId\u003Escalactic_2.11&lt;\u002FartifactId\u003E\n            &lt;version\u003E3.1.1&lt;\u002Fversion\u003E\n            &lt;scope\u003Etest&lt;\u002Fscope\u003E\n        &lt;\u002Fdependency\u003E\n    &lt;\u002Fdependencies\u003E\n \n    &lt;build\u003E\n        &lt;!--   Java sources path:     --\u003E\n        &lt;!--        &lt;resources\u003E--\u003E\n        &lt;!--            &lt;resource\u003E--\u003E\n        &lt;!--                &lt;directory\u003Esrc\u002Fmain\u002Fscala&lt;\u002Fdirectory\u003E--\u003E\n        &lt;!--            &lt;\u002Fresource\u003E--\u003E\n        &lt;!--        &lt;\u002Fresources\u003E--\u003E\n        &lt;!--   For JaCoCo:     --\u003E\n        &lt;sourceDirectory\u003Esrc\u002Fmain\u002Fscala&lt;\u002FsourceDirectory\u003E\n        &lt;finalName\u003E${project.artifactId}&lt;\u002FfinalName\u003E\n        &lt;plugins\u003E\n            &lt;!-- display active profile in compile phase --\u003E\n            &lt;plugin\u003E\n                &lt;groupId\u003Eorg.apache.maven.plugins&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Emaven-help-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E3.2.0&lt;\u002Fversion\u003E\n                &lt;executions\u003E\n                    &lt;execution\u003E\n                        &lt;id\u003Eshow-profiles&lt;\u002Fid\u003E\n                        &lt;phase\u003Ecompile&lt;\u002Fphase\u003E\n                        &lt;goals\u003E\n                            &lt;goal\u003Eactive-profiles&lt;\u002Fgoal\u003E\n                        &lt;\u002Fgoals\u003E\n                    &lt;\u002Fexecution\u003E\n                &lt;\u002Fexecutions\u003E\n            &lt;\u002Fplugin\u003E\n            &lt;plugin\u003E\n                &lt;groupId\u003Eorg.apache.maven.plugins&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Emaven-jar-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E3.2.0&lt;\u002Fversion\u003E\n                &lt;configuration\u003E\n                    &lt;archive\u003E\n                        &lt;manifest\u003E\n                            &lt;addDefaultImplementationEntries\u003Etrue&lt;\u002FaddDefaultImplementationEntries\u003E\n                            &lt;addDefaultSpecificationEntries\u003Etrue&lt;\u002FaddDefaultSpecificationEntries\u003E\n                        &lt;\u002Fmanifest\u003E\n                    &lt;\u002Farchive\u003E\n                &lt;\u002Fconfiguration\u003E\n            &lt;\u002Fplugin\u003E\n            &lt;!-- scala and java mix compilation --\u003E\n            &lt;plugin\u003E\n                &lt;groupId\u003Enet.alchim31.maven&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Escala-maven-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E3.2.2&lt;\u002Fversion\u003E\n                &lt;executions\u003E\n                    &lt;execution\u003E\n                        &lt;goals\u003E\n                            &lt;goal\u003Ecompile&lt;\u002Fgoal\u003E\n                            &lt;goal\u003EtestCompile&lt;\u002Fgoal\u003E\n                        &lt;\u002Fgoals\u003E\n                    &lt;\u002Fexecution\u003E\n                &lt;\u002Fexecutions\u003E\n                &lt;configuration\u003E\n                    &lt;scalaVersion\u003E${scala.version}&lt;\u002FscalaVersion\u003E\n                &lt;\u002Fconfiguration\u003E\n            &lt;\u002Fplugin\u003E\n \n            &lt;plugin\u003E\n                &lt;groupId\u003Eorg.apache.maven.plugins&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Emaven-surefire-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E2.7&lt;\u002Fversion\u003E\n                &lt;configuration\u003E\n                    &lt;skipTests\u003Etrue&lt;\u002FskipTests\u003E\n                &lt;\u002Fconfiguration\u003E\n            &lt;\u002Fplugin\u003E\n            &lt;plugin\u003E\n                &lt;groupId\u003Eorg.scalatest&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Escalatest-maven-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E1.0&lt;\u002Fversion\u003E\n                &lt;executions\u003E\n                    &lt;execution\u003E\n                        &lt;id\u003Etest&lt;\u002Fid\u003E\n                        &lt;goals\u003E\n                            &lt;goal\u003Etest&lt;\u002Fgoal\u003E\n                        &lt;\u002Fgoals\u003E\n                    &lt;\u002Fexecution\u003E\n                &lt;\u002Fexecutions\u003E\n            &lt;\u002Fplugin\u003E\n            &lt;plugin\u003E\n                &lt;groupId\u003Eorg.jacoco&lt;\u002FgroupId\u003E\n                &lt;artifactId\u003Ejacoco-maven-plugin&lt;\u002FartifactId\u003E\n                &lt;version\u003E0.8.5&lt;\u002Fversion\u003E\n                &lt;executions\u003E\n                    &lt;execution\u003E\n                        &lt;goals\u003E\n                            &lt;goal\u003Eprepare-agent&lt;\u002Fgoal\u003E\n                        &lt;\u002Fgoals\u003E\n                    &lt;\u002Fexecution\u003E\n                    &lt;!-- attached to Maven test phase --\u003E\n                    &lt;execution\u003E\n                        &lt;id\u003Ereport&lt;\u002Fid\u003E\n                        &lt;phase\u003Etest&lt;\u002Fphase\u003E\n                        &lt;goals\u003E\n                            &lt;goal\u003Ereport&lt;\u002Fgoal\u003E\n                        &lt;\u002Fgoals\u003E\n                    &lt;\u002Fexecution\u003E\n                &lt;\u002Fexecutions\u003E\n            &lt;\u002Fplugin\u003E\n        &lt;\u002Fplugins\u003E\n    &lt;\u002Fbuild\u003E\n \n&lt;\u002Fproject\u003E\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003Cp\u003EНа этом статья закончена, а наша работа продолжается. Разработка расширения Spark требует множества решений, и не всегда они простые. Это видно и в исходном коде Spark, я думаю, разработчики сейчас реализовали бы многое иначе.\u003C\u002Fp\u003E\u003Cp\u003EВ любом случае, мы не обязаны пользоваться только существующими средствами, можно разработать что-то своё. Если вы хотите преобразовать данные, используя Spark, то можете выбрать готовое решение (HashPartitioner, RangePartitioner). И всё же, если если вы поняли, что нужно специфическое распределение данных, то не бойтесь сделать партишенер для своих нужд, и я уверен, что он будет лучше и полезнее!\u003C\u002Fp\u003E\u003Cp\u003EНе пытайтесь заставить машину работать быстрее, постарайтесь сделать так, чтобы машина не выполняла ненужную работу, а нужной работы было как можно меньше. Тогда это будет не преждевременная, а осознанная и нужная оптимизация.\u003C\u002Fp\u003E\u003Cp\u003EВ следующей статье мы разберём сам DataSource, предназначенный для чтения данных, и средства работы с метаданными.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"spark"},{"titleHtml":"таблицы"},{"titleHtml":"data"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa1e\u002F78b\u002F13a\u002Fa1e78b13a83819b4dd3ffa494da3700b.jpg","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa1e\u002F78b\u002F13a\u002Fa1e78b13a83819b4dd3ffa494da3700b.jpg","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fsberbank\\\u002Fblog\\\u002F583018\\\u002F\"},\"headline\":\"Изменить сохранения Spark Часть вторая: реализация партишенера\",\"datePublished\":\"2021-10-12T15:04:16+03:00\",\"dateModified\":\"2021-10-15T11:34:30+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Sber\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH\\\u002FBigData.Профессиональное сообщество SberProfi DWH\\\u002FBigData отвечает за развитие...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fsberbank\\\u002Fblog\\\u002F583018\\\u002F#post-content-body\",\"about\":[\"c_sberbank\",\"h_db_admins\",\"h_bigdata\",\"f_develop\",\"f_admin\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F583018\\\u002F1bf72fb4428e347e7a6cc8b4640a1cfc\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F964\\\u002Fe1d\\\u002F99d\\\u002F964e1d99d9eebd2740a09ba7ca1be2dd.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Feab\\\u002F499\\\u002Fe37\\\u002Feab499e37f38678093879d9be9b058f1.png\"]}","metaDescription":"Автор: Иван Калининский, участник профессионального сообщества Сбера SberProfi DWH\u002FBigData.Профессиональное сообщество SberProfi DWH\u002FBigData отвечает за развитие компетенций в таких направлениях, как...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":""},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"sberbank":{"alias":"sberbank","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompany\u002F9db\u002F3c1\u002Fec0\u002F9db3c1ec02265b8bcbfdfb0d23d8b9f2.jpg","titleHtml":"Сбер","descriptionHtml":"Больше чем банк","relatedData":null,"statistics":{"postsCount":229,"newsCount":7,"vacanciesCount":156,"employeesCount":159,"careerRating":4.07,"subscribersCount":32019,"rating":229.68,"invest":null},"foundationDate":{"year":"1841","month":"11","day":"12"},"location":{"city":{"id":"447159","title":"Москва"},"region":{"id":"1885","title":"Москва и Московская обл."},"country":{"id":"168","title":"Россия"}},"siteUrl":"http:\u002F\u002Fwww.sber.ru\u002F","staffNumber":"свыше 10 000 человек","registrationDate":"2011-02-08T10:09:33+00:00","representativeUser":null,"contacts":[],"settings":{"analyticsSettings":[{"type":"ga","trackingId":"UA-170457662-1"}],"branding":{"imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fbranding\u002F6ac\u002F725\u002F4eb\u002F6ac7254eb269ffa84589b75da04eb5ae.png","linkUrl":"","pixelUrl":""},"status":"active"},"metadata":{"titleHtml":"Сбер, Москва - Больше чем банк с 12 ноября 1841 г.","title":"Сбер, Москва - Больше чем банк с 12 ноября 1841 г.","keywords":["Управление проектами","Машинное обучение","Искусственный интеллект","Natural Language Processing","Блог компании SberDevices"],"descriptionHtml":"229 статей от авторов компании Сбер","description":"229 статей от авторов компании Сбер"},"aDeskSettings":null,"careerAlias":"sberbank-russia","maxCustomTrackerLinks":3}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
