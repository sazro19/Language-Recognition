<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2 / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/prequel\/blog\/574868\/"},"headline":"Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2","datePublished":"2021-10-12T15:17:16+03:00","dateModified":"2021-10-12T16:37:06+03:00","author":{"@type":"Person","name":"Мария Белялова"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография...","url":"https:\/\/habr.com\/ru\/company\/prequel\/blog\/574868\/#post-content-body","about":["c_prequel","h_algorithms","h_image_processing","h_machine_learning","h_artificial_intelligence","f_develop","f_popsci"],"image":["https:\/\/habrastorage.org\/webt\/r6\/xk\/z2\/r6xkz2peuqhrwoja1ehnqd5wez8.jpeg","https:\/\/habrastorage.org\/webt\/px\/3j\/pi\/px3jpibp-hytditqf7f2jnedbcs.png","https:\/\/habrastorage.org\/webt\/vs\/k2\/_n\/vsk2_nqjpwbp-rhyjnrit0jbljc.png","https:\/\/habrastorage.org\/webt\/uu\/ut\/pp\/uuutppfdtgksyo2rvkwfpurbw5u.png","https:\/\/habrastorage.org\/webt\/lx\/he\/lb\/lxhelbiic23v7rxk0ae7floxeya.png","https:\/\/habrastorage.org\/webt\/r6\/l2\/lb\/r6l2lbcwqis8cp5_y4-w-tdxkc0.png","https:\/\/habrastorage.org\/webt\/3t\/3y\/nu\/3t3ynue2n1k80asxmucgrra714o.png","https:\/\/habrastorage.org\/webt\/5j\/xr\/t3\/5jxrt3nkz5a5imw1d51ea7v_y30.png","https:\/\/habrastorage.org\/webt\/yy\/m8\/kg\/yym8kgf9olrulhcvmpsmcog3_w4.png","https:\/\/habrastorage.org\/webt\/2c\/rg\/jj\/2crgjj5pmz7k7ezokms1lrwrjfs.png","https:\/\/habrastorage.org\/webt\/b3\/na\/6v\/b3na6v07ni9x8mirqjmqcspc70g.png","https:\/\/habrastorage.org\/webt\/qj\/bb\/ly\/qjbbly6_zfoux5nyvsrkmkrm_gw.png","https:\/\/habrastorage.org\/webt\/-2\/nk\/nf\/-2nknfsern_vgknnw5vhaitrxje.png","https:\/\/habrastorage.org\/webt\/ln\/nx\/uq\/lnnxuqnqaj4ncqahlt0bwhm-foy.png","https:\/\/habrastorage.org\/webt\/5m\/zo\/9g\/5mzo9gzbmpegeuj63cmy-muwzuc.png","https:\/\/habrastorage.org\/webt\/tq\/5x\/uc\/tq5xucnnu-5la59lqblk_4rnrig.png","https:\/\/habrastorage.org\/webt\/kf\/v7\/3u\/kfv73urkzyvqcjbafc3ituvuoby.png","https:\/\/habrastorage.org\/webt\/2o\/y_\/s3\/2oy_s3azexmd0qic7vd7gw74rpo.png","https:\/\/habrastorage.org\/webt\/sx\/rl\/66\/sxrl66w42so_y3gfiahvom83kpk.png","https:\/\/habrastorage.org\/webt\/41\/lr\/dd\/41lrdd9_la5qbyze8uublkalpui.png","https:\/\/habrastorage.org\/webt\/fn\/go\/r4\/fngor46zqzlqvzpjp8kssscp_fg.png","https:\/\/habrastorage.org\/webt\/cw\/n7\/12\/cwn712khcbufldlgvfqh5ebzgcs.png","https:\/\/habrastorage.org\/webt\/gn\/ba\/6r\/gnba6ribmtlyokn9cawsfgiulas.png","https:\/\/habrastorage.org\/webt\/v3\/rk\/oe\/v3rkoezo8eh5ksloi-j7hpvexp0.png","https:\/\/habrastorage.org\/webt\/xp\/xv\/my\/xpxvmy1svzlyebp_pw5gmnnkz0y.png","https:\/\/habrastorage.org\/webt\/vm\/ig\/rw\/vmigrwhbgk6bok8dx1r_fvtr_b0.png","https:\/\/habrastorage.org\/webt\/fl\/eh\/e4\/flehe4bbjtf7jwywro0e7v_hsng.png","https:\/\/habrastorage.org\/webt\/af\/s5\/2n\/afs52nvwf9cvobg2u_82gdvqgd4.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.

Эта вторая статья..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.

Эта вторая статья..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.

Эта вторая статья..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.

Эта вторая статья..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.

Эта вторая статья..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="574868" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-12T12:17:16.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/574868/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/prequel/blog/574868/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/574868/ecdca20d2269ef9e348768d5cd7890d6/" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="prequel" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><!----></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"><div class="tm-company-card tm-company-article__company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/prequel/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/company/d1e/39a/cb5/d1e39acb58d46ac84fd15d3e57bee5d1.png" width="48" class="tm-entity-image__pic"></div></a> <!----> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">55.09</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/prequel/profile/" class="tm-company-card__name">
        Prequel
      </a> <div class="tm-company-card__description"></div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/belyalova/" title="belyalova" class="tm-user-info__userpic"><div class="tm-entity-image"><svg height="24" width="24" class="tm-svg-img tm-image-placeholder tm-image-placeholder_green"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <span class="tm-user-info__user"><a href="/ru/users/belyalova/" class="tm-user-info__username">
      belyalova
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-12T12:17:16.000Z" title="2021-10-12, 15:17">12  октября   в 15:17</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/prequel/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании Prequel</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/algorithms/" class="tm-article-snippet__hubs-item-link"><span>Алгоритмы</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/image_processing/" class="tm-article-snippet__hubs-item-link"><span>Обработка изображений</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/artificial_intelligence/" class="tm-article-snippet__hubs-item-link"><span>Искусственный интеллект</span> <!----></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><img src="https://habrastorage.org/r/w780q1/webt/r6/xk/z2/r6xkz2peuqhrwoja1ehnqd5wez8.jpeg" data-src="https://habrastorage.org/webt/r6/xk/z2/r6xkz2peuqhrwoja1ehnqd5wez8.jpeg" data-blurred="true"/><br/>
<br/>
Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.<br/>
<br/>
Эта вторая статья в нашем цикле материалов про сравнение алгоритмов оптимизации для обучения нейросетей. В <a href="https://habr.com/ru/company/prequel/blog/568496/">первой части</a> мы сравнивали поведение 39 алгоритмов на тестовых функциях. Если вы ее еще не читали, то советуем начать с нее. Также в прошлой статье мы кратко рассказали, в связи с чем появляется так много разных оптимизаторов для нейросетей.<br/>
<br/>
В этой статье мы посмотрим, как они ведут себя на игрушечной задаче — распознавании цифр из датасета MNIST. В следующей части мы проверим эти алгоритмы в бою на реальной задаче из продакшена. Код для этой и предыдущей части находится <a href="https://github.com/Prequel-Inc/habr_optimizers">здесь</a>.<br/>
<a name="habracut"></a><br/>
<h3>Условия эксперимента</h3><br/>
В качестве игрушечной задачи мы выбрали классификацию черно-белых изображений с рукописными цифрами из датасета MNIST. Этот датасет в силу своей простоты является популярным выбором для тестирования алгоритмов. Он содержит 60 000 тренировочных изображений и 10 000 тестовых изображений, каждое из которых принадлежит одному из 10 классов, которые соответствуют числу на изображении.<br/>
<br/>
В качестве классификатора мы взяли простую модель с двумя сверточными слоями, двумя полносвязными слоями, макспулингом и дропаутом:<br/>
<br/>
<pre><code class="python">class Net(nn.Module):
	def __init__(self, n_classes=10):
    	super(Net, self).__init__()
    	self.conv1 = nn.Conv2d(1, 32, 3, 1)
    	self.conv2 = nn.Conv2d(32, 64, 3, 1)
    	self.dropout1 = nn.Dropout(0.25)
    	self.dropout2 = nn.Dropout(0.5)
    	self.fc1 = nn.Linear(9216, 128)
    	self.fc2 = nn.Linear(128, n_classes)

	def forward(self, x):
    	x = self.conv1(x)
    	x = F.relu(x)
    	x = self.conv2(x)
    	x = F.relu(x)
    	x = F.max_pool2d(x, 2)
    	x = self.dropout1(x)
    	x = torch.flatten(x, 1)
    	x = self.fc1(x)
    	x = F.relu(x)
    	x = self.dropout2(x)
    	x = self.fc2(x)
    	output = F.log_softmax(x, dim=1)
    	return output</code></pre><br/>
В качестве функции потерь использовался <a href="https://pytorch.org/docs/master/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss">negative log likelihood loss</a>. Во всех экспериментах модель инициализируется одинаковыми весами.<br/>
<br/>
С каждым алгоритмом оптимизации модель обучалась:<br/>
<br/>
<ul>
<li>на сетке из 4 learning rate и 6 размерах батча — 48 раз;</li>
<li>с 12 разными learning rate schedulers с двумя парами фиксированных learning rate и размером батча (ниже расскажем, как мы их выбрали) — 24 раза.</li>
</ul><br/>
В экспериментах участвовали 36 алгоритмов оптимизации (в прошлой статье мы рассматривали 39 алгоритмов, в этой мы не рассматриваем LBFGS, Shampoo и Adafactor, так как они обучались слишком долго — при таком количестве экспериментов мы не могли себе это позволить). Всего модель была обучена 2592 раз с разными параметрами и оптимизаторами.<br/>
<br/>
<h3>Сравнение с разными learning rate</h3><br/>
Фиксируем размер батча на 64 и обучим модель со всеми оптимизаторами с разными learning rate: 1e-2, 1e-3, 1e-4 и 1e-5. В роли метрики качества выбрана accuracy, потому что в MNIST нет ярко выраженного дисбаланса классов.<br/>
<br/>
Так выглядят графики accuracy от эпохи обучения, функции потерь на обучении (train loss) и на тесте (test loss) для learning rate = 1e-4 — с этим значением графики наиболее наглядны. В легенде на графике accuracy алгоритмы отсортированы по максимальной достигнутой accuracy, а также указан номер эпохи, на которой она достигается. В легенде на графиках train loss и test loss алгоритмы отсортированы по минимальному достигнутому ими значению функции потерь, и указано место алгоритма по accuracy (чем меньше номер, тем больше accuracy). На графиках train loss и test loss нет алгоритма Rprop из-за масштабирования (это единственный алгоритм, с которым loss возрастает), с ним график перестает быть наглядным. <br/>
<br/>
<img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/px/3j/pi/px3jpibp-hytditqf7f2jnedbcs.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/vs/k2/_n/vsk2_nqjpwbp-rhyjnrit0jbljc.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/uu/ut/pp/uuutppfdtgksyo2rvkwfpurbw5u.png" data-width="30%"/><br/>
<br clear="left"/>
Для того, чтобы понять, какие алгоритмы наиболее устойчивы к изменению learning rate, отсортируем их по средней accuracy моделей, обученных с разными learning rate. В таблицах ниже также приведены среднеквадратическое отклонение, минимальное и максимальное значения, и learning rate, на котором было достигнуто максимальное значение accuracy. Чем больше значение в столбце, тем ближе оно к зеленому, чем меньше, тем ближе к красному. В таблице 1 представлены результаты того, как алгоритмы обучались в течение 25 эпох. Далее мы также приведем таблицу с результатами обучения на 50 эпохах для того, чтобы посмотреть, каким из алгоритмов требуется больше времени, чтобы сойтись, и какие алгоритмы при более длительном обучении не покажут особых улучшений.<br/>
<br/>
Таблица 1. <br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/lx/he/lb/lxhelbiic23v7rxk0ae7floxeya.png"/><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/r6/l2/lb/r6l2lbcwqis8cp5_y4-w-tdxkc0.png"/><br/>
<br/>
Названия алгоритмов выделены цветом по тому же принципу, что и в предыдущей статье: зеленым цветом отмечены те алгоритмы, которые хорошо себя показали на обеих тестовых функциях, желтым — средне, красным — плохо. На примере этой таблицы можно убедиться, что не стоит выбирать алгоритм по тестовым функциям: так, алгоритмы MADGRAD, AdaMod, Ranger, Yogi не оказались в числе лидеров ни для одной из тестовых функций, но на данной задаче показали хорошие результаты. Среди алгоритмов, которые оказались лучше всех на обеих тестовых функциях, на этой задаче тоже оказались в лидерах адаптивные алгоритмы первого порядка AdaBound, Adam, AdaBelief. Результаты алгоритма второго порядка Adahessian оказались ближе к худшим.<br/>
<br/>
По таблице видно, что многие алгоритмы показывают худшие результаты на маленьком learning rate = 1e-5. Посмотрим на таблицу для 50 эпох, чтобы понять, какие алгоритмы продолжают медленно обучаться и дальше, а какие уже сошлись на 25 эпохах.<br/>
<br/>
Таблица 2.<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/3t/3y/nu/3t3ynue2n1k80asxmucgrra714o.png"/><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/5j/xr/t3/5jxrt3nkz5a5imw1d51ea7v_y30.png"/><br/>
<br/>
Для наглядности сопоставим результаты обучения в течение 25 эпох и 50 эпох. В следующей таблице приведено место алгоритма по accuracy на 25 на 50 эпохах, как это место изменилось (красным выделены алгоритмы, которые упали в рейтинге, зеленым — которые поднялись), и средние accuracy на 25 и на 50 эпохах. В последнем столбце указано, как изменилась средняя accuracy при увеличении эпох от 25 до 50 — чем ближе значение к зеленому, тем быстрее к лучшему решению с точки зрения метрики accuracy сходится алгоритм. Значения каждого столбца размечены тепловой картой независимо от значений в других столбцах.<br/>
<br/>
Таблица 3.<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/yy/m8/kg/yym8kgf9olrulhcvmpsmcog3_w4.png"/><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/2c/rg/jj/2crgjj5pmz7k7ezokms1lrwrjfs.png"/><br/>
<br/>
Из таблицы видно, что чем лучшие результаты показывал алгоритм на 25 эпохах, тем меньше его результаты изменились при увеличении эпох до 50. Однако, ни один из алгоритмов с худшими результатами не смог вырваться в лидеры. Среди лидеров вышли вперед алгоритмы AdamW и AdamP — выходит, им требуется больше времени, чтобы сойтись.<br/>
<br/>
<h3>Сравнение с разными размерами батча</h3><br/>
Посмотрим, как оптимизаторы ведут себя на разных размерах батча (8, 16, 32, 64, 128, 256) cо значениями learning rate 1e-2, 1e-3, 1e-4, 1e-5.<br/>
<br/>
На части из алгоритмов, таких, как SGD, при уменьшении размера батча увеличивается точность даже на больших learning rate. Это связано с тем, что при большом размере батча происходит недостаточно обновлений, и часть из алгоритмов не успевает обучиться на 25 эпохах. На другой части алгоритмов такая ситуация возникает при уменьшении learning rate.<br/>
<br/>
Ниже приведены примеры графиков accuracy для разных learning rate и размера батча, которые иллюстрируют эту ситуацию: так, алгоритм SGDW не успевает обучиться за 25 эпох даже при больших значениях learning rate, а алгоритм MADGRAD сходится быстрее, и ему начинает не хватать обновлений при learning rate = 1e-5.<br/>
<br/>
Графики для алгоритма SGDW при разных размерах батча и фиксированном learning rate:<br/>
<br/>
<img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/b3/na/6v/b3na6v07ni9x8mirqjmqcspc70g.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/qj/bb/ly/qjbbly6_zfoux5nyvsrkmkrm_gw.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/-2/nk/nf/-2nknfsern_vgknnw5vhaitrxje.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/ln/nx/uq/lnnxuqnqaj4ncqahlt0bwhm-foy.png" data-width="30%"/><br/>
<br clear="left"/>
Графики для алгоритма MADGRAD при разных размерах батча и фиксированном learning rate:<br/>
<br/>
<img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/5m/zo/9g/5mzo9gzbmpegeuj63cmy-muwzuc.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/tq/5x/uc/tq5xucnnu-5la59lqblk_4rnrig.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/kf/v7/3u/kfv73urkzyvqcjbafc3ituvuoby.png" data-width="30%"/><img src="/img/image-loader.svg" align="left" data-src="https://habrastorage.org/webt/2o/y_/s3/2oy_s3azexmd0qic7vd7gw74rpo.png" data-width="30%"/><br/>
<br clear="left"/>
В таблице ниже все алгоритмы отсортированы по максимальной средней точности из предыдущего пункта. Для каждого алгоритма указан learning rate, начиная с которого accuracy обратно пропорциональна размеру батча:<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/sx/rl/66/sxrl66w42so_y3gfiahvom83kpk.png" data-width="50%"/><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/41/lr/dd/41lrdd9_la5qbyze8uublkalpui.png" data-width="50%"/><br/>
<br/>
В таблице ниже указана средняя accuracy моделей, обученных с разными оптимизаторами, для каждого значения learning rate и размера батча для 25 эпох:<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/fn/go/r4/fngor46zqzlqvzpjp8kssscp_fg.png" data-width="70%"/><br/>
<br/>
Для 50 эпох:<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/cw/n7/12/cwn712khcbufldlgvfqh5ebzgcs.png" data-width="70%"/><br/>
<br/>
В этой таблице указана средняя accuracy среди 5 моделей с наибольшей accuracy для каждой фиксированной пары learning rate и размера батча для 25 эпох:<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/gn/ba/6r/gnba6ribmtlyokn9cawsfgiulas.png" data-width="70%"/></div><br/>
Для 50 эпох:<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/v3/rk/oe/v3rkoezo8eh5ksloi-j7hpvexp0.png" data-width="70%"/></div><br/>
При learning rate = 1e-3, 1e-4 и 1e-5, чем меньше размер батча, тем больше средняя accuracy моделей. При learning rate = 1e-2 часть из алгоритмов ведет себя нестабильно. При learning rate = 1e-5 многим алгоритмам не хватило 25 эпох обучения.<br/>
<br/>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title">Таблица с количеством оптимизаторов, для которых выбранный размер батча оказался наилучшим при заданном learning rate.</b>
                        <div class="spoiler_text"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/xp/xv/my/xpxvmy1svzlyebp_pw5gmnnkz0y.png" data-width="70%"/><br/>
</div>
                    </div><br/>
<h3>Сравнение с разными расписаниями learning rate</h3><br/>
Зафиксируем learning rate и размер батча и попробуем менять learning rate в зависимости от эпохи с разными стратегиями. Возьмем следующие 12 learning rate schedulers:<br/>
<br/>
<ul>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.StepLR">StepLR</a>(gamma = 0.1) со значениями step_size = 1, 2, 3: умножение learning rate на gamma каждые step_size эпох;</li>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau">ReduceLROnPlateau</a>(factor=0.1) co значениями patience = 2, 3: если функция потерь не уменьшается в течение patience эпох, то learning rate умножается на factor;</li>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.CosineAnnealingLR">CosineAnnealingLR</a>(T_max = 10, eta_min = 0);</li>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts">CosineAnnealingWarmRestarts</a>(T_0 = 10, T_mult = 1, eta_min = 0);</li>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.CyclicLR">CyclicLR</a>(base_lr = 1e-3, max_lr = 0.1) со значениями mode = ’triangular’, ’triangular2’, ’exp_range’;<br/>
</li>
<li><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.OneCycleLR">OneCycleLR</a>(max_lr = 0.1) cо значениями anneal_strategy = 'cos' и 'linear';<br/>
</li>
</ul><br/>
На графиках ниже изображено, как изменяется learning rate с разными расписаниями. В легенде указаны минимальный и максимальный learning rate для каждого расписания. Серая линия — участок наложения графиков ReduceLROnPlateau со значениями patience, равными 2 и 3, бордовые — участки наложения графиков CosineAnnealingLR и CosineAnnealingWarmRestarts.<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/vm/ig/rw/vmigrwhbgk6bok8dx1r_fvtr_b0.png" data-width="70%"/></div><br/>
Здесь наложились друг на друга CyclicLR с политиками triangular и exp_range, поэтому, дальше exp_range рассматриваться не будет.<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/fl/eh/e4/flehe4bbjtf7jwywro0e7v_hsng.png" data-width="70%"/></div><br/>
По таблице из предыдущего пункта возьмем параметры, при которых 5 лучших моделей набрали наибольшую среднюю accuracy (learning rate 1e-3 и размер батча 256) и также возьмем параметры одного из средних результатов (learning rate 1e-4, размер батча 8). В таблицах ниже отображены средняя accuracy и отклонение всех моделей с каждым из расписаний и средняя accuracy по 5 лучшим результатам.<br/>
<br/>
<div style="text-align:center;"><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/af/s5/2n/afs52nvwf9cvobg2u_82gdvqgd4.png" data-width="80%"/></div><br/>
<h3>В следующей серии</h3><br/>
В следующей статье я расскажу про тот же эксперимент, но проведенный уже на реальной задаче — мультилейбловой классификации фото, сделанных на мобильный телефон. Будем благодарны вашему фидбеку о том, что можно было бы сделать лучше/понятнее/интереснее в этом эксперименте.</div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bneural%20networks%5D" class="tm-tags-list__link">neural networks</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%80%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%5D" class="tm-tags-list__link">рекомендательные системы</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BMNIST%5D" class="tm-tags-list__link">MNIST</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bdata%20science%5D" class="tm-tags-list__link">data science</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/company/prequel/blog/" class="tm-hubs-list__link router-link-active">
    Блог компании Prequel
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/algorithms/" class="tm-hubs-list__link">
    Алгоритмы
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/image_processing/" class="tm-hubs-list__link">
    Обработка изображений
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/artificial_intelligence/" class="tm-hubs-list__link">
    Искусственный интеллект
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 8: ↑8 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 8: ↑8 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+8</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">2.8K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    35
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/prequel/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/company/d1e/39a/cb5/d1e39acb58d46ac84fd15d3e57bee5d1.png" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/prequel/profile/" class="tm-company-snippet__title">Prequel</a> <div class="tm-company-snippet__description">Компания</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <div class="tm-article-author__company-contacts"><a href="https://prequel.app" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a></div> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/belyalova/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><svg class="tm-svg-img tm-image-placeholder tm-image-placeholder_green"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <div class="tm-user-card__meta"><div title=" 8 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    8
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">8</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Мария Белялова</span> <a href="/ru/users/belyalova/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @belyalova
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Data Scientist</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/prequel/blog/574868/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 1 
    </span></a> <!----></div></div></div>  <!---->  <!----> <!----></div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2018-08-10T21:00:00.000Z" title="2018-08-11, 00:00">11  августа  2018</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    США
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="https://prequel.app" target="_blank" class="tm-company-basic-info__link">
      prequel.app
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    101–200 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2021-07-13T15:15:28.000Z" title="2021-07-13, 18:15">13  июля  </time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Представитель</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="/ru/users/Dchinarev/" class="tm-company-basic-info__link">
      Dmitry Chinarev
    </a></dd></dl></div></div> <!----></section> <!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/prequel/blog/574868/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/prequel/blog/574868/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"574868":{"id":"574868","timePublished":"2021-10-12T12:17:16+00:00","isCorporative":true,"lang":"ru","titleHtml":"Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2","leadData":{"textHtml":"\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fr6\u002Fxk\u002Fz2\u002Fr6xkz2peuqhrwoja1ehnqd5wez8.jpeg\"\u003E\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nЕще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nЭта вторая статья в нашем цикле материалов про сравнение алгоритмов оптимизации для обучения нейросетей. В \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fprequel\u002Fblog\u002F568496\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы сравнивали поведение 39 алгоритмов на тестовых функциях. Если вы ее еще не читали, то советуем начать с нее. Также в прошлой статье мы кратко рассказали, в связи с чем появляется так много разных оптимизаторов для нейросетей.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nВ этой статье мы посмотрим, как они ведут себя на игрушечной задаче — распознавании цифр из датасета MNIST. В следующей части мы проверим эти алгоритмы в бою на реальной задаче из продакшена. Код для этой и предыдущей части находится \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FPrequel-Inc\u002Fhabr_optimizers\" rel=\"nofollow noopener noreferrer\"\u003Eздесь\u003C\u002Fa\u003E.\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"editorVersion":"1.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":8,"votesCount":8},"rating":8,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"2754837","alias":"belyalova","fullname":"Мария Белялова","avatarUrl":null,"speciality":"Data Scientist"},"statistics":{"commentsCount":1,"favoritesCount":35,"readingCount":2769,"score":8,"votesCount":8},"hubs":[{"relatedData":null,"id":"22770","alias":"prequel","type":"corporative","title":"Блог компании Prequel","titleHtml":"Блог компании Prequel","isProfiled":false},{"relatedData":null,"id":"8000","alias":"algorithms","type":"collective","title":"Алгоритмы","titleHtml":"Алгоритмы","isProfiled":true},{"relatedData":null,"id":"17175","alias":"image_processing","type":"collective","title":"Обработка изображений","titleHtml":"Обработка изображений","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"21922","alias":"artificial_intelligence","type":"collective","title":"Искусственный интеллект","titleHtml":"Искусственный интеллект","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fwebt\u002Fr6\u002Fxk\u002Fz2\u002Fr6xkz2peuqhrwoja1ehnqd5wez8.jpeg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fr6\u002Fxk\u002Fz2\u002Fr6xkz2peuqhrwoja1ehnqd5wez8.jpeg\" data-blurred=\"true\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭта вторая статья в нашем цикле материалов про сравнение алгоритмов оптимизации для обучения нейросетей. В \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fprequel\u002Fblog\u002F568496\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы сравнивали поведение 39 алгоритмов на тестовых функциях. Если вы ее еще не читали, то советуем начать с нее. Также в прошлой статье мы кратко рассказали, в связи с чем появляется так много разных оптимизаторов для нейросетей.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ этой статье мы посмотрим, как они ведут себя на игрушечной задаче — распознавании цифр из датасета MNIST. В следующей части мы проверим эти алгоритмы в бою на реальной задаче из продакшена. Код для этой и предыдущей части находится \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FPrequel-Inc\u002Fhabr_optimizers\"\u003Eздесь\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3\u003EУсловия эксперимента\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\nВ качестве игрушечной задачи мы выбрали классификацию черно-белых изображений с рукописными цифрами из датасета MNIST. Этот датасет в силу своей простоты является популярным выбором для тестирования алгоритмов. Он содержит 60 000 тренировочных изображений и 10 000 тестовых изображений, каждое из которых принадлежит одному из 10 классов, которые соответствуют числу на изображении.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ качестве классификатора мы взяли простую модель с двумя сверточными слоями, двумя полносвязными слоями, макспулингом и дропаутом:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cpre\u003E\u003Ccode class=\"python\"\u003Eclass Net(nn.Module):\n\tdef __init__(self, n_classes=10):\n    \tsuper(Net, self).__init__()\n    \tself.conv1 = nn.Conv2d(1, 32, 3, 1)\n    \tself.conv2 = nn.Conv2d(32, 64, 3, 1)\n    \tself.dropout1 = nn.Dropout(0.25)\n    \tself.dropout2 = nn.Dropout(0.5)\n    \tself.fc1 = nn.Linear(9216, 128)\n    \tself.fc2 = nn.Linear(128, n_classes)\n\n\tdef forward(self, x):\n    \tx = self.conv1(x)\n    \tx = F.relu(x)\n    \tx = self.conv2(x)\n    \tx = F.relu(x)\n    \tx = F.max_pool2d(x, 2)\n    \tx = self.dropout1(x)\n    \tx = torch.flatten(x, 1)\n    \tx = self.fc1(x)\n    \tx = F.relu(x)\n    \tx = self.dropout2(x)\n    \tx = self.fc2(x)\n    \toutput = F.log_softmax(x, dim=1)\n    \treturn output\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003Cbr\u002F\u003E\r\nВ качестве функции потерь использовался \u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fmaster\u002Fgenerated\u002Ftorch.nn.NLLLoss.html#torch.nn.NLLLoss\"\u003Enegative log likelihood loss\u003C\u002Fa\u003E. Во всех экспериментах модель инициализируется одинаковыми весами.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nС каждым алгоритмом оптимизации модель обучалась:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003Eна сетке из 4 learning rate и 6 размерах батча — 48 раз;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eс 12 разными learning rate schedulers с двумя парами фиксированных learning rate и размером батча (ниже расскажем, как мы их выбрали) — 24 раза.\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\nВ экспериментах участвовали 36 алгоритмов оптимизации (в прошлой статье мы рассматривали 39 алгоритмов, в этой мы не рассматриваем LBFGS, Shampoo и Adafactor, так как они обучались слишком долго — при таком количестве экспериментов мы не могли себе это позволить). Всего модель была обучена 2592 раз с разными параметрами и оптимизаторами.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch3\u003EСравнение с разными learning rate\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\nФиксируем размер батча на 64 и обучим модель со всеми оптимизаторами с разными learning rate: 1e-2, 1e-3, 1e-4 и 1e-5. В роли метрики качества выбрана accuracy, потому что в MNIST нет ярко выраженного дисбаланса классов.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТак выглядят графики accuracy от эпохи обучения, функции потерь на обучении (train loss) и на тесте (test loss) для learning rate = 1e-4 — с этим значением графики наиболее наглядны. В легенде на графике accuracy алгоритмы отсортированы по максимальной достигнутой accuracy, а также указан номер эпохи, на которой она достигается. В легенде на графиках train loss и test loss алгоритмы отсортированы по минимальному достигнутому ими значению функции потерь, и указано место алгоритма по accuracy (чем меньше номер, тем больше accuracy). На графиках train loss и test loss нет алгоритма Rprop из-за масштабирования (это единственный алгоритм, с которым loss возрастает), с ним график перестает быть наглядным. \u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fpx\u002F3j\u002Fpi\u002Fpx3jpibp-hytditqf7f2jnedbcs.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvs\u002Fk2\u002F_n\u002Fvsk2_nqjpwbp-rhyjnrit0jbljc.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fuu\u002Fut\u002Fpp\u002Fuuutppfdtgksyo2rvkwfpurbw5u.png\" data-width=\"30%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr clear=\"left\"\u002F\u003E\r\nДля того, чтобы понять, какие алгоритмы наиболее устойчивы к изменению learning rate, отсортируем их по средней accuracy моделей, обученных с разными learning rate. В таблицах ниже также приведены среднеквадратическое отклонение, минимальное и максимальное значения, и learning rate, на котором было достигнуто максимальное значение accuracy. Чем больше значение в столбце, тем ближе оно к зеленому, чем меньше, тем ближе к красному. В таблице 1 представлены результаты того, как алгоритмы обучались в течение 25 эпох. Далее мы также приведем таблицу с результатами обучения на 50 эпохах для того, чтобы посмотреть, каким из алгоритмов требуется больше времени, чтобы сойтись, и какие алгоритмы при более длительном обучении не покажут особых улучшений.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТаблица 1. \u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Flx\u002Fhe\u002Flb\u002Flxhelbiic23v7rxk0ae7floxeya.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fr6\u002Fl2\u002Flb\u002Fr6l2lbcwqis8cp5_y4-w-tdxkc0.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНазвания алгоритмов выделены цветом по тому же принципу, что и в предыдущей статье: зеленым цветом отмечены те алгоритмы, которые хорошо себя показали на обеих тестовых функциях, желтым — средне, красным — плохо. На примере этой таблицы можно убедиться, что не стоит выбирать алгоритм по тестовым функциям: так, алгоритмы MADGRAD, AdaMod, Ranger, Yogi не оказались в числе лидеров ни для одной из тестовых функций, но на данной задаче показали хорошие результаты. Среди алгоритмов, которые оказались лучше всех на обеих тестовых функциях, на этой задаче тоже оказались в лидерах адаптивные алгоритмы первого порядка AdaBound, Adam, AdaBelief. Результаты алгоритма второго порядка Adahessian оказались ближе к худшим.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПо таблице видно, что многие алгоритмы показывают худшие результаты на маленьком learning rate = 1e-5. Посмотрим на таблицу для 50 эпох, чтобы понять, какие алгоритмы продолжают медленно обучаться и дальше, а какие уже сошлись на 25 эпохах.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТаблица 2.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F3t\u002F3y\u002Fnu\u002F3t3ynue2n1k80asxmucgrra714o.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F5j\u002Fxr\u002Ft3\u002F5jxrt3nkz5a5imw1d51ea7v_y30.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДля наглядности сопоставим результаты обучения в течение 25 эпох и 50 эпох. В следующей таблице приведено место алгоритма по accuracy на 25 на 50 эпохах, как это место изменилось (красным выделены алгоритмы, которые упали в рейтинге, зеленым — которые поднялись), и средние accuracy на 25 и на 50 эпохах. В последнем столбце указано, как изменилась средняя accuracy при увеличении эпох от 25 до 50 — чем ближе значение к зеленому, тем быстрее к лучшему решению с точки зрения метрики accuracy сходится алгоритм. Значения каждого столбца размечены тепловой картой независимо от значений в других столбцах.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТаблица 3.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fyy\u002Fm8\u002Fkg\u002Fyym8kgf9olrulhcvmpsmcog3_w4.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F2c\u002Frg\u002Fjj\u002F2crgjj5pmz7k7ezokms1lrwrjfs.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИз таблицы видно, что чем лучшие результаты показывал алгоритм на 25 эпохах, тем меньше его результаты изменились при увеличении эпох до 50. Однако, ни один из алгоритмов с худшими результатами не смог вырваться в лидеры. Среди лидеров вышли вперед алгоритмы AdamW и AdamP — выходит, им требуется больше времени, чтобы сойтись.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch3\u003EСравнение с разными размерами батча\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\nПосмотрим, как оптимизаторы ведут себя на разных размерах батча (8, 16, 32, 64, 128, 256) cо значениями learning rate 1e-2, 1e-3, 1e-4, 1e-5.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНа части из алгоритмов, таких, как SGD, при уменьшении размера батча увеличивается точность даже на больших learning rate. Это связано с тем, что при большом размере батча происходит недостаточно обновлений, и часть из алгоритмов не успевает обучиться на 25 эпохах. На другой части алгоритмов такая ситуация возникает при уменьшении learning rate.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНиже приведены примеры графиков accuracy для разных learning rate и размера батча, которые иллюстрируют эту ситуацию: так, алгоритм SGDW не успевает обучиться за 25 эпох даже при больших значениях learning rate, а алгоритм MADGRAD сходится быстрее, и ему начинает не хватать обновлений при learning rate = 1e-5.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nГрафики для алгоритма SGDW при разных размерах батча и фиксированном learning rate:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fb3\u002Fna\u002F6v\u002Fb3na6v07ni9x8mirqjmqcspc70g.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fqj\u002Fbb\u002Fly\u002Fqjbbly6_zfoux5nyvsrkmkrm_gw.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F-2\u002Fnk\u002Fnf\u002F-2nknfsern_vgknnw5vhaitrxje.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fln\u002Fnx\u002Fuq\u002Flnnxuqnqaj4ncqahlt0bwhm-foy.png\" data-width=\"30%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr clear=\"left\"\u002F\u003E\r\nГрафики для алгоритма MADGRAD при разных размерах батча и фиксированном learning rate:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F5m\u002Fzo\u002F9g\u002F5mzo9gzbmpegeuj63cmy-muwzuc.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ftq\u002F5x\u002Fuc\u002Ftq5xucnnu-5la59lqblk_4rnrig.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fkf\u002Fv7\u002F3u\u002Fkfv73urkzyvqcjbafc3ituvuoby.png\" data-width=\"30%\"\u002F\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" align=\"left\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F2o\u002Fy_\u002Fs3\u002F2oy_s3azexmd0qic7vd7gw74rpo.png\" data-width=\"30%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr clear=\"left\"\u002F\u003E\r\nВ таблице ниже все алгоритмы отсортированы по максимальной средней точности из предыдущего пункта. Для каждого алгоритма указан learning rate, начиная с которого accuracy обратно пропорциональна размеру батча:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fsx\u002Frl\u002F66\u002Fsxrl66w42so_y3gfiahvom83kpk.png\" data-width=\"50%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F41\u002Flr\u002Fdd\u002F41lrdd9_la5qbyze8uublkalpui.png\" data-width=\"50%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ таблице ниже указана средняя accuracy моделей, обученных с разными оптимизаторами, для каждого значения learning rate и размера батча для 25 эпох:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ffn\u002Fgo\u002Fr4\u002Ffngor46zqzlqvzpjp8kssscp_fg.png\" data-width=\"70%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДля 50 эпох:\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fcw\u002Fn7\u002F12\u002Fcwn712khcbufldlgvfqh5ebzgcs.png\" data-width=\"70%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ этой таблице указана средняя accuracy среди 5 моделей с наибольшей accuracy для каждой фиксированной пары learning rate и размера батча для 25 эпох:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fgn\u002Fba\u002F6r\u002Fgnba6ribmtlyokn9cawsfgiulas.png\" data-width=\"70%\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nДля 50 эпох:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fv3\u002Frk\u002Foe\u002Fv3rkoezo8eh5ksloi-j7hpvexp0.png\" data-width=\"70%\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nПри learning rate = 1e-3, 1e-4 и 1e-5, чем меньше размер батча, тем больше средняя accuracy моделей. При learning rate = 1e-2 часть из алгоритмов ведет себя нестабильно. При learning rate = 1e-5 многим алгоритмам не хватило 25 эпох обучения.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"spoiler\" role=\"button\" tabindex=\"0\"\u003E\n                        \u003Cb class=\"spoiler_title\"\u003EТаблица с количеством оптимизаторов, для которых выбранный размер батча оказался наилучшим при заданном learning rate.\u003C\u002Fb\u003E\n                        \u003Cdiv class=\"spoiler_text\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fxp\u002Fxv\u002Fmy\u002Fxpxvmy1svzlyebp_pw5gmnnkz0y.png\" data-width=\"70%\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fdiv\u003E\n                    \u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3\u003EСравнение с разными расписаниями learning rate\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\nЗафиксируем learning rate и размер батча и попробуем менять learning rate в зависимости от эпохи с разными стратегиями. Возьмем следующие 12 learning rate schedulers:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.StepLR\"\u003EStepLR\u003C\u002Fa\u003E(gamma = 0.1) со значениями step_size = 1, 2, 3: умножение learning rate на gamma каждые step_size эпох;\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\"\u003EReduceLROnPlateau\u003C\u002Fa\u003E(factor=0.1) co значениями patience = 2, 3: если функция потерь не уменьшается в течение patience эпох, то learning rate умножается на factor;\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.CosineAnnealingLR\"\u003ECosineAnnealingLR\u003C\u002Fa\u003E(T_max = 10, eta_min = 0);\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\"\u003ECosineAnnealingWarmRestarts\u003C\u002Fa\u003E(T_0 = 10, T_mult = 1, eta_min = 0);\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.CyclicLR\"\u003ECyclicLR\u003C\u002Fa\u003E(base_lr = 1e-3, max_lr = 0.1) со значениями mode = ’triangular’, ’triangular2’, ’exp_range’;\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Foptim.html#torch.optim.lr_scheduler.OneCycleLR\"\u003EOneCycleLR\u003C\u002Fa\u003E(max_lr = 0.1) cо значениями anneal_strategy = 'cos' и 'linear';\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\nНа графиках ниже изображено, как изменяется learning rate с разными расписаниями. В легенде указаны минимальный и максимальный learning rate для каждого расписания. Серая линия — участок наложения графиков ReduceLROnPlateau со значениями patience, равными 2 и 3, бордовые — участки наложения графиков CosineAnnealingLR и CosineAnnealingWarmRestarts.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvm\u002Fig\u002Frw\u002Fvmigrwhbgk6bok8dx1r_fvtr_b0.png\" data-width=\"70%\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nЗдесь наложились друг на друга CyclicLR с политиками triangular и exp_range, поэтому, дальше exp_range рассматриваться не будет.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ffl\u002Feh\u002Fe4\u002Fflehe4bbjtf7jwywro0e7v_hsng.png\" data-width=\"70%\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\nПо таблице из предыдущего пункта возьмем параметры, при которых 5 лучших моделей набрали наибольшую среднюю accuracy (learning rate 1e-3 и размер батча 256) и также возьмем параметры одного из средних результатов (learning rate 1e-4, размер батча 8). В таблицах ниже отображены средняя accuracy и отклонение всех моделей с каждым из расписаний и средняя accuracy по 5 лучшим результатам.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cdiv style=\"text-align:center;\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Faf\u002Fs5\u002F2n\u002Fafs52nvwf9cvobg2u_82gdvqgd4.png\" data-width=\"80%\"\u002F\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\n\u003Ch3\u003EВ следующей серии\u003C\u002Fh3\u003E\u003Cbr\u002F\u003E\r\nВ следующей статье я расскажу про тот же эксперимент, но проведенный уже на реальной задаче — мультилейбловой классификации фото, сделанных на мобильный телефон. Будем благодарны вашему фидбеку о том, что можно было бы сделать лучше\u002Fпонятнее\u002Fинтереснее в этом эксперименте.\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"neural networks"},{"titleHtml":"рекомендательные системы"},{"titleHtml":"MNIST"},{"titleHtml":"data science"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F574868\u002Fecdca20d2269ef9e348768d5cd7890d6\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F574868\u002Fecdca20d2269ef9e348768d5cd7890d6\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fprequel\\\u002Fblog\\\u002F574868\\\u002F\"},\"headline\":\"Копнем поглубже: сравниваем популярные алгоритмы оптимизации с менее известными. Часть 2\",\"datePublished\":\"2021-10-12T15:17:16+03:00\",\"dateModified\":\"2021-10-12T16:37:06+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Мария Белялова\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fprequel\\\u002Fblog\\\u002F574868\\\u002F#post-content-body\",\"about\":[\"c_prequel\",\"h_algorithms\",\"h_image_processing\",\"h_machine_learning\",\"h_artificial_intelligence\",\"f_develop\",\"f_popsci\"],\"image\":[\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fr6\\\u002Fxk\\\u002Fz2\\\u002Fr6xkz2peuqhrwoja1ehnqd5wez8.jpeg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fpx\\\u002F3j\\\u002Fpi\\\u002Fpx3jpibp-hytditqf7f2jnedbcs.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fvs\\\u002Fk2\\\u002F_n\\\u002Fvsk2_nqjpwbp-rhyjnrit0jbljc.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fuu\\\u002Fut\\\u002Fpp\\\u002Fuuutppfdtgksyo2rvkwfpurbw5u.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Flx\\\u002Fhe\\\u002Flb\\\u002Flxhelbiic23v7rxk0ae7floxeya.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fr6\\\u002Fl2\\\u002Flb\\\u002Fr6l2lbcwqis8cp5_y4-w-tdxkc0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F3t\\\u002F3y\\\u002Fnu\\\u002F3t3ynue2n1k80asxmucgrra714o.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F5j\\\u002Fxr\\\u002Ft3\\\u002F5jxrt3nkz5a5imw1d51ea7v_y30.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fyy\\\u002Fm8\\\u002Fkg\\\u002Fyym8kgf9olrulhcvmpsmcog3_w4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F2c\\\u002Frg\\\u002Fjj\\\u002F2crgjj5pmz7k7ezokms1lrwrjfs.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fb3\\\u002Fna\\\u002F6v\\\u002Fb3na6v07ni9x8mirqjmqcspc70g.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fqj\\\u002Fbb\\\u002Fly\\\u002Fqjbbly6_zfoux5nyvsrkmkrm_gw.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F-2\\\u002Fnk\\\u002Fnf\\\u002F-2nknfsern_vgknnw5vhaitrxje.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fln\\\u002Fnx\\\u002Fuq\\\u002Flnnxuqnqaj4ncqahlt0bwhm-foy.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F5m\\\u002Fzo\\\u002F9g\\\u002F5mzo9gzbmpegeuj63cmy-muwzuc.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ftq\\\u002F5x\\\u002Fuc\\\u002Ftq5xucnnu-5la59lqblk_4rnrig.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fkf\\\u002Fv7\\\u002F3u\\\u002Fkfv73urkzyvqcjbafc3ituvuoby.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F2o\\\u002Fy_\\\u002Fs3\\\u002F2oy_s3azexmd0qic7vd7gw74rpo.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fsx\\\u002Frl\\\u002F66\\\u002Fsxrl66w42so_y3gfiahvom83kpk.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F41\\\u002Flr\\\u002Fdd\\\u002F41lrdd9_la5qbyze8uublkalpui.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ffn\\\u002Fgo\\\u002Fr4\\\u002Ffngor46zqzlqvzpjp8kssscp_fg.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fcw\\\u002Fn7\\\u002F12\\\u002Fcwn712khcbufldlgvfqh5ebzgcs.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fgn\\\u002Fba\\\u002F6r\\\u002Fgnba6ribmtlyokn9cawsfgiulas.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fv3\\\u002Frk\\\u002Foe\\\u002Fv3rkoezo8eh5ksloi-j7hpvexp0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fxp\\\u002Fxv\\\u002Fmy\\\u002Fxpxvmy1svzlyebp_pw5gmnnkz0y.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fvm\\\u002Fig\\\u002Frw\\\u002Fvmigrwhbgk6bok8dx1r_fvtr_b0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ffl\\\u002Feh\\\u002Fe4\\\u002Fflehe4bbjtf7jwywro0e7v_hsng.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Faf\\\u002Fs5\\\u002F2n\\\u002Fafs52nvwf9cvobg2u_82gdvqgd4.png\"]}","metaDescription":"Еще раз здравствуй, Хабр! Меня зовут Мария Белялова, и я занимаюсь data science в мобильном фоторедакторе Prequel. Кстати, именно в нём и обработана фотография из шапки поста.\r\n\r\nЭта вторая статья...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":""},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"prequel":{"alias":"prequel","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompany\u002Fd1e\u002F39a\u002Fcb5\u002Fd1e39acb58d46ac84fd15d3e57bee5d1.png","titleHtml":"Prequel","descriptionHtml":null,"relatedData":null,"statistics":{"postsCount":5,"newsCount":0,"vacanciesCount":0,"employeesCount":5,"careerRating":null,"subscribersCount":20,"rating":55.09,"invest":null},"foundationDate":{"year":"2018","month":"08","day":"11"},"location":{"city":{"id":"478807","title":"New York"},"region":{"id":"957","title":"New York"},"country":{"id":"198","title":"США"}},"siteUrl":"https:\u002F\u002Fprequel.app","staffNumber":"101–200 человек","registrationDate":"2021-07-13T15:15:28+00:00","representativeUser":{"alias":"Dchinarev","fullname":"Dmitry Chinarev"},"contacts":[{"title":"Сайт","url":"https:\u002F\u002Fprequel.app"}],"settings":{"analyticsSettings":[],"branding":null,"status":"expired"},"metadata":{"titleHtml":"Prequel, New York -  с 11 августа 2018 г.","title":"Prequel, New York -  с 11 августа 2018 г.","keywords":["Алгоритмы","Машинное обучение","Искусственный интеллект","Обработка изображений","Аналитика мобильных приложений"],"descriptionHtml":"5 статей от авторов компании Prequel","description":"5 статей от авторов компании Prequel"},"aDeskSettings":null,"careerAlias":null,"maxCustomTrackerLinks":0}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
