<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/582980\/"},"headline":"Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году","datePublished":"2021-10-12T12:51:53+03:00","dateModified":"2021-10-22T12:05:54+03:00","author":{"@type":"Person","name":"Михаил Утробин"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"FastText &mdash; это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком...","url":"https:\/\/habr.com\/ru\/post\/582980\/#post-content-body","about":["h_python","h_machine_learning","h_artificial_intelligence","f_develop","f_popsci"],"image":["https:\/\/habr.com\/share\/publication\/582980\/dea421c87847d8e7e207852d40806e0b\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/69a\/70d\/d2c\/69a70dd2c34b0d32e2162b082c7dd1bd.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/a4a\/437\/daf\/a4a437daf5f9517ae08fca14f9298791.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/713\/f35\/a30\/713f35a30c194771ffb53abd14e8a96b.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/a0c\/264\/94d\/a0c26494dfd401425d861100c7669d88.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/813\/343\/353\/813343353312f28df3826250812e2b10.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/b66\/3e2\/670\/b663e2670bfe3b438f24a43f0399693b.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="582980" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-12T09:51:53.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/582980/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/582980/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/582980/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/UtrobinMV/" title="UtrobinMV" class="tm-user-info__userpic"><div class="tm-entity-image"><svg height="24" width="24" class="tm-svg-img tm-image-placeholder tm-image-placeholder_lilac"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <span class="tm-user-info__user"><a href="/ru/users/UtrobinMV/" class="tm-user-info__username">
      UtrobinMV
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-12T09:51:53.000Z" title="2021-10-12, 12:51">12  октября   в 12:51</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/python/" class="tm-article-snippet__hubs-item-link"><span>Python</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/artificial_intelligence/" class="tm-article-snippet__hubs-item-link"><span>Искусственный интеллект</span> <!----></a></span></div> <div class="tm-article-snippet__labels"><div class="tm-article-snippet__label"><span>
        Из песочницы
      </span></div></div> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p>FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на текущий момент обученная модель FastText на русскоязычном корпусе текстов Википедии занимает немногим более 16Гигабайт, что в значительной мере сужает возможности использования данной технологией.  </p><p>На просторах хабра вы уже найдете примеры такого сжатия описанные ранее Давидом Дале в статье «<a href="https://habr.com/ru/post/489474/" rel="noopener noreferrer nofollow">Как сжать модель fastText в 100 раз</a>». Решая эту задачу, а применял рекомендации из данной статьи, и к ним мы еще вернемся, но эта статья уже несколько потеряла свою актуальность, так как часть используемых методов более не работают в новой версии библиотеки Gensim 4.0. Кроме того, применяемый в данной статье имеет более общий характер применения, так как сжатая данный образом модель все же не рассчитана на решение узкой задачи, и как показала практика при решении более узких задач, модель теряет в качестве более существенно, чем это показано на примерах.</p><p>В этой статье я расскажу о том, как я сжимал модель FastText для решения конкретной, локальной задачи, при этом основной целью, было именно то, чтобы результаты не отличались, от результатов исходной модели FastText.</p><p>Основная суть примененного мною метода, была в том, чтобы исключить из словаря модели FastText не используемые слова. Так как например модель «wiki_ru», содержит в своем корпусе 1,88 млн слов в словаре, и 2 млн n-грамм токенов, (300 мерных) векторов.  </p><p>Для решения же локальной задачи, я сократил это количество до 80 тысяч слов, и 100 тысяч нграмм, и тем самым получил практически 80 кратное уменьшение размера модели. При этом решая данную задачу я не хотел уменьшать размерность векторов, и заниматься квантизацией, так как это неминуемо снижает качество, из за потери части несущей информации в векторах от такого сжатия.</p><h3>Ход решения</h3><p>Итак, первое что нужно было сделать, это взять из своего тренировочного корпуса текста список всех слов (токенов), что я собственно и сделал. Мой тренировочный текст хранился в файле train_input.txt.</p><p>Для создания собственного словаря, я воспользовался библиотекой gensim и механизмом тренировки FastText. Да, наверное это не самый лучший способ, но мне он показался достаточно гибки, для решения именно этой задачи, где я мог параметрами вроде min_count управлять размером своего полученного словаря.</p><figure class="full-width "><img src="/img/image-loader.svg" height="354" data-src="https://habrastorage.org/getpro/habr/upload_files/69a/70d/d2c/69a70dd2c34b0d32e2162b082c7dd1bd.png" data-width="655"/><figcaption></figcaption></figure><p>Следующей этапом, я хотел добиться, чтобы полученная модель выдавала аналогичные результаты запроса при похожих слов текста, поэтому кроме слов из своего корпуса, в будущий корпус текста своей модели, я так же добавил слова из TOP 10, похожих слов используя метод most_similar</p><figure class="full-width "><img src="/img/image-loader.svg" height="414" data-src="https://habrastorage.org/getpro/habr/upload_files/a4a/437/daf/a4a437daf5f9517ae08fca14f9298791.png" data-width="601"/><figcaption></figcaption></figure><p>Но вероятно, и этого может показаться мало. Ведь мы знаем, что модель fastText хранит в себе не только слова но и n-граммы слов. Потому, как модель способна разбивать слова на n-граммы и в своей части хранит их в том числе и в словаре. Поэтому следующим этапом, каждое слово из полученного словаря, я разбил на n-граммы слов, и тоже добавил их в наш полученный словарь.</p><figure class="full-width "><img src="/img/image-loader.svg" height="124" data-src="https://habrastorage.org/getpro/habr/upload_files/713/f35/a30/713f35a30c194771ffb53abd14e8a96b.png" data-width="537"/><figcaption></figcaption></figure><p>Таким образом я получил общий словарь, в котором получилось 32 тысячи слов и 50 тысяч n-грамм слов из словаря, что в сумме составило 72 тысячи слов. Однако я решил не ограничиваться только этим словарем, и в завершение добавил еще 8000 тысяч слов наиболее часто встречающихся из модели FastText «wiki_ru», как это рекомендуется из вышеуказанной статьи, чтобы модель была более устойчива, в том числе, к новым неизвестным ей словам.</p><figure class=""><img src="/img/image-loader.svg" height="183" data-src="https://habrastorage.org/getpro/habr/upload_files/a0c/264/94d/a0c26494dfd401425d861100c7669d88.png" data-width="475"/><figcaption></figcaption></figure><p>Далее из полученных слов, составлен итоговый словарь. При этом важным являлось, то, чтобы порядок слов не отличался от основной модели. Так как словарь составлен в порядке частоты встречаемости слов.</p><p>После генерации словаря, важным моментом в настройке новой модели FastText является переупаковка матриц хэшей n-грамм. Метод которой было описан в статье Андреем Васнецовым, в этой <a href="https://medium.com/@vasnetsov93/shrinking-fasttext-embeddings-so-that-it-fits-google-colab-cd59ab75959e" rel="noopener noreferrer nofollow">статье</a>. Однако данный код так же пришлось немного видоизменить, в связи с обновлением библиотеки gensim.</p><figure class="full-width "><img src="/img/image-loader.svg" height="245" data-src="https://habrastorage.org/getpro/habr/upload_files/813/343/353/813343353312f28df3826250812e2b10.png" data-width="863"/><figcaption></figcaption></figure><h3>В результате</h3><p>В результате данных преобразований, мною была получена модель, которая по свои характеристикам для решения поставленной задачи, ни чуть не уступает в качестве предоставленных результатов её родительской модели. Что очень хорошо видно, при составлении запросов most_similar.  </p><figure class=""><img src="/img/image-loader.svg" height="449" data-src="https://habrastorage.org/getpro/habr/upload_files/b66/3e2/670/b663e2670bfe3b438f24a43f0399693b.png" data-width="411"/><figcaption></figcaption></figure><p>Получение векторных представлений слов, предложений, и таблицы результатов схожести, давали сопоставимые результаты.</p><p>Код для сжатия модели и его последующего применения доступен в моем <a href="https://github.com/utrobinmv/gensim-fasttext-shrink" rel="noopener noreferrer nofollow">репозитории</a> на GitHub.</p><p>Если у вас появились дополнительные идеи, как можно было бы улучшить полученную таким образом модель, напишите в комментарии, я буду очень рад.</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bfasttext%5D" class="tm-tags-list__link">fasttext</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bpython%5D" class="tm-tags-list__link">python</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bgensim%5D" class="tm-tags-list__link">gensim</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bmachine%20learning%5D" class="tm-tags-list__link">machine learning</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bword%20embeddings%5D" class="tm-tags-list__link">word embeddings</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%8D%D0%BC%D0%B1%D0%B5%D0%B4%D0%B4%D0%B8%D0%BD%D0%B3%D0%B8%5D" class="tm-tags-list__link">эмбеддинги</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/python/" class="tm-hubs-list__link">
    Python
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/artificial_intelligence/" class="tm-hubs-list__link">
    Искусственный интеллект
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 10: ↑10 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 10: ↑10 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+10</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">2.3K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    29
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/UtrobinMV/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><svg class="tm-svg-img tm-image-placeholder tm-image-placeholder_lilac"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <div class="tm-user-card__meta"><div title=" 5 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    5
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">10</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Михаил Утробин</span> <a href="/ru/users/UtrobinMV/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @UtrobinMV
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Machine Learning</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/582980/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 4 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/582980/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/582980/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"582980":{"id":"582980","timePublished":"2021-10-12T09:51:53+00:00","isCorporative":false,"lang":"ru","titleHtml":"Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году","leadData":{"textHtml":"\u003Cp\u003EFastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на текущий момент обученная модель FastText на русскоязычном корпусе текстов Википедии занимает немногим более 16Гигабайт, что в значительной мере сужает возможности использования данной технологией.  \u003C\u002Fp\u003E\u003Cp\u003EНа просторах хабра вы уже найдете примеры такого сжатия описанные ранее «Давидом Дале» в статье «\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F489474\u002F\" rel=\"noopener noreferrer nofollow\"\u003EКак сжать модель fastText в 100 раз\u003C\u002Fa\u003E». Решая эту задачу, а применял рекомендации из данной статьи, и к ним мы еще вернемся, но эта статья уже несколько потеряла свою актуальность, так как часть используемых методов более не работают в новой версии библиотеки Gensim 4.0. Кроме того, применяемый в данной статье имеет более общий характер применения, так как сжатая данный образом модель все же не рассчитана на решение узкой задачи, и как показала практика при решении более узких задач, модель теряет в качестве более существенно, чем это показано на примерах.\u003C\u002Fp\u003E\u003Cp\u003EВ этой статье я расскажу о том, как я сжимал модель FastText для решения конкретной, локальной задачи, при этом основной целью, было именно то, чтобы результаты не отличались, от результатов исходной модели FastText.\u003C\u002Fp\u003E\u003Cp\u003EОсновная суть примененного мною метода, была в том, чтобы исключить из словаря модели FastText не используемые слова. Так как например модель «wiki_ru», содержит в своем корпусе 1,88 млн слов в словаре, и 2 млн n-грамм токенов, (300 мерных) векторов.  \u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69a\u002F70d\u002Fd2c\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69a\u002F70d\u002Fd2c\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[{"type":"sandbox","data":null}],"author":{"scoreStats":{"score":5,"votesCount":5},"rating":10,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"2542969","alias":"UtrobinMV","fullname":"Михаил Утробин","avatarUrl":null,"speciality":"Machine Learning"},"statistics":{"commentsCount":4,"favoritesCount":29,"readingCount":2343,"score":10,"votesCount":10},"hubs":[{"relatedData":null,"id":"340","alias":"python","type":"collective","title":"Python","titleHtml":"Python","isProfiled":true},{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"21922","alias":"artificial_intelligence","type":"collective","title":"Искусственный интеллект","titleHtml":"Искусственный интеллект","isProfiled":false}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EFastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на текущий момент обученная модель FastText на русскоязычном корпусе текстов Википедии занимает немногим более 16Гигабайт, что в значительной мере сужает возможности использования данной технологией.  \u003C\u002Fp\u003E\u003Cp\u003EНа просторах хабра вы уже найдете примеры такого сжатия описанные ранее Давидом Дале в статье «\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fpost\u002F489474\u002F\" rel=\"noopener noreferrer nofollow\"\u003EКак сжать модель fastText в 100 раз\u003C\u002Fa\u003E». Решая эту задачу, а применял рекомендации из данной статьи, и к ним мы еще вернемся, но эта статья уже несколько потеряла свою актуальность, так как часть используемых методов более не работают в новой версии библиотеки Gensim 4.0. Кроме того, применяемый в данной статье имеет более общий характер применения, так как сжатая данный образом модель все же не рассчитана на решение узкой задачи, и как показала практика при решении более узких задач, модель теряет в качестве более существенно, чем это показано на примерах.\u003C\u002Fp\u003E\u003Cp\u003EВ этой статье я расскажу о том, как я сжимал модель FastText для решения конкретной, локальной задачи, при этом основной целью, было именно то, чтобы результаты не отличались, от результатов исходной модели FastText.\u003C\u002Fp\u003E\u003Cp\u003EОсновная суть примененного мною метода, была в том, чтобы исключить из словаря модели FastText не используемые слова. Так как например модель «wiki_ru», содержит в своем корпусе 1,88 млн слов в словаре, и 2 млн n-грамм токенов, (300 мерных) векторов.  \u003C\u002Fp\u003E\u003Cp\u003EДля решения же локальной задачи, я сократил это количество до 80 тысяч слов, и 100 тысяч нграмм, и тем самым получил практически 80 кратное уменьшение размера модели. При этом решая данную задачу я не хотел уменьшать размерность векторов, и заниматься квантизацией, так как это неминуемо снижает качество, из за потери части несущей информации в векторах от такого сжатия.\u003C\u002Fp\u003E\u003Ch3\u003EХод решения\u003C\u002Fh3\u003E\u003Cp\u003EИтак, первое что нужно было сделать, это взять из своего тренировочного корпуса текста список всех слов (токенов), что я собственно и сделал. Мой тренировочный текст хранился в файле train_input.txt.\u003C\u002Fp\u003E\u003Cp\u003EДля создания собственного словаря, я воспользовался библиотекой gensim и механизмом тренировки FastText. Да, наверное это не самый лучший способ, но мне он показался достаточно гибки, для решения именно этой задачи, где я мог параметрами вроде min_count управлять размером своего полученного словаря.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"354\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69a\u002F70d\u002Fd2c\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png\" data-width=\"655\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EСледующей этапом, я хотел добиться, чтобы полученная модель выдавала аналогичные результаты запроса при похожих слов текста, поэтому кроме слов из своего корпуса, в будущий корпус текста своей модели, я так же добавил слова из TOP 10, похожих слов используя метод most_similar\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"414\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa4a\u002F437\u002Fdaf\u002Fa4a437daf5f9517ae08fca14f9298791.png\" data-width=\"601\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНо вероятно, и этого может показаться мало. Ведь мы знаем, что модель fastText хранит в себе не только слова но и n-граммы слов. Потому, как модель способна разбивать слова на n-граммы и в своей части хранит их в том числе и в словаре. Поэтому следующим этапом, каждое слово из полученного словаря, я разбил на n-граммы слов, и тоже добавил их в наш полученный словарь.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"124\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F713\u002Ff35\u002Fa30\u002F713f35a30c194771ffb53abd14e8a96b.png\" data-width=\"537\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EТаким образом я получил общий словарь, в котором получилось 32 тысячи слов и 50 тысяч n-грамм слов из словаря, что в сумме составило 72 тысячи слов. Однако я решил не ограничиваться только этим словарем, и в завершение добавил еще 8000 тысяч слов наиболее часто встречающихся из модели FastText «wiki_ru», как это рекомендуется из вышеуказанной статьи, чтобы модель была более устойчива, в том числе, к новым неизвестным ей словам.\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"183\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fa0c\u002F264\u002F94d\u002Fa0c26494dfd401425d861100c7669d88.png\" data-width=\"475\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EДалее из полученных слов, составлен итоговый словарь. При этом важным являлось, то, чтобы порядок слов не отличался от основной модели. Так как словарь составлен в порядке частоты встречаемости слов.\u003C\u002Fp\u003E\u003Cp\u003EПосле генерации словаря, важным моментом в настройке новой модели FastText является переупаковка матриц хэшей n-грамм. Метод которой было описан в статье Андреем Васнецовым, в этой \u003Ca href=\"https:\u002F\u002Fmedium.com\u002F@vasnetsov93\u002Fshrinking-fasttext-embeddings-so-that-it-fits-google-colab-cd59ab75959e\" rel=\"noopener noreferrer nofollow\"\u003Eстатье\u003C\u002Fa\u003E. Однако данный код так же пришлось немного видоизменить, в связи с обновлением библиотеки gensim.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"245\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F813\u002F343\u002F353\u002F813343353312f28df3826250812e2b10.png\" data-width=\"863\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EВ результате\u003C\u002Fh3\u003E\u003Cp\u003EВ результате данных преобразований, мною была получена модель, которая по свои характеристикам для решения поставленной задачи, ни чуть не уступает в качестве предоставленных результатов её родительской модели. Что очень хорошо видно, при составлении запросов most_similar.  \u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"449\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fb66\u002F3e2\u002F670\u002Fb663e2670bfe3b438f24a43f0399693b.png\" data-width=\"411\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EПолучение векторных представлений слов, предложений, и таблицы результатов схожести, давали сопоставимые результаты.\u003C\u002Fp\u003E\u003Cp\u003EКод для сжатия модели и его последующего применения доступен в моем \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Futrobinmv\u002Fgensim-fasttext-shrink\" rel=\"noopener noreferrer nofollow\"\u003Eрепозитории\u003C\u002Fa\u003E на GitHub.\u003C\u002Fp\u003E\u003Cp\u003EЕсли у вас появились дополнительные идеи, как можно было бы улучшить полученную таким образом модель, напишите в комментарии, я буду очень рад.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"fasttext"},{"titleHtml":"python"},{"titleHtml":"gensim"},{"titleHtml":"machine learning"},{"titleHtml":"word embeddings"},{"titleHtml":"эмбеддинги"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69a\u002F70d\u002Fd2c\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69a\u002F70d\u002Fd2c\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582980\\\u002F\"},\"headline\":\"Как я сжимал модель fastText для реальной задачи в 80 раз в 2021 году\",\"datePublished\":\"2021-10-12T12:51:53+03:00\",\"dateModified\":\"2021-10-22T12:05:54+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Михаил Утробин\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"FastText &mdash; это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582980\\\u002F#post-content-body\",\"about\":[\"h_python\",\"h_machine_learning\",\"h_artificial_intelligence\",\"f_develop\",\"f_popsci\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F582980\\\u002Fdea421c87847d8e7e207852d40806e0b\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F69a\\\u002F70d\\\u002Fd2c\\\u002F69a70dd2c34b0d32e2162b082c7dd1bd.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fa4a\\\u002F437\\\u002Fdaf\\\u002Fa4a437daf5f9517ae08fca14f9298791.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F713\\\u002Ff35\\\u002Fa30\\\u002F713f35a30c194771ffb53abd14e8a96b.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fa0c\\\u002F264\\\u002F94d\\\u002Fa0c26494dfd401425d861100c7669d88.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F813\\\u002F343\\\u002F353\\\u002F813343353312f28df3826250812e2b10.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fb66\\\u002F3e2\\\u002F670\\\u002Fb663e2670bfe3b438f24a43f0399693b.png\"]}","metaDescription":"FastText — это отличное решение для предоставления готовых векторных представлений слов, для решения различных задач в области ML и NLP. Но основным недостатком данных моделей является, то что на...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"python,machine_learning,artificial_intelligence"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
