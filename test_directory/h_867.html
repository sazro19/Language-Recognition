<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Использование нейронных сетей для поиска ответов в таблицах / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/582248\/"},"headline":"Использование нейронных сетей для поиска ответов в таблицах","datePublished":"2021-10-07T18:47:04+03:00","dateModified":"2021-10-07T18:51:59+03:00","author":{"@type":"Person","name":"Шкарин Сергей"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угод...","url":"https:\/\/habr.com\/ru\/post\/582248\/#post-content-body","about":["h_machine_learning","f_develop"],"image":["https:\/\/habr.com\/share\/publication\/582248\/0b3d50fd157da15670b2de26c4f57ecd\/","https:\/\/habrastorage.org\/webt\/o1\/qb\/n7\/o1qbn7fcmpgmkg5pcl5qmiy7kw4.png","https:\/\/habrastorage.org\/webt\/ab\/5y\/h0\/ab5yh04f2czwyc8ckvysk3d2y-c.png","https:\/\/habrastorage.org\/webt\/vu\/gi\/ga\/vugigalxus3evocx9aywiqusjxq.png","https:\/\/habrastorage.org\/webt\/a_\/19\/ag\/a_19agzlnwzvdsqlggvzzh1-tui.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Использование нейронных сетей для поиска ответов в таблицах" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Использование нейронных сетей для поиска ответов в таблицах" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Использование нейронных сетей для поиска ответов в таблицах" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="582248" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-07T15:47:04.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/582248/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/582248/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/Kouki_RUS/" title="Kouki_RUS" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/c14/a18/311/c14a18311542505a95ea109563914d7f.jpg" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/Kouki_RUS/" class="tm-user-info__username">
      Kouki_RUS
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-07T15:47:04.000Z" title="2021-10-07, 18:47">7  октября   в 18:47</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Использование нейронных сетей для поиска ответов в таблицах</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <div class="tm-article-snippet__labels"><div class="tm-article-snippet__label"><span>
        Перевод
      </span></div></div> <!----> <!----></div></div> <div class="tm-article-presenter__origin"><a href="https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html" target="_blank" class="tm-article-presenter__origin-link">
                Автор оригинала:
                <span>
                  Thomas Müller
                </span></a></div> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><p>Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик потребительских товаров до финансовой статистики и данных экономического развития страны, спортивных результатов и многого другого. Для того, чтобы найти ответ, сейчас необходимо вручную просматривать эти таблицы или полагаться на специальную службу, которая дает ответы на конкретные вопросы (например, о спортивных результатах). Однако эта информация была бы намного более доступной и полезной, если бы ее можно было запрашивать на естественном языке.</p><br/>
<p>Например, на следующем рисунке показана таблица с рядом вопросов, которые люди могут задать. Ответ на эти вопросы может быть найден в одной или нескольких ячейках таблицы («<em>У какого рестлера было больше всего побед?</em>» — «<em>Which wrestler had the most number of reigns?</em>»), или может потребоваться объединение нескольких ячеек таблицы («<em>Сколько чемпионов мира имеют только одну победу?</em>» — «*How many world champions are there with only one reign?»).</p><br/>
<p><img src="/img/image-loader.svg" alt="image6 (1)" data-src="https://habrastorage.org/webt/o1/qb/n7/o1qbn7fcmpgmkg5pcl5qmiy7kw4.png"/></p><br/>
<p><em>Таблица и вопросы с ожидаемыми ответами. Ответы можно выбрать напрямую из таблицы (#1, #4) или вычислить на основе данных таблицы (#2, #3).</em></p><a name="habracut"></a><br/>
<p><a href="https://www.aclweb.org/anthology/P15-1142/" rel="nofollow noopener noreferrer">Многие</a> <a href="https://www.aclweb.org/anthology/P18-1034/" rel="nofollow noopener noreferrer">недавние</a> <a href="https://www.aclweb.org/anthology/N19-1273" rel="nofollow noopener noreferrer">подходы</a> для этой задачи применяют традиционный <a href="https://en.wikipedia.org/wiki/Semantic_parsing" rel="nofollow noopener noreferrer">семантический парсинг</a>, когда вопрос на естественном языке переводится в <a href="https://en.wikipedia.org/wiki/SQL" rel="nofollow noopener noreferrer">SQL</a>-подобный запрос к базе данных, который затем исполняется для предоставления ответов. Например, вопрос: «Сколько чемпионов мира имеют только одну победу?» будет сопоставлен с таким запросом, как «<code>select count(*) where column("No. of reigns") == 1;</code>», а затем исполнен для получения ответа. Этот подход часто требует серьезной инженерии для генерации синтаксически и семантически корректных запросов, и его трудно масштабировать до произвольных вопросов, а не вопросов об очень конкретных таблицах (например, о спортивных результатах).</p><br/>
<p>В статье «<a href="https://arxiv.org/abs/2004.02349" rel="nofollow noopener noreferrer">TAPAS: Weakly Supervised Table Parsing via Pre-training</a>», принятой на <a href="https://acl2020.org/" rel="nofollow noopener noreferrer">ACL 2020</a>, авторы используют другой подход, расширяющий архитектуру <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="nofollow noopener noreferrer">BERT</a> для кодирования вопроса вместе с табличной структурой данных, в результате чего получается модель, которая затем может указывать прямо на ответ. Вместо создания модели, работающей только с одним типом таблицы, этот подход позволяет создавать модели, применимые к таблицам из широкого диапазона доменов. Авторы показали, что после предварительного обучения на миллионах таблиц Википедии модель демонстрирует конкурентоспособную точность (accuracy) на трех наборах данных академических таблиц с <a href="https://en.wikipedia.org/wiki/Question_answering" rel="nofollow noopener noreferrer">ответами на вопросы</a> (QA). Кроме того, чтобы способствовать более интересным исследованиям в этой области, авторы предоставили открытый исходный код для обучения и тестирования моделей, а также сами модели, предварительно обученные на таблицах Википедии, в своем <a href="https://github.com/google-research/tapas" rel="nofollow noopener noreferrer">репозитории на GitHub</a>.</p><br/>
<h1 id="kak-obrabotat-vopros">Как обработать вопрос</h1><br/>
<p>Чтобы обработать такой вопрос, как «<em>Среднее время пребывания в титуле чемпиона для двух лучших рестлеров?</em>», модель совместно кодирует вопрос, а также содержимое таблицы строка за строкой, используя модель BERT, расширенную за счет специальных эмбеддингов для кодирования структуры таблицы.</p><br/>
<p>Ключевым дополнением к модели BERT на основе архитектуры Трансформер являются дополнительные эмбеддинги, которые используются для кодирования структурированного входа. Эти эмбеддинги кодируют индекс столбца, индекс строки и специальный порядковый индекс, указывающий на порядок элементов в числовых столбцах. На следующем изображении показано, как все это объединяется на входе и подается в слои Трансформера. Также на картинке показано, как закодирован вопрос вместе с небольшой таблицей, показанной слева. Каждый токен ячейки имеет специальный эмбеддинг, который указывает его строку, столбец и порядковый индекс в столбце.</p><br/>
<p><img src="/img/image-loader.svg" alt="image2" data-src="https://habrastorage.org/webt/ab/5y/h0/ab5yh04f2czwyc8ckvysk3d2y-c.png"/></p><br/>
<p><em>Входной слой BERT: каждый входной токен представлен как сумма эмбеддингов его слова, абсолютной позиции, сегмента (принадлежит ли он вопросу или таблице), столбца, строки и порядкового индекса (позиция, которую будет иметь ячейка, если столбец был отсортирован по числовым значениям).</em></p><br/>
<p>Модель имеет два выхода: 1) для каждой ячейки таблицы оценка указывает вероятность того, что эта ячейка будет частью ответа, и 2) операция агрегирования, которая указывает, какая операция (если она есть) применяется для получения окончательного ответа. На следующем рисунке показано, как для вопроса «<em>Среднее время в качестве чемпиона для двух лучших борцов?</em>» модель должна с высокой вероятностью выбрать первые две ячейки столбца «Объединенные дни» и операцию «СРЕДНЕЕ».</p><br/>
<p><img src="/img/image-loader.svg" alt="image1" data-src="https://habrastorage.org/webt/vu/gi/ga/vugigalxus3evocx9aywiqusjxq.png"/></p><br/>
<p><em>Схема модели: слой BERT кодирует как вопрос, так и таблицу. Модель выводит вероятность для каждой операции агрегирования и вероятность выбора для каждой ячейки таблицы. На вопрос «Среднее время в качестве чемпиона для двух лучших борцов?» операция СРЕДНИЙ и ячейки с числами 3,749 и 3,103 должны иметь высокую вероятность.</em></p><br/>
<h1 id="predvaritelnoe-obuchenie">Предварительное обучение</h1><br/>
<p>Используя метод, аналогичный тому, как BERT обучается на тексте, авторы предварительно обучили модель на 6.2 миллионах пар таблица-текст, извлеченных из английской Википедии. Во время предварительного обучения модель учится восстанавливать маскированные слова как в таблице, так и в тексте. Авторы обнаружили, что модель может сделать это с относительно высокой точностью (71.4% замаскированных токенов корректно восстанавливаются для невидимых во время обучения таблиц).</p><br/>
<h1 id="uchimsya-tolko-na-otvetah">Учимся только на ответах</h1><br/>
<p>Во время тонкой настройки модель учится отвечать на вопросы из таблицы. Это достигается путем «строгого» и «мягкого» обучения с учителем (strong and weak supervision). В случае «строгого» обучения для данной таблицы и вопросов необходимо предоставить ячейки и операцию агрегирования для выбора (например, сумма или количество), что является достаточно трудоемким процессом. Чаще всего модели обучаются с помощью «мягкого» обучения, когда дается только правильный ответ (например, 3426 на вопрос в приведенном выше примере). В этом случае модель пытается найти операцию агрегирования и ячейки, которые дают ответ, близкий к правильному. Это делается путем вычисления ожидания по всем возможным решениям агрегирования и сравнения его с истинным результатом. Сценарий «мягкого» обучения выгоден, потому что он позволяет неспециалистам предоставлять данные, необходимые для обучения модели, и занимает меньше времени, чем «строгое» обучение.</p><br/>
<h1 id="poluchennye-rezultaty">Полученные результаты</h1><br/>
<p>Авторы применили свою модель к трем наборам данных — <a href="https://www.microsoft.com/en-us/download/details.aspx?id=54253" rel="nofollow noopener noreferrer">SQA</a>, WikiTableQuestions (<a href="https://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/" rel="nofollow noopener noreferrer">WTQ</a>) и <a href="https://github.com/salesforce/WikiSQL" rel="nofollow noopener noreferrer">WikiSQL</a> — и сравнили ее результаты с тремя самыми современными моделями (state-of-the-art, SOTA) для анализа табличных данных. Модели сравнения включали <a href="https://www.aclweb.org/anthology/D19-1284" rel="nofollow noopener noreferrer">Min et al (2019)</a> для WikiSQL, <a href="https://www.aclweb.org/anthology/D19-1391" rel="nofollow noopener noreferrer">Wang et al. (2019)</a> для WTQ и предыдущие работы самих авторов для SQA (<a href="https://www.aclweb.org/anthology/D19-1603" rel="nofollow noopener noreferrer">Mueller et al., 2019</a>). Для всех наборов данных публикуются метрики точности (accuracy) на тестовых наборах для модели «мягкого» обучения. Для SQA и WIkiSQL использовалась базовая модель, предварительно обученная на Википедии, а для WTQ было решено предварительно дообучить модель на данных SQA. Лучшие модели авторов превосходят предыдущую SOTA для SQA более чем на 12 баллов, предыдущую SOTA для WTQ более чем на 4 балла и работают аналогично лучшей опубликованной модели на WikiSQL.</p><br/>
<p><img src="/img/image-loader.svg" alt="image4" data-src="https://habrastorage.org/webt/a_/19/ag/a_19agzlnwzvdsqlggvzzh1-tui.png"/></p><br/>
<p><em>Метрика точности (accuracy) ответов для «мягкого» обучения на трех академических наборах данных TableQA.</em></p><br/>
<h1 id="avtory">Авторы</h1><br/>
<ul>
<li><strong>Автор оригинала</strong> – Thomas Müller</li>
<li><strong>Перевод</strong> – <a href="https://habr.com/ru/users/smekur/">Смирнова Екатерина</a></li>
<li><strong>Редактирование и вёрстка</strong> – <a href="https://habr.com/ru/users/kouki_rus/">Шкарин Сергей</a></li>
</ul></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BNLP%5D" class="tm-tags-list__link">NLP</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BTAPAS%5D" class="tm-tags-list__link">TAPAS</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BTable%20Parsing%5D" class="tm-tags-list__link">Table Parsing</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 2: ↑2 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 2: ↑2 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+2</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">2.8K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    24
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/Kouki_RUS/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/c14/a18/311/c14a18311542505a95ea109563914d7f.jpg" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 31 голос " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    29
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0.8</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><span class="tm-user-card__name tm-user-card__name_variant-article">Шкарин Сергей</span> <a href="/ru/users/Kouki_RUS/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @Kouki_RUS
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Исследователь данных</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <button type="submit" class="tm-user-card__button btn btn_transparent btn_small">
      Задонатить
    </button> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/582248/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 3 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/582248/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/582248/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"582248":{"id":"582248","timePublished":"2021-10-07T15:47:04+00:00","isCorporative":false,"lang":"ru","titleHtml":"Использование нейронных сетей для поиска ответов в таблицах","leadData":{"textHtml":"\u003Cp\u003EБольшая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик потребительских товаров до финансовой статистики и данных экономического развития страны, спортивных результатов и многого другого. Для того, чтобы найти ответ, сейчас необходимо вручную просматривать эти таблицы или полагаться на специальную службу, которая дает ответы на конкретные вопросы (например, о спортивных результатах). Однако эта информация была бы намного более доступной и полезной, если бы ее можно было запрашивать на естественном языке.\u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Cp\u003EНапример, на следующем рисунке показана таблица с рядом вопросов, которые люди могут задать. Ответ на эти вопросы может быть найден в одной или нескольких ячейках таблицы («\u003Cem\u003EУ какого рестлера было больше всего побед?\u003C\u002Fem\u003E» — «\u003Cem\u003EWhich wrestler had the most number of reigns?\u003C\u002Fem\u003E»), или может потребоваться объединение нескольких ячеек таблицы («\u003Cem\u003EСколько чемпионов мира имеют только одну победу?\u003C\u002Fem\u003E» — «*How many world champions are there with only one reign?»).\u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fo1\u002Fqb\u002Fn7\u002Fo1qbn7fcmpgmkg5pcl5qmiy7kw4.png\" alt=\"image6 (1)\"\u003E\u003C\u002Fp\u003E\u003Cbr\u003E\r\n\u003Cp\u003E\u003Cem\u003EТаблица и вопросы с ожидаемыми ответами. Ответы можно выбрать напрямую из таблицы (#1, #4) или вычислить на основе данных таблицы (#2, #3).\u003C\u002Fem\u003E\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"editorVersion":"1.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"Thomas Müller","originalUrl":"https:\u002F\u002Fai.googleblog.com\u002F2020\u002F04\u002Fusing-neural-networks-to-find-answers.html"}}],"author":{"scoreStats":{"score":29,"votesCount":31},"rating":0.8,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":"shkarinsergey","paymentWebmoney":null},"id":"1821121","alias":"Kouki_RUS","fullname":"Шкарин Сергей","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Fc14\u002Fa18\u002F311\u002Fc14a18311542505a95ea109563914d7f.jpg","speciality":"Исследователь данных"},"statistics":{"commentsCount":3,"favoritesCount":24,"readingCount":2785,"score":2,"votesCount":2},"hubs":[{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EБольшая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик потребительских товаров до финансовой статистики и данных экономического развития страны, спортивных результатов и многого другого. Для того, чтобы найти ответ, сейчас необходимо вручную просматривать эти таблицы или полагаться на специальную службу, которая дает ответы на конкретные вопросы (например, о спортивных результатах). Однако эта информация была бы намного более доступной и полезной, если бы ее можно было запрашивать на естественном языке.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНапример, на следующем рисунке показана таблица с рядом вопросов, которые люди могут задать. Ответ на эти вопросы может быть найден в одной или нескольких ячейках таблицы («\u003Cem\u003EУ какого рестлера было больше всего побед?\u003C\u002Fem\u003E» — «\u003Cem\u003EWhich wrestler had the most number of reigns?\u003C\u002Fem\u003E»), или может потребоваться объединение нескольких ячеек таблицы («\u003Cem\u003EСколько чемпионов мира имеют только одну победу?\u003C\u002Fem\u003E» — «*How many world champions are there with only one reign?»).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"image6 (1)\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fo1\u002Fqb\u002Fn7\u002Fo1qbn7fcmpgmkg5pcl5qmiy7kw4.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cem\u003EТаблица и вопросы с ожидаемыми ответами. Ответы можно выбрать напрямую из таблицы (#1, #4) или вычислить на основе данных таблицы (#2, #3).\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FP15-1142\u002F\" rel=\"nofollow noopener noreferrer\"\u003EМногие\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FP18-1034\u002F\" rel=\"nofollow noopener noreferrer\"\u003Eнедавние\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FN19-1273\" rel=\"nofollow noopener noreferrer\"\u003Eподходы\u003C\u002Fa\u003E для этой задачи применяют традиционный \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FSemantic_parsing\" rel=\"nofollow noopener noreferrer\"\u003Eсемантический парсинг\u003C\u002Fa\u003E, когда вопрос на естественном языке переводится в \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FSQL\" rel=\"nofollow noopener noreferrer\"\u003ESQL\u003C\u002Fa\u003E-подобный запрос к базе данных, который затем исполняется для предоставления ответов. Например, вопрос: «Сколько чемпионов мира имеют только одну победу?» будет сопоставлен с таким запросом, как «\u003Ccode\u003Eselect count(*) where column(\"No. of reigns\") == 1;\u003C\u002Fcode\u003E», а затем исполнен для получения ответа. Этот подход часто требует серьезной инженерии для генерации синтаксически и семантически корректных запросов, и его трудно масштабировать до произвольных вопросов, а не вопросов об очень конкретных таблицах (например, о спортивных результатах).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВ статье «\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.02349\" rel=\"nofollow noopener noreferrer\"\u003ETAPAS: Weakly Supervised Table Parsing via Pre-training\u003C\u002Fa\u003E», принятой на \u003Ca href=\"https:\u002F\u002Facl2020.org\u002F\" rel=\"nofollow noopener noreferrer\"\u003EACL 2020\u003C\u002Fa\u003E, авторы используют другой подход, расширяющий архитектуру \u003Ca href=\"https:\u002F\u002Fai.googleblog.com\u002F2018\u002F11\u002Fopen-sourcing-bert-state-of-art-pre.html\" rel=\"nofollow noopener noreferrer\"\u003EBERT\u003C\u002Fa\u003E для кодирования вопроса вместе с табличной структурой данных, в результате чего получается модель, которая затем может указывать прямо на ответ. Вместо создания модели, работающей только с одним типом таблицы, этот подход позволяет создавать модели, применимые к таблицам из широкого диапазона доменов. Авторы показали, что после предварительного обучения на миллионах таблиц Википедии модель демонстрирует конкурентоспособную точность (accuracy) на трех наборах данных академических таблиц с \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FQuestion_answering\" rel=\"nofollow noopener noreferrer\"\u003Eответами на вопросы\u003C\u002Fa\u003E (QA). Кроме того, чтобы способствовать более интересным исследованиям в этой области, авторы предоставили открытый исходный код для обучения и тестирования моделей, а также сами модели, предварительно обученные на таблицах Википедии, в своем \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fgoogle-research\u002Ftapas\" rel=\"nofollow noopener noreferrer\"\u003Eрепозитории на GitHub\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch1 id=\"kak-obrabotat-vopros\"\u003EКак обработать вопрос\u003C\u002Fh1\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЧтобы обработать такой вопрос, как «\u003Cem\u003EСреднее время пребывания в титуле чемпиона для двух лучших рестлеров?\u003C\u002Fem\u003E», модель совместно кодирует вопрос, а также содержимое таблицы строка за строкой, используя модель BERT, расширенную за счет специальных эмбеддингов для кодирования структуры таблицы.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКлючевым дополнением к модели BERT на основе архитектуры Трансформер являются дополнительные эмбеддинги, которые используются для кодирования структурированного входа. Эти эмбеддинги кодируют индекс столбца, индекс строки и специальный порядковый индекс, указывающий на порядок элементов в числовых столбцах. На следующем изображении показано, как все это объединяется на входе и подается в слои Трансформера. Также на картинке показано, как закодирован вопрос вместе с небольшой таблицей, показанной слева. Каждый токен ячейки имеет специальный эмбеддинг, который указывает его строку, столбец и порядковый индекс в столбце.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"image2\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fab\u002F5y\u002Fh0\u002Fab5yh04f2czwyc8ckvysk3d2y-c.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cem\u003EВходной слой BERT: каждый входной токен представлен как сумма эмбеддингов его слова, абсолютной позиции, сегмента (принадлежит ли он вопросу или таблице), столбца, строки и порядкового индекса (позиция, которую будет иметь ячейка, если столбец был отсортирован по числовым значениям).\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМодель имеет два выхода: 1) для каждой ячейки таблицы оценка указывает вероятность того, что эта ячейка будет частью ответа, и 2) операция агрегирования, которая указывает, какая операция (если она есть) применяется для получения окончательного ответа. На следующем рисунке показано, как для вопроса «\u003Cem\u003EСреднее время в качестве чемпиона для двух лучших борцов?\u003C\u002Fem\u003E» модель должна с высокой вероятностью выбрать первые две ячейки столбца «Объединенные дни» и операцию «СРЕДНЕЕ».\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"image1\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvu\u002Fgi\u002Fga\u002Fvugigalxus3evocx9aywiqusjxq.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cem\u003EСхема модели: слой BERT кодирует как вопрос, так и таблицу. Модель выводит вероятность для каждой операции агрегирования и вероятность выбора для каждой ячейки таблицы. На вопрос «Среднее время в качестве чемпиона для двух лучших борцов?» операция СРЕДНИЙ и ячейки с числами 3,749 и 3,103 должны иметь высокую вероятность.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch1 id=\"predvaritelnoe-obuchenie\"\u003EПредварительное обучение\u003C\u002Fh1\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИспользуя метод, аналогичный тому, как BERT обучается на тексте, авторы предварительно обучили модель на 6.2 миллионах пар таблица-текст, извлеченных из английской Википедии. Во время предварительного обучения модель учится восстанавливать маскированные слова как в таблице, так и в тексте. Авторы обнаружили, что модель может сделать это с относительно высокой точностью (71.4% замаскированных токенов корректно восстанавливаются для невидимых во время обучения таблиц).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch1 id=\"uchimsya-tolko-na-otvetah\"\u003EУчимся только на ответах\u003C\u002Fh1\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВо время тонкой настройки модель учится отвечать на вопросы из таблицы. Это достигается путем «строгого» и «мягкого» обучения с учителем (strong and weak supervision). В случае «строгого» обучения для данной таблицы и вопросов необходимо предоставить ячейки и операцию агрегирования для выбора (например, сумма или количество), что является достаточно трудоемким процессом. Чаще всего модели обучаются с помощью «мягкого» обучения, когда дается только правильный ответ (например, 3426 на вопрос в приведенном выше примере). В этом случае модель пытается найти операцию агрегирования и ячейки, которые дают ответ, близкий к правильному. Это делается путем вычисления ожидания по всем возможным решениям агрегирования и сравнения его с истинным результатом. Сценарий «мягкого» обучения выгоден, потому что он позволяет неспециалистам предоставлять данные, необходимые для обучения модели, и занимает меньше времени, чем «строгое» обучение.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch1 id=\"poluchennye-rezultaty\"\u003EПолученные результаты\u003C\u002Fh1\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EАвторы применили свою модель к трем наборам данных — \u003Ca href=\"https:\u002F\u002Fwww.microsoft.com\u002Fen-us\u002Fdownload\u002Fdetails.aspx?id=54253\" rel=\"nofollow noopener noreferrer\"\u003ESQA\u003C\u002Fa\u003E, WikiTableQuestions (\u003Ca href=\"https:\u002F\u002Fnlp.stanford.edu\u002Fblog\u002Fwikitablequestions-a-complex-real-world-question-understanding-dataset\u002F\" rel=\"nofollow noopener noreferrer\"\u003EWTQ\u003C\u002Fa\u003E) и \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsalesforce\u002FWikiSQL\" rel=\"nofollow noopener noreferrer\"\u003EWikiSQL\u003C\u002Fa\u003E — и сравнили ее результаты с тремя самыми современными моделями (state-of-the-art, SOTA) для анализа табличных данных. Модели сравнения включали \u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FD19-1284\" rel=\"nofollow noopener noreferrer\"\u003EMin et al (2019)\u003C\u002Fa\u003E для WikiSQL, \u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FD19-1391\" rel=\"nofollow noopener noreferrer\"\u003EWang et al. (2019)\u003C\u002Fa\u003E для WTQ и предыдущие работы самих авторов для SQA (\u003Ca href=\"https:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FD19-1603\" rel=\"nofollow noopener noreferrer\"\u003EMueller et al., 2019\u003C\u002Fa\u003E). Для всех наборов данных публикуются метрики точности (accuracy) на тестовых наборах для модели «мягкого» обучения. Для SQA и WIkiSQL использовалась базовая модель, предварительно обученная на Википедии, а для WTQ было решено предварительно дообучить модель на данных SQA. Лучшие модели авторов превосходят предыдущую SOTA для SQA более чем на 12 баллов, предыдущую SOTA для WTQ более чем на 4 балла и работают аналогично лучшей опубликованной модели на WikiSQL.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"image4\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fa_\u002F19\u002Fag\u002Fa_19agzlnwzvdsqlggvzzh1-tui.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cem\u003EМетрика точности (accuracy) ответов для «мягкого» обучения на трех академических наборах данных TableQA.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Ch1 id=\"avtory\"\u003EАвторы\u003C\u002Fh1\u003E\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Cstrong\u003EАвтор оригинала\u003C\u002Fstrong\u003E – Thomas Müller\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Cstrong\u003EПеревод\u003C\u002Fstrong\u003E – \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fusers\u002Fsmekur\u002F\"\u003EСмирнова Екатерина\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Cstrong\u003EРедактирование и вёрстка\u003C\u002Fstrong\u003E – \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fusers\u002Fkouki_rus\u002F\"\u003EШкарин Сергей\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"NLP"},{"titleHtml":"TAPAS"},{"titleHtml":"Table Parsing"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvu\u002Fgi\u002Fga\u002Fvugigalxus3evocx9aywiqusjxq.png","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvu\u002Fgi\u002Fga\u002Fvugigalxus3evocx9aywiqusjxq.png","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582248\\\u002F\"},\"headline\":\"Использование нейронных сетей для поиска ответов в таблицах\",\"datePublished\":\"2021-10-07T18:47:04+03:00\",\"dateModified\":\"2021-10-07T18:51:59+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Шкарин Сергей\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угод...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F582248\\\u002F#post-content-body\",\"about\":[\"h_machine_learning\",\"f_develop\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F582248\\\u002F0b3d50fd157da15670b2de26c4f57ecd\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fo1\\\u002Fqb\\\u002Fn7\\\u002Fo1qbn7fcmpgmkg5pcl5qmiy7kw4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fab\\\u002F5y\\\u002Fh0\\\u002Fab5yh04f2czwyc8ckvysk3d2y-c.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fvu\\\u002Fgi\\\u002Fga\\\u002Fvugigalxus3evocx9aywiqusjxq.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002F19\\\u002Fag\\\u002Fa_19agzlnwzvdsqlggvzzh1-tui.png\"]}","metaDescription":"Большая часть информации в мире хранится в виде таблиц, которые можно найти в Интернете или в базах данных и документах. В таблицах может находиться всё что угодно, от технических характеристик...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"machine_learning"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
