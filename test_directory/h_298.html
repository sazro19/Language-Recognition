<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>HTTP/3: улучшения производительности. Часть 2 / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/company\/southbridge\/blog\/583434\/"},"headline":"HTTP\/3: улучшения производительности. Часть 2","datePublished":"2021-10-19T18:14:35+03:00","dateModified":"2021-10-19T19:26:48+03:00","author":{"@type":"Person","name":"Polina_Averina"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Фото Jack Hunter, Unsplash.com  После почти пятилетней разработки протокол HTTP\/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP\/3 у...","url":"https:\/\/habr.com\/ru\/company\/southbridge\/blog\/583434\/#post-content-body","about":["c_southbridge","h_hi","h_webdev","h_s_admin","h_devops","f_develop","f_admin"],"image":["https:\/\/habr.com\/share\/publication\/583434\/fc35dcb9ceb2a1447e81306c6e4b286c\/","https:\/\/habrastorage.org\/webt\/mp\/mn\/hr\/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg","https:\/\/habrastorage.org\/webt\/ho\/im\/7p\/hoim7p8gofdx8u8jbjmhyzwhj1q.png","https:\/\/habrastorage.org\/webt\/mi\/9h\/ri\/mi9hriqqmce05xmeaalq81xdmys.png","https:\/\/habrastorage.org\/webt\/xr\/ks\/xm\/xrksxm0jdltcfcw7vj-erczaxp0.png","https:\/\/habrastorage.org\/webt\/v7\/v1\/wx\/v7v1wxee63v3t7cphkrstht0ai0.png","https:\/\/habrastorage.org\/webt\/g6\/_n\/wd\/g6_nwda0f8kp219wy6nlnr57e38.png","https:\/\/habrastorage.org\/webt\/ro\/_y\/qz\/ro_yqz59ztve8opucqpj0rfhzlm.gif","https:\/\/habrastorage.org\/webt\/ns\/tw\/yi\/nstwyiqkhw4vawkbrsua2ind3ra.png","https:\/\/habrastorage.org\/webt\/fs\/py\/sv\/fspysv-1_m4aaw-fvxmztiiipom.png","https:\/\/habrastorage.org\/webt\/di\/pk\/3f\/dipk3fhymwvigy6npltvr0qpqx0.png","https:\/\/habrastorage.org\/webt\/x1\/fj\/2r\/x1fj2ru4oj9grl_a1oplehxmk14.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="HTTP/3: улучшения производительности. Часть 2" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="HTTP/3: улучшения производительности. Часть 2" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="HTTP/3: улучшения производительности. Часть 2" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Фото Jack Hunter, Unsplash.com

После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность,..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Фото Jack Hunter, Unsplash.com

После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность,..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Фото Jack Hunter, Unsplash.com

После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность,..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Фото Jack Hunter, Unsplash.com

После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность,..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Фото Jack Hunter, Unsplash.com

После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность,..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="583434" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-19T15:14:35.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/583434/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/company/southbridge/blog/583434/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" companyName="southbridge" data-async-called="true" class="tm-page"><div class="tm-page-width"><div class="tm-page__header"><div class="tm-company-card__branding tm-company-article__branding tm-company-card__branding_loading"><div class="tm-company-card__branding-placeholder"><!----></div> <a href="https://slurm.io/kubernetes-security?utm_source=habr&amp;utm_medium=top&amp;utm_campaign=kubernetes-security&amp;utm_content=top_20-10-2021&amp;utm_term=habr-top"><img src="//habrastorage.org/getpro/habr/branding/307/f03/4ad/307f034ad5afe09d902d1991c541ef3d.png" width="100%" class="tm-company-card__branding-image"></a></div></div> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"><div class="tm-company-card tm-company-article__company-card"><div class="tm-company-card__info"><div class="tm-company-card__header"><a href="/ru/company/southbridge/profile/" class="tm-company-card__avatar"><div class="tm-entity-image"><img alt="" height="48" src="//habrastorage.org/getpro/habr/company/754/d93/3ca/754d933caeb494c6127add17ff60feb5.png" width="48" class="tm-entity-image__pic"></div></a> <a href="https://career.habr.com/companies/southbridge" rel="noopener" target="_blank" class="tm-grade tm-company-card__rating"><div class="tm-rating"><div class="tm-rating__header"><svg height="24" width="24" class="tm-svg-img tm-svg-grade__icon"><title>Оценка компании на Хабр Карьере</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#grade"></use></svg> <div class="tm-rating__counter tm-rating__counter_variant-grade">4.31</div></div> <div class="tm-rating__text tm-rating__text_variant-grade">
    Оценка
  </div></div></a> <div class="tm-rating tm-company-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">159.57</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div> <div class="tm-company-card__info"><a href="/ru/company/southbridge/profile/" class="tm-company-card__name">
        Southbridge
      </a> <div class="tm-company-card__description">Обеспечиваем стабильную работу highload-проектов</div></div></div> <div class="tm-company-card__buttons"><!----> <!----></div></div> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/Polina_Averina/" title="Polina_Averina" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/eab/364/193/eab36419344dc0ed056f430c3212263f.png" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/Polina_Averina/" class="tm-user-info__username">
      Polina_Averina
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-19T15:14:35.000Z" title="2021-10-19, 18:14">19  октября   в 18:14</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>HTTP/3: улучшения производительности. Часть 2</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/company/southbridge/blog/" class="tm-article-snippet__hubs-item-link router-link-active"><span>Блог компании Southbridge</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/hi/" class="tm-article-snippet__hubs-item-link"><span>Высокая производительность</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/webdev/" class="tm-article-snippet__hubs-item-link"><span>Разработка веб-сайтов</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/s_admin/" class="tm-article-snippet__hubs-item-link"><span>Серверное администрирование</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/devops/" class="tm-article-snippet__hubs-item-link"><span>DevOps</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <div class="tm-article-snippet__labels"><div class="tm-article-snippet__label"><span>
        Перевод
      </span></div></div> <!----> <!----></div></div> <div class="tm-article-presenter__origin"><a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/" target="_blank" class="tm-article-presenter__origin-link">
                Автор оригинала:
                <span>
                  Robin Marx
                </span></a></div> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><img src="https://habrastorage.org/r/w780q1/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-src="https://habrastorage.org/webt/mp/mn/hr/mpmnhrdwnrpnxbk385wmq2-lbq8.jpeg" data-blurred="true"/><br/>
<i>Фото Jack Hunter, Unsplash.com</i><br/>
<br/>
После почти пятилетней разработки протокол HTTP/3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP/3 улучшилась производительность, включая контроль перегрузок, блокировки HoL и установку соединения 0-RTT.<br/>
<br/>
Это вторая часть серии о новом протоколе HTTP/3. В первой мы говорили о том, <a href="https://habr.com/ru/company/southbridge/blog/575464/">зачем нам вообще нужен HTTP/3</a>, о протоколе QUIC и новых возможностях.<br/>
<a name="habracut"></a><br/>
Во второй части вы увидите, как QUIC и HTTP/3 <b>повышают производительность</b> при загрузке веб-страниц. Спойлер: не ждите слишком многого.<br/>
<br/>
У QUIC и HTTP/3 отличный потенциал, но порадуют они, в основном, <b>пользователей в медленных сетях</b>. Если сеть и так быстрая, скорее всего, вы почти ничего не заметите. Но даже в странах и регионах с быстрой связью, 1% или даже 10% пользователей с самым медленным соединением (<i>99-й</i> и <i>90-й перцентили</i>) могут приятно удивиться. Дело в том, что HTTP/3 и QUIC решают проблемы, которые встречаются не так часто, но могут сильно затруднять работу.<br/>
<br/>
В этой части будет <b>больше технических деталей</b>, чем в первой, но в самые глубины мы лезть не будем — просто приведём список дополнительных ресурсов о том, что новый протокол даст среднестатистическому веб-разработчику.<br/>
<br/>
<ul>
<li><a href="https://habr.com/ru/company/southbridge/blog/575464/"><b>Часть 1: История и ключевые концепции HTTP/3</b><br/>
</a>Эта часть для тех, кто в целом мало что знает об HTTP/3 и протоколах. Здесь мы говорим о самых основах.<br/>
</li>
<li><b>Часть 2: Характеристики производительности HTTP/3</b><br/>
Тут мы углубимся в технические детали. Если с основами вы уже знакомы, начинайте со второй части.<br/>
</li>
<li><a href="https://www.smashingmagazine.com/2021/09/http3-practical-deployment-options-part3/"><b>Часть 3: развертывание HTTP/3 на практике</b><br/>
</a>Здесь описываются трудности, связанные с самостоятельным развёртыванием и тестированием HTTP/3. Мы поговорим, как нужно изменить веб-страницы и ресурсы и нужно ли вообще <i>(примечание переводчика: перевод третьей части тоже появится в нашем блоге в ближайшее время)</i>.<br/>
</li>
</ul><br/>
<h2>Скорость </h2><br/>
Говорить о производительности и скорости сложно, потому что веб-страницы загружаются медленно по многим причинам. Раз речь о сетевых протоколах, мы рассмотрим сетевые аспекты. И самые важные из них — задержка и полоса пропускания.<br/>
<br/>
Задержкой мы будем считать <b>время, которое требуется для доставки пакета из точки А (допустим, клиента) в точку Б (сервер)</b>. В теории мы ограничены скоростью света, а на практике — скоростью прохождения сигналов по проводным или беспроводным сетям. В итоге задержка часто зависит от физического расстояния между точками А и Б.<br/>
<br/>
<a href="https://www.youtube.com/watch?v=6bbN48zCNl8">На планете Земля</a> это значит, что задержки небольшие, от 10 до 200 мс. Но это только в одну сторону — ведь нужно ещё дождаться ответа. Задержка при передаче туда и обратно называется <b>временем кругового пути (round-trip time, RTT)</b>.<br/>
<br/>
Из-за таких функций, как <i>контроль перегрузок</i> (см. ниже), круговых путей даже для загрузки одного-единственного файла будет немало, как правило. Поэтому даже если задержка меньше 50 мс, в сумме может получиться гораздо больше. И это одна из главных причин, по которым мы используем сети доставки контента (CDN): в них серверы находятся физически ближе к конечным пользователям, чтобы максимально сократить задержку.<br/>
<br/>
Полоса пропускания — <b>это число пакетов, которые можно отправить одновременно</b>. Эту концепцию сложнее объяснить, потому что она зависит от физических свойств среды (например, частоты радиоволн), числа пользователей в сети и устройств, которые соединяют разные подсети (потому что они обычно могут обрабатывать ограниченное количество пакетов в секунду).<br/>
<br/>
Представьте себе трубу, по которой течёт вода. Длина трубы определяет задержку, а диаметр — полосу пропускания. Интернет можно сравнить с <b>целой системой разных труб</b>, и в трубах с маленьким диаметром возникают узкие места. Поэтому полоса пропускания между точками А и Б обычно ограничена самым медленным отрезком.<br/>
<br/>
Все тонкости мы рассматривать не будем, для понимания этой статьи достаточно общего представления. Если хотите узнать больше, читайте <a href="https://hpbn.co/primer-on-latency-and-bandwidth/">превосходную главу о задержках и полосе пропускания</a> в книге Ильи Григорика (Ilya Grigorik) <i>High Performance Browser Networking</i>.<br/>
<br/>
<h2>Контроль перегрузок </h2><br/>
Один из аспектов производительности — насколько <b>эффективно</b> транспортный протокол может использовать полную (физическую) пропускную способность, т. е. сколько пакетов можно отправлять и получать в секунду. От этого зависит, как быстро загружаются ресурсы страницы. Некоторые считают, что в этом QUIC гораздо лучше TCP, но это не так.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
TCP-соединение, например, не начинает сразу отправлять данные на полную полосу пропускания, чтобы избежать перегрузки сети. Мы уже говорили, что каждый сетевой канал физически может обработать только определённый объём данных в секунду. Отправьте больше — и лишнее придётся отбросить, что приведет к <b>потере пакетов</b>.<br/>
<br/>
В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы уже говорили, что TCP может исправить потерю пакетов только одним способом — заново отправить данные. Для этого требуется ещё один проход туда-обратно. В сетях с большой задержкой (больше 50 мс RTT) потеря пакетов может серьезно снижать производительность.</blockquote><br/>
<br/>
Ещё одна проблема — мы не знаем заранее, какой будет максимальная <b>полоса пропускания</b>. Где-то по пути может возникнуть узкое место, но где это будет — угадать невозможно. В интернете пока нет механизмов, с помощью которых можно сообщать конечным точкам о ёмкости каналов.<br/>
<br/>
И даже если бы мы знали о доступной физической полосе пропускания, это не означало бы, что вся она достанется нам. Обычно её делят между собой сразу много пользователей.<br/>
<br/>
Соединение не знает, какую полосу пропускания получит, к тому же это значение меняется вместе с величиной активного потребления полосы у провайдеров. Чтобы решить эту проблему, TCP постоянно пытается выяснить доступную полосу пропускания с помощью механизма контроля перегрузки — <b>congestion control</b>.<br/>
<br/>
В начале соединения протокол отправляет несколько пакетов (от 10 до 100, или от 1<b>4 до 140 КБ</b> данных) и ждёт ответа о получении этих пакетов. Если получение подтверждено, значит сеть справляется с такой скоростью и можно попробовать отправить больше данных (обычно объём увеличивается вдвое при каждой итерации).<br/>
<br/>
Скорость отправки растёт до тех пор, пока какие-то пакеты не останутся без подтверждения. Это значит, что сеть перегружена, и они потерялись. Такой алгоритм называется медленным стартом. Заметив пропажу, TCP уменьшает скорость, а через какое-то время пытается увеличить её снова, но с меньшим шагом приращения. Затем эта логика повторяется каждый раз при потере пакетов. По сути, это означает, что TCP всегда пытается получить свою максимально доступную долю полосы пропускания. Этот механизм показан на рисунке 1.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ho/im/7p/hoim7p8gofdx8u8jbjmhyzwhj1q.png"/><i>Рис. 1. Упрощённая схема контроля перегрузок: TCP начинает с 10 пакетов (адаптация с сайта <a href="https://hpbn.co/building-blocks-of-tcp/#congestion-avoidance-and-control">hpbn.co</a>) (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9d5e5ddd-7a90-48c6-84c5-dc5c335e2305/congestion-control.png">исходное изображение</a>)</i>.<br/>
<br/>
Это <i>очень</i> упрощённое объяснение контроля перегрузок. На практике здесь участвует много факторов, например, <a href="https://www.youtube.com/watch?v=ZeCIbCzGY6k">bufferbloat (излишняя буферизация)</a>, <a href="https://blog.apnic.net/2017/05/09/bbr-new-kid-tcp-block/">колебания RTT из-за перегрузки</a> и тот факт, что <a href="https://justinesherry.com/papers/ware-hotnets19.pdf">получить свою долю полосы пропускания</a> стараются сразу несколько желающих. Существуют и продолжают появляться разные алгоритмы контроля перегрузок, но ни один из них не универсален.<br/>
<br/>
Механизм контроля перегрузок TCP повышает надежность, но <b>оптимальная скорость отправки</b> достигается не сразу, в зависимости от RTT и фактически доступной полосы пропускания. При загрузке веб-страниц медленный старт влияет на метрики, например, время до первой полезной отрисовки контента (First Contentful Paint), потому что в первых нескольких проходах туда и обратно передаётся очень маленький объём данных (пара десятков или сотен килобайт). (Слышали, наверное, о рекомендации <a href="https://www.tunetheweb.com/blog/critical-resources-and-the-first-14kb/">укладывать критически важные данные в 14 КБ</a>.)<br/>
<br/>
Если действовать агрессивнее, можно улучшить результаты в сетях с большой полосой пропускания и задержкой, особенно если потеря пакетов для вас не проблема. На эту тему бытует много <b>заблуждений</b> о принципах работы QUIC.<br/>
<br/>
В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы говорили, что в теории QUIC меньше страдает от потери пакетов (и связанной блокировки HoL), потому что обрабатывает каждый поток байтов независимо. Кроме того, QUIC использует <i>протокол UDP</i>, у которого, в отличие от TCP, нет встроенной функции контроля перегрузок. С ним можно попытаться отправить данные на любой скорости, но потерянные данные он не будет передавать заново.<br/>
<br/>
В итоге появилось много статей, где говорится, что QUIC не контролирует перегрузки, а просто сразу отправляет данные на высокой скорости по UDP, решая проблему потери пакетов благодаря отсутствию блокировки HoL. Потому, мол, QUIC гораздо быстрее TCP.<br/>
<br/>
В реальности <a href="https://www.rfc-editor.org/rfc/rfc9002.html">это максимально далеко от истины</a>: <b>методы управления полосой пропускания у QUIC очень похожи на то, что делает TCP</b>. QUIC тоже начинает с невысокой скорости и увеличивает её со временем, используя подтверждения, чтобы измерять пропускную способность сети. Отчасти это связано с тем, что QUIC должен обеспечивать надёжность, чтобы его можно было использовать с HTTP, потому что кроме него есть и другие QUIC (и TCP!) соединения и потому что удаление блокировки HoL не гарантирует полную защиту от потери пакетов (как мы увидим чуть позже).<br/>
<br/>
Это не значит, что QUIC не может управлять полосой пропускания чуточку умнее, чем TCP. В основном, потому что <b>QUIC дает больше гибкости и его проще развивать</b>. Мы уже сказали, что алгоритмы контроля перегрузок по-прежнему активно развиваются, например, чтобы <a href="https://dl.acm.org/doi/abs/10.1145/3387514.3405882">максимально эффективно использовать технологию 5G</a>.<br/>
<br/>
TCP обычно реализуется в ядре ОС, самой защищённой и самой ограниченной среде, к тому же проприетарной в большинстве ОС. Поэтому логика контроля перегрузок в ОС обычно реализуется ограниченным кругом разработчиков, что замедляет развитие технологии.<br/>
<br/>
Большинство реализаций QUIC, наоборот, находятся в пользовательском пространстве, где мы обычно запускаем нативные приложения, и имеют <a href="https://github.com/quicwg/base-drafts/wiki/Implementations">открытый исходный код</a> — как раз для того, чтобы как можно больше разработчиков экспериментировали с ним (и <a href="https://research.fb.com/wp-content/uploads/2019/12/MVFST-RL-An-Asynchronous-RL-Framework-for-Congestion-Control-with-Delayed-Actions.pdf">Facebook</a> уже подает пример).<br/>
<br/>
Ещё один пример — расширение для <a href="https://tools.ietf.org/html/draft-iyengar-quic-delayed-ack-02"><i>отложенной отправки подтверждений</i></a>, предложенное для QUIC. По умолчанию QUIC отправляет подтверждения для каждых двух полученных пакетов. С помощью расширения можно настроить подтверждение, допустим, для каждых десяти пакетов. Такой подход показал <b>значительное увеличение скорости</b> в спутниковых сетях и сетях с большой полосой пропускания, потому что издержки на передачу подтверждений снизились. Внедрять такое расширение для TCP было бы очень долго, а с QUIC все гораздо проще.<br/>
<br/>
Мы ожидаем, что благодаря гибкости QUIC будет больше экспериментов, и алгоритмы контроля перегрузок со временем улучшатся. Эти наработки потом можно будет перенести на TCP.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
В официальном <a href="https://www.rfc-editor.org/rfc/rfc9002.html">QUIC Recovery RFC 9002</a> описано использование алгоритма контроля перегрузок NewReno. Это надежный, но немного <b>устаревший</b> подход, который уже не очень широко используется на практике. Тогда почему он включен в QUIC RFC? Во-первых, потому, что в начале разработки QUIC алгоритм NewReno был самым современным из стандартизированных. Более продвинутые алгоритмы, вроде BBR и CUBIC, до сих пор не стандартизированы или <a href="https://datatracker.ietf.org/doc/html/rfc8312">только недавно</a> стали RFC.<br/>
<br/>
Во-вторых, NewReno относительно просто настраивать. Поскольку любой алгоритм нужно адаптировать, чтобы учесть отличия QUIC от TCP, с простым алгоритмом будет приятнее иметь дело. Поэтому RFC 9002 можно считать скорее рекомендацией по тому, как настроить контроль перегрузок для QUIC, чем требованием использовать с QUIC именно этот алгоритм. По факту большинство реализаций QUIC на уровне продакшена используют кастомные варианты <a href="https://blog.cloudflare.com/cubic-and-hystart-support-in-quiche/">Cubic</a> и <a href="https://qlog.edm.uhasselt.be/epiq/files/QUICImplementationDiversity_Marx_final_11jun2020.pdf">BBR</a>.<br/>
<br/>
Повторю: алгоритмы контроля перегрузок <b>не привязаны к TCP или QUIC</b>. Их можно использовать для обоих протоколов, и мы надеемся, что усовершенствования в QUIC доберутся и до TCP.</blockquote><br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
С концепцией контроля перегрузок связан механизм <a href="https://www.rfc-editor.org/rfc/rfc9000.html#name-flow-control">контроля потоков</a> (flow-control). Их часто путают в TCP, потому что они оба используют <b>TCP window</b> (окно TCP), хотя окон по сути два: congestion window и receive window. Flow control, впрочем, не так важен для загрузки веб-страниц, поэтому здесь мы не будем о нём говорить. Если интересно, см. <a href="https://qlog.edm.uhasselt.be/epiq/files/QUICImplementationDiversity_Marx_final_11jun2020.pdf">исследование</a>, <a href="https://youtu.be/HQ1uIClmzkU?t=603">видео</a> или <a href="https://blog.cloudflare.com/delivering-http-2-upload-speed-improvements/">статью</a>.</blockquote><br/>
<h4>Что всё это значит? </h4><br/>
QUIC по-прежнему подчиняется законам физики и должен проявлять уважение к остальным отправителям в сети. Он <b>не сможет</b> волшебным образом загружать ресурсы на сайте гораздо быстрее, чем TCP. Но QUIC очень гибкий, а значит экспериментировать с алгоритмами контроля перегрузок будет проще. TCP от этого в итоге тоже выиграет.<br/>
<br/>
<h2>Установка соединения 0-RTT </h2><br/>
Второй аспект производительности — <b>сколько раз нужно совершить круговой путь</b>, прежде чем можно будет отправить полезные данные HTTP (ресурсы страницы, например) в новом соединении. Кто-то говорит, что QUIC на два-три цикла быстрее, чем TCP + TLS, но на самом деле мы экономим всего один цикл.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
В <a href="https://www.smashingmagazine.com/2021/08/http3-core-concepts-part1/">первой части</a> мы уже говорили, что обычно соединению требуется одно (TCP) или два (TCP + TLS) рукопожатия, прежде чем можно будет обмениваться HTTP-запросами и ответами. При этих рукопожатиях клиент и сервер обмениваются начальными параметрами, которые нужны им, например, для шифрования данных.<br/>
<br/>
Как видно на рисунке 2, каждому <i>отдельному</i> рукопожатию нужен как минимум один круговой путь (TCP + TLS 1.3, (b)), а иногда и все два (TLS 1.2 и ниже (a)). Это неэффективно, потому что нам приходится ждать как минимум <b>два прохода туда и обратно</b>, прежде чем можно будет отправить первый HTTP-запрос, то есть первые данные ответа HTTP (красная стрелка обратно) поступят минимум через три круга. В медленных сетях это может приводить к дополнительной задержке в 100–200 мс.</blockquote><br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/mi/9h/ri/mi9hriqqmce05xmeaalq81xdmys.png"/><br/>
<i>Рис. 2: Установка соединения TCP + TLS и QUIC (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9f4c69d1-5ab6-4ca2-ad1e-ec68d99dc9ab/connection-setup-1.png">исходное изображение</a>)</i>.<br/>
<br/>
Странно же, что нельзя объединить рукопожатия TCP + TLS в одном проходе? Теоретически это возможно, и QUIC так и делает, но изначально было задумано, что <a href="https://habr.com/ru/company/southbridge/blog/575464/">TCP можно использовать как с TLS, так и без него</a>. Другими словами, TCP просто <b>не поддерживает отправку того, что к нему не относится</b>, во время рукопожатия. Были попытки добавить эту возможность в расширение TCP Fast Open, но, как мы уже сказали в <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a>, оказалось, что в <a href="https://squeeze.isobar.com/2019/04/11/the-sad-story-of-tcp-fast-open">большом масштабе всё это трудно развернуть</a>.<br/>
<br/>
QUIC с самого начался создавался под TLS, поэтому объединяет транспортные и криптографические рукопожатия. Получается, что QUIC нужно совершить один круговой путь, а это ровно на один меньше, чем TCP + TLS 1.3 (см. рис. 2c).<br/>
<br/>
Вы наверняка слышали, что QUIC быстрее на два или даже три круга, но в большинстве статей рассматривают худший сценарий (TCP + TLS 1.2 (2a)) и почему-то забывают, что TCP + TLS 1.3 укладывается в два прохода (2b). Сэкономить один проход, конечно, приятно, но вряд ли вызывает восторг. Если сеть быстрая (допустим, с RTT &lt; 50 мс), <b>этого никто и не заметит</b>, хотя для медленных соединений с отдалённым сервером преимущества будут.<br/>
<br/>
А почему мы вообще должны ждать, пока рукопожатия закончатся? Давайте сразу отправим HTTP-запрос да и всё. Но в этом случае первый запрос будет <b>не зашифрован</b>. Кто угодно сможет перехватить его в нарушение всех требований безопасности и конфиденциальности. Поэтому и приходится ждать, прежде чем отправить первый HTTP-запрос. Или всё-таки это необязательно?<br/>
<br/>
Тут есть одна хитрость. Мы знаем, что пользователи часто возвращаются на веб-страницы вскоре после первого посещения, а значит можно использовать <b>изначальное зашифрованное соединение</b>, чтобы запустить следующее соединение в будущем. Проще говоря, во время первого соединения клиент и сервер безопасно обмениваются новыми криптографическими параметрами. С помощью этих параметров можно с самого начала <b>зашифровать второе соединение</b>, не дожидаясь завершения рукопожатия TLS. Такой подход называется <i>возобновлением сеанса</i>.<br/>
<br/>
С его помощью можно серьёзно оптимизировать процесс: можно отправить первый HTTP-запрос вместе с рукопожатием QUIC/TLS, <b>сэкономив еще один проход туда-обратно</b>! Если использовать TLS 1.3, то ждать рукопожатия TLS вообще не придётся. Такой метод часто называется 0-RTT (хотя, по сути, HTTP-ответ всё-таки приходит после одного кругового пути).<br/>
<br/>
Многие ошибочно считают, что возобновление сеанса и 0-RTT относятся исключительно к QUIC. На самом деле это <i>функции TLS</i>, которые уже в каком-то виде присутствуют в TLS 1.2, а теперь полноценно реализованы в <a href="https://tools.ietf.org/html/rfc8446#section-2.3">TLS 1.3</a>.<br/>
<br/>
Если посмотреть на рисунок 3, будет очевидно, что производительность можно увеличить и для TCP (а значит и для HTTP/2 и даже HTTP/1.1)! Как видите, даже с 0-RTT протокол QUIC по-прежнему <b>всего на один круговой путь</b> опережает стек TCP + TLS 1.3. Разговоры про три круга основаны на сравнении рисунка 2a с рисунком 3f, что, как мы видели, не совсем справедливо.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/xr/ks/xm/xrksxm0jdltcfcw7vj-erczaxp0.png"/><i>Рис. 3: Установка соединения TCP + TLS и QUIC 0-RTT (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ddbd604f-cec4-4e61-9172-707eda88bc99/connection-setup-2.png">исходное изображение</a>)</i>.<br/>
<br/>
Проблема в том, что при использовании 0-RTT, QUIC не может полноценно реализовать эту экономию из соображений безопасности. Чтобы понять это, нужно разобраться, зачем рукопожатие TCP вообще существует. Во-первых, оно позволяет клиенту убедиться, что сервер доступен по указанному IP-адресу, прежде чем отправлять на него данные.<br/>
<br/>
Во-вторых, и это самое главное, сервер должен проверить, что клиент действительно то, за что себя выдает, прежде чем посылать ему данные в ответ. Если помните, в <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы говорили о четырёх параметрах соединения. Так вот, клиент, в основном, идентифицируется по своему IP-адресу. В этом и проблема: <b>IP-адреса можно подделывать!</b><br/>
<br/>
Допустим, злоумышленник запрашивает очень большой файл по HTTP через QUIC 0-RTT. При этом он подменяет IP-адрес, чтобы всё выглядело так, будто запрос 0-RTT поступил с компьютера жертвы. См. рисунок 4 ниже. Сервер QUIC никак не может определить подлинность IP-адреса, потому что это первый пакет от клиента.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/v7/v1/wx/v7v1wxee63v3t7cphkrstht0ai0.png"/><i>Рис. 4: Злоумышленники могут подменять IP-адрес при отправке запроса 0-RTT на сервер QUIC, запуская атаку с усилением (amplification) (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/64b9318e-3f18-4852-b911-409033d8645b/amplification.png">исходное изображение</a>)</i>.<br/>
<br/>
Если сервер просто начнёт отправлять большой файл на этот IP, это приведёт <b>к перегрузке полосы пропускания в сети жертвы</b> (особенно если параллельно отправлено много фейковых запросов). Компьютер жертвы отклонит этот ответ, потому что не запрашивал его, но это уже не важно. Сеть всё равно должна будет обработать эти пакеты!<br/>
<br/>
Также это называется <a href="https://www.f5.com/labs/articles/education/what-is-a-dns-amplification-attack-">reflection attack (amplification attack</a>), и это один из самых распространённых методов DDoS-атак. Такого не случится, если использовать 0-RTT с TCP + TLS, как раз благодаря рукопожатию TCP, которое происходит ещё до первого запроса 0-RTT + TLS.<br/>
<br/>
Поэтому QUIC <b>должен использовать консервативный подход</b>, отвечая на запросы 0-RTT, и ограничить объём отправляемых данных, пока сервер не убедится, что это настоящий клиент, а не жертва. Для QUIC установлен лимит: <a href="https://www.rfc-editor.org/rfc/rfc9000.html#name-address-validation">в три раза больше данных, чем получено от клиента</a>.<br/>
<br/>
Другими словами, коэффициент усиления у QUIC равен трём. Это компромисс между производительностью и безопасностью (случались инциденты, где <a href="https://www.cloudflare.com/learning/ddos/memcached-ddos-attack/">коэффициент усиления был больше 51 000</a>). Обычно клиент сначала отправляет один или два пакета, так что ответ 0-RTT от сервера QUIC <b>не превысит 4–6 КБ</b> (включая остальные издержки QUIC и TLS). Не впечатляет?<br/>
<br/>
Другие проблемы безопасности могут привести, например, к атакам повторного воспроизведения (replay attack), что ограничивает доступные типы HTTP-запросов. Например, Cloudflare разрешает <a href="https://blog.cloudflare.com/introducing-0-rtt/#whatsthecatch">только запросы HTTP GET без параметров запроса</a> в 0-RTT. Очевидно, что это ещё больше снижает потенциальную пользу 0-RTT.<br/>
<br/>
К счастью, у QUIC есть возможность немного улучшить ситуацию. Например, сервер может проверить, поступает ли запрос 0-RTT с <a href="https://www.rfc-editor.org/rfc/rfc9000.html#name-address-validation-for-futu">IP-адреса, с которым у него уже было соединение</a>. Но это работает, только если клиент остаётся в той же сети (частично это ограничивает возможность <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#connection-migration">миграции соединения</a> в QUIC). Даже если всё получится, ответ QUIC будет ограничен из-за логики медленного старта для контроля перегрузок, которую мы обсуждали <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#congestion-control">выше</a>. Как видите, <b>никакого невероятного увеличения скорости мы не получим</b>, разве что сэкономим один круговой путь.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Интересно отметить, что в QUIC коэффициент усиления, равный трём, действует и без 0-RTT (рис. 2c). Это может стать проблемой, если, например, <a href="https://hpbn.co/transport-layer-security-tls/#chain-of-trust-and-certificate-authorities">TLS-сертифкат</a> сервера слишком большой и не поместится в эти 4–6 КБ. В этом случае его придется разделить, и второй фрагмент попадет во второй проход (после подтверждения первых пакетов, чтобы убедиться в подлинности IP-адреса клиента). И тогда <b>для рукопожатий QUIC понадобится два прохода</b> — прямо как у TCP + TLS! Поэтому для QUIC очень важно будет использовать такие методы, как <a href="https://www.fastly.com/blog/quic-handshake-tls-compression-certificates-extension-study">сжатие сертификатов</a>.</blockquote><br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
В некоторых продвинутых системах эти проблемы можно будет хотя бы отчасти решить, чтобы получить больше пользы от 0-RTT. Например, сервер может помнить, какая полоса пропускания была у клиента в последний раз, и применять менее строгие алгоритмы медленного старта для контроля перегрузок для подлинных клиентов. <a href="https://arxiv.org/pdf/1905.03144.pdf">Исследователи уже занимаются</a> этим вопросом и даже <a href="https://tools.ietf.org/html/draft-kuhn-quic-0rtt-bdp-08">предложили подходящее расширение</a> для QUIC. Некоторые компании используют что-то подобное для ускорения TCP.<br/>
<br/>
Ещё один вариант — отправлять с клиентов <b>больше пакетов</b> (например, еще 7 пакетов без полезных данных), чтобы трёхкратное усиление давало хотя бы 12–14 КБ даже после миграции соединения. Я писал об этом в одном из своих <a href="https://qlog.edm.uhasselt.be/epiq/files/QUICImplementationDiversity_Marx_final_11jun2020.pdf">исследований</a>.<br/>
<br/>
Кроме того, неправильно настроенные серверы QUIC могут специально превышать трёхкратный лимит, если им кажется, что это безопасно, или проблемы с безопасностью их не волнуют (в конце концов, никакие <a href="https://tools.ietf.org/html/rfc8962">политики протокола</a> этому не препятствуют).</blockquote><br/>
<h4>Что всё это значит? </h4><br/>
Если с 0-RTT соединение QUIC устанавливается быстрее, это скорее <b>небольшая оптимизация</b>, но уж никак не революция. По сравнению со стеком TCP + TLS 1.3 в лучшем виде, мы экономим максимум один круговой путь, да и то можем отправить только небольшой объём данных из соображений безопасности.<br/>
<br/>
По сути, вы получите большое преимущество только для пользователей в сетях <b>с очень высокой задержкой</b> (допустим, спутниковые сети с RTT > 200 мс) или если отправляете много данных. Пример последнего сценария — сайты с большим объёмом кэшированных данных, а еще одностраничные приложения, которые периодически получают небольшие обновления через API и другие протоколы, например, <a href="https://datatracker.ietf.org/doc/html/draft-ietf-dprive-dnsoquic">DNS-over-QUIC</a>. Если <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/8b935debf13bd176a08326738f5f88ad115a071e.pdf">Google получил очень хорошие результаты с 0-RTT для QUIC</a>, так это потому, что они тестировали его на уже хорошо оптимизированной странице поиска с маленькими ответами на запросы.<br/>
<br/>
В остальных случаях вы сэкономите не больше <b>пары десятков миллисекунд</b>. Даже меньше, если используете сеть CDN (кстати, используйте CDN, если вам важна производительность!).<br/>
<br/>
<h2>Миграция соединения </h2><br/>
Третья особенность ускоряет QUIC при переходе между сетями,<b> поддерживая существующее соединение</b>. Это полезная функция, но смена сетей происходит не так уж часто, и соединению все равно приходится сбрасывать скорость.<br/>
<br/>
В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы говорили, что идентификаторы соединения (CID) в QUIC позволяют переносить соединение при <b>смене сети</b>. В качестве примера мы привели переход с Wi-Fi на 4G во время загрузки большого файла. В TCP пришлось бы прервать загрузку, а в QUIC она может продолжаться.<br/>
<br/>
Но давайте подумаем, как часто такое вообще происходит. Может показаться, что так бывает, когда мы переходим от одной точки доступа Wi-Fi в здании к другой или между сотовыми вышками в дороге. Но если в такой системе все настроить правильно, устройство сохраняет IP-адрес, потому что переход между беспроводными базовыми станциями выполняется на более низком уровне протокола. В итоге миграция нужна только при <b>переходе между разными сетями</b>, а это не самый частый случай.<br/>
<br/>
Во-вторых: полезна ли эта функция для других сценариев, кроме отправки больших файлов или онлайн-конференции? Если вы загружаете веб-страницу и в этот самый момент переходите между сетями, придется повторно запросить некоторые последние ресурсы.<br/>
<br/>
Но загрузка страницы занимает секунды, маловероятно, что этот период совпадёт со сменой сети. Более того, в сценариях, где это действительно проблема, <b>уже настроены другие механизмы миграции</b>. Например, серверы, с которых загружают большие файлы, могут поддерживать <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests">HTTP-запросы с диапазоном</a>, чтобы загрузку можно было возобновлять.<br/>
<br/>
Поскольку есть <b>переходный период</b>, пока первая сеть отключается, а вторая подключается, видеоприложения могут открывать несколько соединений (по одному на сеть), синхронизируя их после полного отключения первой сети. Пользователь заметит переключение, но перерывов в воспроизведении видео быть не должно.<br/>
<br/>
В-третьих, нет никаких гарантий, что в новой сети будет такая же полоса пропускания, как в старой. Поэтому даже если по сути соединение не прерывается, сервер QUIC не может отправлять данные на прежней высокой скорости. Чтобы избежать перегрузки в новой сети, он должен <b>сбросить (или хотя бы снизить) скорость отправки</b> и снова начать с <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#congestion-control">медленного старта</a>.<br/>
<br/>
Начальная скорость обычно слишком маленькая, чтобы поддержать видеостриминг, так что вы заметите <b>потерю качества</b> или короткие сбои даже с QUIC. В каком-то смысле миграция соединения нужна скорее не для повышения производительности, а для того, чтобы сохранить контекст соединения и не потреблять лишние ресурсы сервера.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Если очень постараться, можно оптимизировать миграцию соединения. Например, можно попытаться запомнить, <b>какая полоса пропускания была доступна</b> в конкретной сети в прошлый раз, и быстрее увеличить скорость до этого уровня при миграции. Ещё можно представить, что мы не просто переключаемся между сетями, а используем их обе одновременно. Эта концепция называется <i>multipath</i>, и <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#future-developments-to-look-out-for">мы поговорим о ней чуть позже</a>.</blockquote><br/>
Пока мы, в основном, говорили об активной миграции соединения, когда пользователи перемещаются между сетями. Но бывает еще и <a href="https://www.rfc-editor.org/rfc/rfc9000.html#name-connection-migration">пассивная миграция</a>, когда сама сеть меняет параметры. Хороший пример — повторная привязка <a href="https://computer.howstuffworks.com/nat.htm">NAT</a> (преобразование сетевых адресов). Здесь мы не будем подробно говорить о NAT, но суть в том, что <b>номера портов могут меняться</b> в любое время без предупреждения. На большинстве роутеров это чаще происходит для UDP, чем для TCP.<br/>
<br/>
В таких случаях QUIC CID не меняется, и большинство реализаций протокола предполагают, что пользователь находится в той же физической сети, а значит не сбрасывают окно перегрузки и другие параметры. QUIC также использует <a href="https://www.rfc-editor.org/rfc/rfc9000.html#https://www.rfc-editor.org/rfc/rfc9000.html">PING</a> и <a href="https://www.rfc-editor.org/rfc/rfc9000.html#idle-timeout">индикаторы таймаута</a>, чтобы предотвратить подобное, потому что обычно это происходит с соединениями, которые долго неактивны.<br/>
<br/>
В <a href="https://www.smashingmagazine.com/2021/08/http3-core-concepts-part1/#quic-supports-connection-migration">первой части</a> мы говорили, что для безопасности QUIC использует несколько CID. При миграции CID меняется. На практике всё сложнее, потому что у клиента и сервера есть отдельные списки CID (<a href="https://www.rfc-editor.org/rfc/rfc9000.html#name-connection-id">в QUIC RFC они называются CID источника и назначения</a>). См. рисунок 5.<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/g6/_n/wd/g6_nwda0f8kp219wy6nlnr57e38.png"/><i>Рис. 5: QUIC использует отдельные CID для клиента и сервера(<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6a0b9339-6976-458d-afc2-4a0cb97a7291/4-migration-src-dst-cid.png">исходное изображение</a>)</i>.<br/>
<br/>
Это позволяет <b>каждой конечной точке выбирать собственный формат CID</b> и содержимое. Это важно для расширенной логики маршрутизации и балансировки нагрузки. При миграции соединения балансировщики нагрузки не могут просто идентифицировать соединение по четырем параметрам и направить его на нужный бэкенд-сервер. Если бы все QUIC-соединения использовали случайные CID, это потребовало бы много памяти на стороне балансировщика нагрузки, потому что пришлось бы хранить соответствия CID с бэкенд-серверами. Миграции бы не получалось, потому что CID менялись бы на новые случайные значения.<br/>
<br/>
Поэтому важно, чтобы у бэкенд-серверов QUIC, развернутых за балансировщиком нагрузки, был <b>предсказуемый формат CID</b>. Тогда балансировщик сможет определить по CID нужный сервер даже после миграции. Способы добиться этого описаны в <a href="https://datatracker.ietf.org/doc/html/draft-ietf-quic-load-balancers-06">документе, предложенном IETF</a>. Для этого у серверов должна быть возможность выбирать собственный CID, но это было бы невозможно, если бы инициатор соединения (для QUIC это всегда клиент) выбирал CID сам. Поэтому CID клиента и сервера в QUIC разделены.<br/>
<br/>
<h4>Что всё это значит? </h4> <br/>
Миграция соединения зависит от ситуации. <a href="https://github.com/quicwg/wg-materials/blob/main/ietf104/IETF_104_QUIC_Connection_Migration.pdf">Начальные тесты Google</a>, например, показывают небольшой процент улучшений для их сценариев. Во многих реализациях QUIC эта функция ещё не поддерживается. А даже если поддерживается, используется для мобильных клиентов и приложений, а не их десктопных эквивалентов. Некоторые даже считают, что эта функция не нужна вовсе, потому что в большинстве случаев установка нового соединения с 0-RTT дает аналогичную производительность.<br/>
<br/>
Всё же для некоторых вариантов применения и пользовательских профилей она может быть очень полезной. <b>Если ваш сайт или приложение обычно используются во время движения</b> (например, Uber или Google Maps), преимущества будут более очевидными, чем в случаях, когда ваши пользователи просто сидят за столом. Если речь о <b>непрерывном взаимодействии</b> (видеочат, совместное редактирование или игры), наихудшие варианты улучшатся заметнее, чем при использовании новостных сайтов.<br/>
<br/>
<h2>Удаление блокировки HoL </h2><br/>
Четвертая функция производительности должна ускорить QUIC в сетях с <b>большими потерями пакетов</b>, решая проблему блокировки HoL. В теории звучит хорошо, но на практике мы, скорее всего, увидим, что производительность при загрузке веб-страниц вырастет незначительно.<br/>
Для начала поговорим о приоритизации потоков и мультиплексировании.<br/>
<br/>
<h4>Приоритизация потоков</h4><br/>
В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы говорили, что потеря одного пакета в TCP может привести к <b>задержке данных для нескольких ресурсов</b>, потому что абстракция потока байтов считает все данные частью одного файла. QUIC видит параллельные, но разные потоки байтов и обрабатывает потерю пакетов для каждого потока отдельно. На самом деле потоки передают данные не совсем параллельно. По сути, данные потока <i>мультиплексируются</i> в одном соединении. Мультиплексирование происходит по-разному.<br/>
<br/>
Например, для потоков A, B и C последовательность отправки пакетов может быть <code>ABCABCABCABCABCABCABCABC</code>, то есть пакеты чередуются по кругу, по принципу round-robin. Порядок может быть и другим, например <code>AAAAAAAABBBBBBBBCCCCCCCC</code>, то есть следующий поток отправляется только после полной отправки предыдущего (назовем это последовательной передачей). Комбинации могут быть разными: <code>AAAABBCAAAAABBC…</code>, <code>AABBCCAABBCC…</code>, <code>ABABABCCCC…</code> и т. д. Схема мультиплексирования очень динамичная и управляется функцией приоритизации потоков на уровне HTTP (<a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#stream-prioritization">подробнее об этом чуть позже</a>).<br/>
<br/>
Оказывается, выбор схемы мультиплексирования заметно влияет на производительность загрузки сайта. Это видно на видео внизу (спасибо <a href="https://blog.cloudflare.com/better-http-2-prioritization-for-a-faster-web/">Cloudflare</a>), поскольку у каждого браузера свой мультиплексор. У этого явления множество причин, и я не раз писал об этом (например, <a href="https://speeder.edm.uhasselt.be/www18/files/h2priorities_mwijnants_www2018.pdf">здесь</a> и <a href="https://h2.edm.uhasselt.be/files/ResourceMultiplexing_H2andH2_Marx2020.pdf">здесь</a>) и <a href="https://www.youtube.com/watch?v=nH4iRpFnf1c">рассказывал</a> на конференции. Патрик Минан (Patrick Meenan), создатель <a href="https://www.webpagetest.org/">Webpagetest</a>, записал целое <a href="https://www.youtube.com/watch?v=ct5MvtmL1NM">трехчасовое руководство</a> исключительно на эту тему.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ro/_y/qz/ro_yqz59ztve8opucqpj0rfhzlm.gif"/><i>Как различия в мультиплексировании влияют на загрузку сайтов в разных браузерах (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6a0b9339-6976-458d-afc2-4a0cb97a7291/4-migration-src-dst-cid.png">исходник</a>)</i>.<br/>
<br/>
К счастью, основы можно объяснить относительно просто. Возможно, вы знаете, что некоторые ресурсы <a href="https://web.dev/render-blocking-resources/">блокируют рендеринг</a>. Так бывает с файлами CSS и иногда с JavaScript в элементе HTML <code>head</code>. Эти файлы загружаются, но браузер не может отрисовать страницу (или, например, выполнить новые JavaScript).<br/>
<br/>
Более того, файлы CSS и JavaScript нужно <b>загрузить полностью</b>, чтобы использовать (хотя их часто можно парсить и компилировать постепенно). Такие ресурсы нужно загружать как можно быстрее, у них наивысший приоритет. Что будет, если ресурсы A, B и C будут блокировать рендеринг?<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ns/tw/yi/nstwyiqkhw4vawkbrsua2ind3ra.png"/><i>Рис. 6: Подход к мультиплексированию потока влияет на время загрузки ресурсов, блокирующих рендеринг (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/46ae54c1-2985-4c47-9ebe-18686bbfc4ce/multiplexing-render-blocking.png">исходное изображение</a>)</i>.<br/>
<br/>
Если использовать <i>принцип round-robin</i> (верхний ряд на рис. 6), мы задержим загрузку каждого ресурса, потому что им придется делить полосу пропускания с остальными. Раз их можно использовать только после полной загрузки, задержка будет значительной. Если мультиплексировать их последовательно (нижний ряд на рис. 6), A и B загрузятся гораздо раньше и будут доступны для браузера, при этом они не повлияют на время загрузки C.<br/>
<br/>
Это не значит, что последовательный подход всегда лучше, потому что ресурсы без блокировки рендеринга (например, HTML и прогрессивный JPEG) можно <b>обрабатывать и использовать постепенно</b>. В этих и некоторых других случаях лучше использовать первый вариант или что-то среднее.<br/>
<br/>
Но для <i>большинства</i> ресурсов веб-страниц <b>последовательное мультиплексирование работает лучше</b>. Так, например, поступает Google Chrome на видео выше, а Internet Explorer использует самый неподходящий мультиплексор с round-robin.<br/>
<br/>
<h4>Устойчивость к потере пакетов</h4><br/>
Итак, мы знаем, что потоки не всегда активны одновременно и могут мультиплексироваться по-разному. Давайте посмотрим, что происходит при потере пакетов. В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы видели, что если в одном потоке QUIC теряется пакет, остальные <i>активные</i> потоки все равно можно использовать (в TCP они будут приостановлены).<br/>
<br/>
Как мы только что узнали, несколько параллельных активных потоков — это обычно не лучший вариант в плане производительности, потому что важные ресурсы с блокировкой рендеринга загружаются медленно даже без потери пакетов. Лучше, чтобы активным был только один или два потока, как в последовательном подходе. Но при такой схеме мы не реализуем весь потенциал удаления блокировок HoL в QUIC.<br/>
<br/>
Допустим, отправитель может передать <b>12 пакетов</b> за раз (см. рис. 7) — помните, что это число ограничено <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#congestion-control">механизмом контроля перегрузки</a>). Если все эти 12 пакетов будут относиться к потоку A (потому что он блокирует рендеринг и имеет высший приоритет — допустим, это <code>main.js</code>), у нас будет всего один активный поток.<br/>
<br/>
Если один из пакетов потеряется, придется применить <b>блокировку HoL</b> — у QUIC просто не будет других потоков для обработки, кроме A. Все данные здесь относятся только к A (у нас нет данных B или C) и остальным ресурсам придется ждать, как в TCP.<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/fs/py/sv/fspysv-1_m4aaw-fvxmztiiipom.png"/><i>Рис. 7: Последствия потери пакетов зависят от мультиплексора. Мы предполагаем, что у каждого потока больше для данных для отправки, чем на предыдущих изображениях (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/05412377-b92f-4adc-9725-4a3b4b4d602a/hol-blocking-rr-sequential.png">исходное изображение</a>)</i>.<br/>
<br/>
Возникает противоречие: последовательное мультиплексирование (<code>AAAABBBBCCCC</code>) обычно лучше для производительности веб-страниц, но оно мешает нам использовать все преимущества удаления блокировки HoL в QUIC. Мультиплексирование по принципу round-robin (<code>ABCABCABCABC</code>) лучше сочетается с отсутствием блокировки HoL, но снижает производительность. В итоге получается, что <b>один метод оптимизации нивелирует другой</b>.<br/>
<br/>
И даже это еще не всё. Пока мы говорили только о потере пакетов по одному за раз. На самом деле пакеты в интернете теряются <a href="https://huitema.wordpress.com/2020/07/12/parsing-quic-logs-and-assessing-packet-losses/">пачками</a>, <b>по несколько штук одновременно</b>.<br/>
<br/>
Выше мы говорили, что пакеты часто теряются, когда сеть уже перегружена данными и отбрасывает лишнее. Затем и нужен медленный старт, после которого скорость увеличивается вплоть до… потери пакетов!<br/>
<br/>
То есть механизм, который должен предотвращать перегрузку сети, по факту <b>перегружает сеть</b> (пусть и контролируемо). В большинстве сетей это происходит через некоторое время, когда пакеты отправляются по несколько сотен за раз. Когда лимит достигнут, можно потерять сразу много пакетов.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Отчасти поэтому мы и хотели перейти на использование одного (TCP) соединения с HTTP/2 вместо 6–30 соединений с HTTP/1.1. Каждое отдельное соединение ускоряется примерно одинаково, поэтому у HTTP/1.1 была бы хорошая скорость в начале, но потом началась бы <b>массовая потеря пакетов</b>, потому что соединения перегрузили бы сеть и мешали друг другу.<br/>
<br/>
В то время <a href="https://a77db9aa-a-7b23c8ea-s-sites.googlegroups.com/a/chromium.org/dev/spdy/An_Argument_For_Changing_TCP_Slow_Start.pdf">разработчики Chromium высказывали предположения</a>, что это поведение отвечает за потерю большинства пакетов в интернете. И это одна из причин, по которым BBR часто используется как алгоритм контроля перегрузок, — он оценивает доступную полосу пропускания по колебаниям в RTT, а не потере пакетов.</blockquote><br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Другие причины могут привести к потере небольшого количества пакетов, особенно в беспроводных сетях. Но там потери обычно обнаруживаются на нижних уровнях протокола и решаются между двумя объектами (скажем, смартфоном и вышкой 4G), а не между клиентом и сервером. Обычно это не приводит к настоящей потере пакетов, а выражается, скорее, как <b>отклонения в задержках</b> (jitter) и поступление пакетов в другом порядке.<br/>
<br/>
Допустим, мы используем подход round-robin (<code>ABCABCABCABCABCABCABCABC…</code>), чтобы получить максимум преимуществ от удаления блокировки HoL, и у нас теряется группа из четырёх пакетов. Такая потеря всегда будет затрагивать все три потока (см. средний ряд на рис. 8). В этом случае удаление блокировки HoL в QUIC не даёт никаких преимуществ, потому что <b>всем потокам придётся ждать повторной передачи</b>.</blockquote><br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/di/pk/3f/dipk3fhymwvigy6npltvr0qpqx0.png"/><i>Рис. 8: В зависимости от мультиплексора и количества потерянных пакетов будет затронут один или несколько потоков(<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/93cb3e10-16dd-4647-af85-91cc723d35f6/hol-blocking-bursty.png">исходное изображение</a>)</i>.<br/>
<br/>
Чтобы потеря группы пакетов не влияла сразу на несколько потоков, нужно передавать подряд больше пакетов из одного потока. Например, схема <code>AABBCCAABBCCAABBCCAABBCC…</code> сработает чуть лучше, а <code>AAAABBBBCCCCAAAABBBBCCCC…</code> — ещё лучше (см. нижний ряд на рис. 8). Более последовательный подход будет эффективнее, хотя с ним у нас будет меньше параллельности.<br/>
<br/>
В целом сложно предсказать, какую пользу мы получим от удаления блокировки HoL в QUIC. Все зависит от числа потоков, размера и частоты потери групп пакетов, фактического использования данных потока и т. д. Однако пока <a href="https://h2.edm.uhasselt.be/files/ResourceMultiplexing_H2andH2_Marx2020.pdf">большинство результатов</a> показывают, что преимущество <b>не так уж заметно</b> при загрузке веб-страниц, потому что в этом сценарии у нас обычно меньше параллельных потоков.<br/>
<br/>
Если хотите больше узнать об этой теме или изучить конкретные примеры, читайте мою <a href="https://calendar.perfplanet.com/2020/head-of-line-blocking-in-quic-and-http-3-the-details/">статью с подробным описанием блокировки HoL в HTTP</a>.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Здесь тоже можно использовать разные хитрости. Например, современные механизмы контроля перегрузки используют <a href="https://homes.cs.washington.edu/~tom/pubs/pacing.pdf">packet pacing</a>. Это значит, что они не отправляют, допустим, 100 пакетов одной группой, а <b>распределяют их</b> по всему RTT. Это снижает вероятность перегрузки сети, и <a href="https://www.rfc-editor.org/rfc/rfc9002.html#https://www.rfc-editor.org/rfc/rfc9002.html">в QUIC Recovery RFC рекомендуется использовать такой подход</a>. Кроме того, некоторые алгоритмы контроля перегрузок, например <a href="https://blog.apnic.net/2017/05/09/bbr-new-kid-tcp-block/">BBR</a>, не повышают скорость отправки до потери пакетов, а останавливаются заранее, учитывая, например, колебания RTT, поскольку RTT возрастает при приближении к перегрузке).<br/>
<br/>
Такие подходы снижают вероятность потери пакетов, но не всегда снижают частоту возникновения такого явления, как потеря пакетов.</blockquote><br/>
<h4>Что всё это значит?</h4><br/>
<br/>
В теории удаление блокировки HoL означает, что QUIC (и HTTP/3) будут работать лучше в сетях с большими потерями, но на практике всё зависит от многих факторов. Поскольку для загрузки веб-страниц лучше подходит более последовательное мультиплексирование, а потеря пакетов непредсказуема, скорее всего, эта функция будет по-настоящему полезна только для <b>1% самых медленных пользователей</b>. Но исследования продолжаются и, может быть, что-то изменится.<br/>
<br/>
В некоторых ситуациях улучшения будут более заметны. В основном, не для первой полноценной загрузки страницы (самого распространённого сценария), а в случаях, когда ресурсы не блокируют рендеринг, и они могут обрабатываться постепенно, тогда как потоки полностью независимы друг от друга или за один раз отправляется меньше данных.<br/>
<br/>
Например, <b>при повторном посещении хорошо кэшированных страниц</b>, фоновых загрузках и вызовах API в одностраничных приложениях. Facebook, скажем, реализует преимущества удаления блокировки HoL, когда загружает данные в их собственное приложение приложение через HTTP/3.<br/>
<br/>
<h2>Производительность UDP и TLS </h2><br/>
Пятый аспект производительности QUIC и HTTP/3 связан с тем, насколько эффективно и продуктивно эти протоколы могут <b>создавать и отправлять пакеты</b> в сети. Мы увидим, что из-за UDP и массового шифрования QUIC может работать медленнее, чем TCP (но постепенно прогрессирует).<br/>
<br/>
Мы <a href="https://habr.com/ru/company/southbridge/blog/575464/">уже говорили</a>, что QUIC использует UDP для гибкости и простоты развёртывания, а не для производительности. Это подтверждает и тот факт, что до последнего времени через QUIC с UDP пакеты отправлялись гораздо медленнее, чем у TCP. Во многом это связано с тем, где и как обычно реализуются эти протоколы (см. рис. 9).<br/>
<br/>
<img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/x1/fj/2r/x1fj2ru4oj9grl_a1oplehxmk14.png"/><i>Рис. 9: Различия в реализации между TCP и QUIC (<a href="https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cffc7945-bd57-459f-b6d3-ed06f51b30ad/kernel-user-space.png">исходное изображение</a>) </i>.<br/>
<br/>
Как мы говорили выше, TCP и UDP обычно реализуются на быстром уровне, прямо в ядре ОС. TLS и QUIC, в основном, реализуются в более медленном пользовательском пространстве (в QUIC это сделано, в основном, для гибкости). Хотя бы из-за этого QUIC работает чуть медленнее, чем TCP.<br/>
<br/>
Кроме того, если данные отправляются из софта в пользовательском пространстве (допустим, браузеров или веб-серверов), мы должны <b>передать эти данные в ядро ОС</b>, которое затем использует TCP или UDP для их передачи в сеть. Данные передаются через API ядра (системные вызовы), что приводит к некоторым издержкам. Для TCP эти издержки были гораздо меньше, чем для UDP.<br/>
<br/>
В основном, потому что традиционно TCP использовался гораздо больше, чем UDP. Со временем в реализации TCP и API ядра добавили много оптимизаций, чтобы свести к минимуму издержки при отправке и получении пакетов. Во многих сетевых платах (NIC) даже есть встроенная аппаратная обработка (hardware-offload) для TCP. UDP не так повезло, потому что он используется ограниченно и вроде как не стоит затраченных усилий. К счастью, в последние пять лет <b>большинство ОС добавили</b> <a href="https://blog.cloudflare.com/how-to-receive-a-million-packets/">варианты оптимизации и для UDP</a>.<br/>
<br/>
QUIC связан с большими издержками, потому что <b>шифрует каждый пакет отдельно</b>. Стек TLS + TCP делает это быстрее и эффективнее, потому что <a href="https://blog.cloudflare.com/optimizing-tls-over-tcp-to-reduce-latency/">пакеты шифруются группами</a> (до 16 КБ или 11 пакетов за раз). В QUIC от этого отказались намеренно, потому что шифрование нескольких пакетов может привести <a href="https://www.igvita.com/2013/10/24/optimizing-tls-record-size-and-buffering-latency/">к блокировке HoL</a>.<br/>
<br/>
Здесь уже нельзя добавить API, чтобы ускорить UDP (и QUIC), а значит по этому показателю QUIC всегда будет отставать от TCP + TLS. Но на практике можно, например, использовать <a href="https://github.com/h2o/picotls/pull/310">оптимизированные библиотеки шифрования</a> и продуманные методы, чтобы шифровать заголовки пакетов QUIC по несколько штук.<br/>
<br/>
Первые версии QUIC от Google работали <a href="https://rjshade.com/work/files/papers/pdf/langley_et_al_sigcomm2017_quic.pdf">в два раза медленнее, чем TCP + TLS</a>, но с тех пор всё стало гораздо лучше. Например, в недавних тестах Microsoft удалось достичь для <a href="https://github.com/microsoft/msquic">тщательно оптимизированного стека QUIC</a> скорости в 7,85 Гбит/с, тогда как TCP + TLS показал 11,85 Гбит/с в той же системе (здесь QUIC примерно на треть медленнее TCP + TLS).<br/>
<br/>
Всё благодаря последним апдейтам Windows, которые ускорили UDP (для полноты сравнения — пропускная способность UDP в этой системе была 19,5 Гбит/с). Самая оптимизированная версия стека QUIC у Google сейчас <a href="https://youtu.be/xxN4FfwaANk?t=3161">на 20% медленнее, чем TCP + TLS</a>. <a href="https://www.fastly.com/blog/measuring-quic-vs-tcp-computational-efficiency">Ранние тесты, проведённые Fastly</a> на менее продвинутых системах и с некоторыми доработками даже показывают одинаковые цифры (примерно 450 Мбит/с), то есть в определённых условиях QUIC вполне может составить конкуренцию TCP.<br/>
<br/>
Но даже если QUIC будет в два раза медленнее TCP + TLS, это не так уж и страшно. Начнем с того, что обработка QUIC и TCP + TLS — не самая ресурсоёмкая задача на сервере, потому что есть и другие процессы (допустим, HTTP, кэширование, прокси и т. д.). Поэтому вам не понадобится <b>в два раза больше серверов для QUIC</b> (пока не совсем ясно, как всё-таки это отразится на реальном дата-центре, потому что никто из крупных компаний ещё не рассказывал об этом).<br/>
<br/>
Во-вторых, есть много возможностей оптимизировать реализации QUIC в будущем. Например, со временем некоторые реализации QUIC будут частично перенесены в ядро ОС (как TCP) или будут обходить его (некоторые уже это делают, например <a href="https://github.com/microsoft/msquic">MsQuic</a> и <a href="https://github.com/NTAP/quant">Quant</a>). Можно ожидать появления <a href="https://datatracker.ietf.org/meeting/104/materials/slides-104-quic-offloading-quic-00">оборудования под QUIC.</a><br/>
<br/>
Скорее всего, в некоторых сценариях TCP + TLS останется предпочтительным вариантом. Например, в Netflix в обозримом будущем не собираются переходить на QUIC, потому что <a href="https://www.youtube.com/watch?v=8NSzkYSX5nY">серьёзно вложились в специфичные решения на базе FreeBSD</a> для стриминга по TCP + TLS.<br/>
<br/>
В Facebook тоже говорят, что из-за больших издержек QUIC пока будет использоваться <b>между конечными пользователями и границей CDN</b>, но не между дата-центрами или граничными узлами и исходными серверами. В целом, если полоса пропускания большая, лучше использовать TCP + TLS. Во всяком случае в следующие пару-тройку лет.<br/>
<br/>
<blockquote><i><b>А вы знали?</b></i><br/>
<br/>
Оптимизация сетевых стеков — это огромное непаханое поле, которое мы пока ковыряем лопаткой. Если вам хватит смелости или очень хочется узнать, что такое <code>GRO/GSO</code>, <code>SO_TXTIME</code>, kernel bypass, <code>sendmmsg()</code> и <code>recvmmsg()</code>, почитайте интересные статьи об оптимизации QUIC от <a href="https://blog.cloudflare.com/accelerating-udp-packet-transmission-for-quic/">Cloudflare</a> и <a href="https://www.fastly.com/blog/measuring-quic-vs-tcp-computational-efficiency">Fastly</a> или посмотрите подробные обзоры от <a href="https://www.youtube.com/watch?v=Icskyw17Dgw">Microsoft</a> и <a href="https://archive.fosdem.org/2020/schedule/event/fast_quic_sockets_for_cloud_networking/">Cisco</a>. Один инженер из Google интересно рассказал, как они <a href="https://www.youtube.com/watch?v=xxN4FfwaANk">планируют оптимизировать свою реализацию QUIC</a>.</blockquote><br/>
<h4>Что всё это значит?</h4><br/>
Из-за подхода к применению протоколов UDP и TLS изначально QUIC был гораздо медленнее, чем TCP + TLS. Сейчас благодаря разным улучшениям он потихоньку догоняет. В обычных условиях при загрузке веб-страниц вы вряд ли что-то заметите, но на больших серверных фермах эти расхождения будут бросаться в глаза.<br/>
<br/>
<h2>Возможности HTTP/3</h2> <br/>
До сих пор мы сравнивали QUIC и TCP. А как насчёт HTTP/3 и HTTP/2? В <a href="https://habr.com/ru/company/southbridge/blog/575464/">первой части</a> мы говорили, что <b>HTTP/3 — это, по сути, HTTP/2-over-QUIC</b>, так что ничего особо нового ждать не приходится. HTTP/1.1 и HTTP/2 гораздо сильнее отличаются друг от друга, например, сжатием заголовков, приоритизацией потоков и server push. Всё это есть и в HTTP/3. Разница в том, как эти возможности реализованы.<br/>
<br/>
В основном, это связано с тем, как работает в QUIC удаление блокировки HoL. <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#head-of-line-blocking-removal">Мы уже говорили</a>, что потеря пакетов из потока B больше не означает, что потокам A и C придётся ждать, пока B догонит, как это было в TCP. Так что если пакеты A, B и C были отправлены через QUIC в этом порядке, в итоге браузер может получить и обработать их в порядке A, C, B! Другими словами, в отличие от TCP, QUIC <b>не соблюдает строгий порядок потоков</b>.<br/>
<br/>
HTTP/2 ждал от TCP пакеты в определённом порядке для многих функций, которые используют специальные управляющие сообщения и фрагменты данных. В QUIC управляющие сообщения могут поступать и применяться в любом порядке, так что потенциально результат выполнения функций может быть противоположен ожидаемому. В технические дебри углубляться не будем, но по <a href="https://h2.edm.uhasselt.be/files/HTTP3_Prioritization_extended_3jul2019.pdf">первой половине этой статьи</a> видно, насколько это неразумно сложная схема.<br/>
<br/>
В итоге внутренняя механика и реализация функций должна была измениться в HTTP/3. Конкретный пример — <b>сжатие заголовков HTTP</b>, которое позволяет сэкономить на повторяющихся больших заголовках HTTP (например, cookie и строки user-agent). В HTTP/2 для этого использовался <a href="https://datatracker.ietf.org/doc/html/rfc7541">HPACK</a>, который для HTTP/3 переделали в более сложный <a href="https://datatracker.ietf.org/doc/html/draft-ietf-quic-qpack">QPACK</a>. Обе системы выполняют одну задачу (сжимают заголовки), но по-разному. Подробные технические описания и схемы читайте в <a href="https://blog.litespeedtech.com/tag/quic-header-compression-design-team/">блоге Litespeed</a>.<br/>
<br/>
Примерно то же самое можно сказать и о функции приоритизации, которая управляет логикой мультиплексирования потоков, <a href="https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/#head-of-line-blocking-removal">как мы недавно увидели</a>. В HTTP/2 она реализована с помощью сложного дерева зависимостей, которое пыталось описать все ресурсы страницы и их взаимосвязи (есть <a href="https://www.youtube.com/watch?v=nH4iRpFnf1c">интересное видео о приоритизации ресурсов в HTTP</a>). Если просто перенести эту систему на QUIC, дерево может получиться очень странное, потому что добавление в него каждого ресурса потребовало бы отдельного управляющего сообщения.<br/>
<br/>
Такой подход оказался слишком сложным, так что <a href="https://blog.cloudflare.com/nginx-structural-enhancements-for-http-2-performance/">в реализациях возникали баги и недостатки</a>, а <a href="https://github.com/andydavies/http2-prioritization-issues">производительность на многих серверах оставляла желать лучшего</a>. В итоге система приоритизации <a href="https://blog.cloudflare.com/adopting-a-new-approach-to-http-prioritization/">в HTTP/3 была переработана и упрощена</a>. С упрощённой структурой затруднительно или даже невозможно реализовать некоторые сложные сценарии (например, проксирование трафика с нескольких клиентов в одно соединение), но для оптимизации загрузки веб-страниц возможностей достаточно.<br/>
<br/>
Здесь тоже оба подхода решают одну задачу (мультиплексирование), но мы надеемся, что благодаря простоте настройки HTTP/3 в реализации будет меньше багов.<br/>
<br/>
Наконец, <b>server push</b>. позволяет серверу отправлять HTTP-ответы без явного запроса. В теории это должно серьезно повысить производительность. На практике оказалось, что <a href="https://calendar.perfplanet.com/2016/http2-push-the-details/">правильно использовать эту функцию сложно</a>, и <a href="https://jakearchibald.com/2017/h2-push-tougher-than-i-thought/">реализуется она несогласованно</a>. Скорее всего, <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/K3rYLvmQUBY/m/vOWBKZGoAQAJ">из Google Chrome эту функцию удалят</a>.<br/>
Пока она <i>всё ещё</i> числится <a href="https://datatracker.ietf.org/doc/html/draft-ietf-quic-http">как функция HTTP/3</a> (хотя ее поддерживают мало реализаций). Она изменилась не так сильно, как предыдущие две функции, но её адаптировали к недетерминированному порядку в QUIC. К сожалению, это мало поможет решить её давние проблемы.<br/>
<br/>
<h4>Что всё это значит?</h4><br/>
Мы уже говорили, что большинство потенциальных преимуществ HTTP/3 связаны с QUIC. Внутренняя реализация протокола <i>очень</i> отличается от HTTP/2, но высокоуровневые возможности производительности и варианты их применения не изменились.<br/>
<br/>
<h2>Чего нужно ждать в будущем </h2><br/>
В этой серии я не раз подчёркивал главные преимущества QUIC (а значит и HTTP/3) — быстрое развитие и хорошая гибкость. Это значит, что <b>новые расширения</b> протокола и варианты его применения уже разрабатываются. Вот за чем нужно следить особенно внимательно:<br/>
<br/>
<ul>
<li><a href="https://tools.ietf.org/html/draft-swett-nwcrg-coding-for-quic"><b>Forward error correction</b><br/>
</a>Цель этой техники — <b>повысить устойчивость QUIC к потере пакетов</b>. Суть заключается в отправке избыточных копий данных (они по-умному закодированы и сжаты, так что занимают не очень много места). Если пакет потерялся, но у нас есть его копия, снова передавать его не нужно.<br/>
<br/>
Изначально такая возможность была в Google QUIC (откуда и пошли разговоры об устойчивости к потере пакетов), но в стандартизированный QUIC version 1 она не входит, потому что её влияние на производительность пока не проверено. Эксперименты уже ведутся, и вы можете поучаствовать в них через приложение <a href="https://play.google.com/store/apps/details?id=org.pquic.pquic_fec_android">PQUIC-FEC Download Experiments</a>.<br/>
</li>
<li><a href="https://tools.ietf.org/html/draft-liu-multipath-quic"><b>Multipath QUIC</b><br/>
</a>Вы уже знаете о миграции соединения и о том, что она даёт, скажем, при переходе с Wi-Fi на сотовую сеть. А почему бы тогда не использовать Wi-Fi и сотовую сеть <b>одновременно</b>, чтобы увеличить полосу пропускания и повысить надёжность. Это главная концепция, на которой основан подход multipath.<br/>
<br/>
В Google экспериментировали с этим, но в QUIC version 1 эта возможность не входит из-за своей сложности. Исследователи видят здесь <a href="https://multipath-quic.org/">большой потенциал</a>, так что ждём QUIC version 2. Кстати, <a href="https://www.multipath-tcp.org/">TCP multipath</a> тоже существует, но ему понадобилось почти десять лет, чтобы стать применимым на практике.<br/>
</li>
<li><a href="https://tools.ietf.org/html/draft-ietf-quic-datagram"><b>Передача ненадёжных данных по QUIC</b></a> <b>и</b> <a href="https://datatracker.ietf.org/doc/html/draft-ietf-masque-h2-datagram"><b>HTTP/3</b><br/>
</a>QUIC очень надёжный протокол, но работает поверх ненадёжного UDP, так что QUIC можно приспособить и для передачи ненадёжных данных. Механизм описан в предложенном расширении для датаграмм. Он, конечно, не подходит для отправки ресурсов веб-страницы, но может пригодиться для игр или видеостриминга. Так пользователи получат все преимущества UDP, но с шифрованием и, по желанию, контролем перегрузок от QUIC.<br/>
</li>
<li><a href="https://web.dev/webtransport/"><b>WebTransport</b><br/>
</a>Браузеры не открывают TCP или UDP для JavaScript напрямую, в основном, из соображений безопасности. Приходится использовать API на уровне HTTP, например Fetch, и более гибкие протоколы <a href="https://hpbn.co/websocket/">WebSocket</a> и <a href="https://hpbn.co/webrtc/">WebRTC</a>. Самый новый вариант — WebTransport, с которым можно использовать HTTP/3 (а значит и QUIC) на более низком уровне (хотя его можно приспособить и для TCP и HTTP/2, если нужно).<br/>
<br/>
Самое главное, он позволит использовать ненадёжные данные по HTTP/3 (см. выше), чтобы упростить реализацию в браузере, например, для игр. Для обычных (JSON) вызовов API мы всё равно будем использовать Fetch, который автоматически будет применять HTTP/3 по возможности. Вокруг WebTransport пока много дискуссий, так что неясно, как он в итоге будет выглядеть. Из браузеров только Chromium пока работает над открытой <a href="https://groups.google.com/a/chromium.org/g/web-transport-dev/c/6PwPFy9fVfw">proof-on-concept реализацией</a>.<br/>
</li>
<li><b>DASH и HLS для стриминга</b><br/>
Для видео по запросу (например, YouTube или Netflix) браузеры обычно используют протоколы Dynamic Adaptive Streaming over HTTP (DASH) и HTTP Live Streaming (HLS). Оба подразумевают кодирование видео маленькими фрагментами (2–10 секунд) и разные уровни качества (720p, 1080p, 4K).<br/>
<br/>
При запуске браузер оценивает максимальное качество, которое потянет сеть (или оптимальный уровень для конкретного сценария), и запрашивает соответствующие файлы у сервера по HTTP. У браузера нет прямого доступа к стеку TCP (потому что он обычно реализуется в ядре), так что иногда он ошибается в своих оценках или медленно реагирует на изменение условий (и видео зависает).<br/>
<br/>
QUIC реализуется как часть браузера, поэтому его можно заметно улучшить, если <a href="https://dl.acm.org/doi/abs/10.1145/3386367.3431901">дать механизмам оценки доступ к информации на нижнем уровне протоколов</a> (процент потерь, полоса пропускания и т. д.). Другие исследователи тоже экспериментировали со <a href="https://www.researchgate.net/profile/Mirko-Palmer/publication/327930175_The_QUIC_Fix_for_Optimal_Video_Streaming/links/5f60ea97299bf1d43c063075/The-QUIC-Fix-for-Optimal-Video-Streaming.pdf">смешиванием надёжных и ненадёжных данных для видеостриминга</a> и получили неплохие результаты.<br/>
</li>
<li><b>Другие протоколы (кроме HTTP/3)</b><br/>
QUIC — это транспортный протокол общего назначения, и, скорее всего, многие протоколы на прикладном уровне, которые сейчас используют TCP, будут работать и на QUIC. Сейчас уже разрабатывают <a href="https://datatracker.ietf.org/doc/html/draft-ietf-dprive-dnsoquic">DNS-over-QUIC</a>, <a href="https://techcommunity.microsoft.com/t5/itops-talk-blog/smb-over-quic-files-without-the-vpn/ba-p/1183449">SMB-over-QUIC</a> и даже <a href="https://datatracker.ietf.org/doc/html/draft-bider-ssh-quic-09">SSH-over-QUIC</a>. У этих протоколов другие требования, не связанные с HTTP и загрузкой веб-страниц, так что в них улучшения производительности QUIC могут проявляться заметнее.<br/>
</li>
</ul><br/>
<br/>
<h4>Что всё это значит?</h4><br/>
QUIC version 1 — это <b>всего лишь начало</b>. Многие улучшения производительности, над которыми экспериментировал Google, не вошли в первую версию. Но протокол очень быстро развивается, появляются всё новые расширения и функции. Со временем QUIC (и HTTP/3 вместе с ним) станут заметно более быстрыми и гибкими по сравнению с TCP (и HTTP/2).<br/>
<br/>
<h2>Заключение </h2><br/>
Во второй части серии мы рассмотрели разные <b>функции и аспекты производительности HTTP/3</b> и особенно QUIC. Мы увидели, что большинство этих функций кажутся интересными, но на практике не приносят ожидаемой пользы среднему пользователю при загрузке веб-страниц.<br/>
Например, хоть QUIC и использует UDP, это не значит, что ему доступна более широкая полоса пропускания, чем TCP, или что он будет загружать ресурсы быстрее. Хвалёный 0-RTT позволяет сэкономить всего один круговой путь, и то мы успеем передать примерно пять килобайт (в худшем сценарии).<br/>
<br/>
Удаление блокировки HoL не спасает, <b>если мы теряем много пакетов сразу</b> или загружаем ресурсы с блокировкой рендеринга. Миграция соединения зависит от ситуации, и HTTP/3 здесь особо не обгоняет HTTP/2.<br/>
<br/>
Всё это звучит так, будто игра не стоит свеч. И что теперь? Забыть об HTTP/3 и QUIC? Ни в коем случае! Новые протоколы вряд ли впечатлят пользователей в быстрых (городских) сетях, но определённо принесут пользу <b>мобильным пользователям</b> и тем, кто вынужден использовать медленные сети.<br/>
<br/>
Даже, например, в Европе, где мы используем быстрые устройства и высокоскоростные сотовые сети, улучшения заметят от 1 до 10% пользователей в зависимости от продукта. Например, пассажиру поезда срочно нужно найти важную информацию на вашем сайте, но приходится ждать 45 секунд, пока всё загрузится. Я не раз бывал в таких ситуациях, и QUIC пришёлся бы очень кстати.<br/>
<br/>
А ведь есть страны и регионы, где условия гораздо хуже. Там среднему пользователю приходится хуже, чем 10% самых медленных пользователей в европейской стране, а для одного худшего процента страница вообще может так и не загрузиться. Во <a href="https://infrequently.org/2021/03/the-performance-inequality-gap/">многих частях мира</a> веб-производительность — <a href="https://hookedoncode.com/2020/07/performance-is-accessibility/">это вопрос доступности и инклюзивности</a>.<br/>
<br/>
Поэтому тестировать страницы нужно не только на нашем хорошем оборудовании (а ещё и использовать сервисы вроде <a href="https://www.webpagetest.org/">Webpagetest</a>), и поэтому же <b>обязательно нужно развернуть QUIC и HTTP/3</b>. Если ваши пользователи часто находятся в дороге или не имеют доступа к быстрым сотовым сетям, новые протоколы принесут огромную пользу, даже если на своём MacBook Pro с кабельным интернетом вы ничего особенного не заметите. Обязательно почитайте <a href="https://www.fastly.com/blog/how-http3-and-quic-help-long-tail-connections">пост Fastly на эту тему</a>.<br/>
<br/>
Если и это вас не убедит, просто знайте, что QUIC и HTTP/3 <b>будут активно развиваться и ускоряться</b> в следующие несколько лет. Опыт с протоколом на ранних этапах обязательно окупится в будущем, где вы сможете использовать преимущества новых функций сразу после их появления. Наконец, QUIC использует лучшие методы безопасности и конфиденциальности, которые будут полезны абсолютно всем пользователям.</div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bhttp%2F2%5D" class="tm-tags-list__link">http/2</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bhttp2%5D" class="tm-tags-list__link">http2</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bhttp%2F3%5D" class="tm-tags-list__link">http/3</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bhttp3%5D" class="tm-tags-list__link">http3</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bquic%5D" class="tm-tags-list__link">quic</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B0-rtt%5D" class="tm-tags-list__link">0-rtt</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btcp%5D" class="tm-tags-list__link">tcp</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btls%5D" class="tm-tags-list__link">tls</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btls%201.2%5D" class="tm-tags-list__link">tls 1.2</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Btls%201.3%5D" class="tm-tags-list__link">tls 1.3</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Budp%5D" class="tm-tags-list__link">udp</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BF%D1%80%D0%BE%D1%82%D0%BE%D0%BA%D0%BE%D0%BB%D1%8B%20%D0%BF%D0%B5%D1%80%D0%B5%D0%B4%D0%B0%D1%87%D0%B8%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%5D" class="tm-tags-list__link">протоколы передачи данных</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/company/southbridge/blog/" class="tm-hubs-list__link router-link-active">
    Блог компании Southbridge
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/hi/" class="tm-hubs-list__link">
    Высокая производительность
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/webdev/" class="tm-hubs-list__link">
    Разработка веб-сайтов
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/s_admin/" class="tm-hubs-list__link">
    Серверное администрирование
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/devops/" class="tm-hubs-list__link">
    DevOps
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 21: ↑20 и ↓1</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 21: ↑20 и ↓1" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+19</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">5.3K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    61
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a href="/ru/company/southbridge/profile/" class="tm-company-snippet__logo-link"><div class="tm-entity-image"><img alt="" height="40" src="//habrastorage.org/getpro/habr/company/754/d93/3ca/754d933caeb494c6127add17ff60feb5.png" width="40" class="tm-entity-image__pic"></div></a> <div class="tm-company-snippet__info"><a href="/ru/company/southbridge/profile/" class="tm-company-snippet__title">Southbridge</a> <div class="tm-company-snippet__description">Обеспечиваем стабильную работу highload-проектов</div></div></div> <div class="tm-article-author__buttons"><!----> <!----></div></div> <div class="tm-article-author__company-contacts"><a href="https://southbridge.io/" rel="noopener" target="_blank" class="tm-article-author__contact">
      Сайт
    </a></div> <div class="tm-article-author__separator"></div></div> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/Polina_Averina/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/eab/364/193/eab36419344dc0ed056f430c3212263f.png" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 97 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    45
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">7.6</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/Polina_Averina/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @Polina_Averina
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Редактор в Southbridge</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/company/southbridge/blog/583434/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 3 
    </span></a> <!----></div></div></div>  <!---->  <!----> <!----></div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <section class="tm-block tm-block_spacing-bottom"><header class="tm-block__header"><h2 class="tm-block__title">Информация</h2> <!----></header> <div class="tm-block__body"><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата основания</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2008-02-21T21:00:00.000Z" title="2008-02-22, 00:00">22  февраля  2008</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Местоположение</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    Россия
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Сайт</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="https://southbridge.io" target="_blank" class="tm-company-basic-info__link">
      southbridge.io
    </a></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Численность</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap">
    51–100 человек
  </dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Дата регистрации</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><time datetime="2012-11-15T08:41:16.000Z" title="2012-11-15, 12:41">15  ноября  2012</time></dd></dl> <dl class="tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap">Представитель</dt> <dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap"><a href="/ru/users/aSkobin/" class="tm-company-basic-info__link">
      Антон Скобин
    </a></dd></dl></div></div> <!----></section> <div class="tm-company-widgets"></div> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/company/southbridge/blog/583434/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/company/southbridge/blog/583434/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"583434":{"id":"583434","timePublished":"2021-10-19T15:14:35+00:00","isCorporative":true,"lang":"ru","titleHtml":"HTTP\u002F3: улучшения производительности. Часть 2","leadData":{"textHtml":"\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fmp\u002Fmn\u002Fhr\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg\"\u003E\u003Cbr\u003E\r\n\u003Ci\u003EФото Jack Hunter, Unsplash.com\u003C\u002Fi\u003E\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nПосле почти пятилетней разработки протокол HTTP\u002F3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP\u002F3 улучшилась производительность, включая контроль перегрузок, блокировки HoL и установку соединения 0-RTT.\u003Cbr\u003E\r\n\u003Cbr\u003E\r\nЭто вторая часть серии о новом протоколе HTTP\u002F3. В первой мы говорили о том, \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eзачем нам вообще нужен HTTP\u002F3\u003C\u002Fa\u003E, о протоколе QUIC и новых возможностях.\u003Cbr\u003E","imageUrl":null,"buttonTextHtml":"Читать дальше &rarr;","image":null},"editorVersion":"1.0","postType":"article","postLabels":[{"type":"translation","data":{"originalAuthorName":"Robin Marx","originalUrl":"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F"}}],"author":{"scoreStats":{"score":45,"votesCount":97},"rating":7.6,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"2388777","alias":"Polina_Averina","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002Feab\u002F364\u002F193\u002Feab36419344dc0ed056f430c3212263f.png","speciality":"Редактор в Southbridge"},"statistics":{"commentsCount":3,"favoritesCount":61,"readingCount":5255,"score":19,"votesCount":21},"hubs":[{"relatedData":null,"id":"17901","alias":"southbridge","type":"corporative","title":"Блог компании Southbridge","titleHtml":"Блог компании Southbridge","isProfiled":false},{"relatedData":null,"id":"4","alias":"hi","type":"collective","title":"Высокая производительность","titleHtml":"Высокая производительность","isProfiled":true},{"relatedData":null,"id":"91","alias":"webdev","type":"collective","title":"Разработка веб-сайтов","titleHtml":"Разработка веб-сайтов","isProfiled":true},{"relatedData":null,"id":"17350","alias":"s_admin","type":"collective","title":"Серверное администрирование","titleHtml":"Серверное администрирование","isProfiled":true},{"relatedData":null,"id":"20788","alias":"devops","type":"collective","title":"DevOps","titleHtml":"DevOps","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"6","alias":"admin","title":"Администрирование"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fwebt\u002Fmp\u002Fmn\u002Fhr\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fmp\u002Fmn\u002Fhr\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg\" data-blurred=\"true\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Ci\u003EФото Jack Hunter, Unsplash.com\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПосле почти пятилетней разработки протокол HTTP\u002F3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP\u002F3 улучшилась производительность, включая контроль перегрузок, блокировки HoL и установку соединения 0-RTT.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто вторая часть серии о новом протоколе HTTP\u002F3. В первой мы говорили о том, \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eзачем нам вообще нужен HTTP\u002F3\u003C\u002Fa\u003E, о протоколе QUIC и новых возможностях.\u003Cbr\u002F\u003E\r\n\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\nВо второй части вы увидите, как QUIC и HTTP\u002F3 \u003Cb\u003Eповышают производительность\u003C\u002Fb\u003E при загрузке веб-страниц. Спойлер: не ждите слишком многого.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУ QUIC и HTTP\u002F3 отличный потенциал, но порадуют они, в основном, \u003Cb\u003Eпользователей в медленных сетях\u003C\u002Fb\u003E. Если сеть и так быстрая, скорее всего, вы почти ничего не заметите. Но даже в странах и регионах с быстрой связью, 1% или даже 10% пользователей с самым медленным соединением (\u003Ci\u003E99-й\u003C\u002Fi\u003E и \u003Ci\u003E90-й перцентили\u003C\u002Fi\u003E) могут приятно удивиться. Дело в том, что HTTP\u002F3 и QUIC решают проблемы, которые встречаются не так часто, но могут сильно затруднять работу.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ этой части будет \u003Cb\u003Eбольше технических деталей\u003C\u002Fb\u003E, чем в первой, но в самые глубины мы лезть не будем — просто приведём список дополнительных ресурсов о том, что новый протокол даст среднестатистическому веб-разработчику.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003E\u003Cb\u003EЧасть 1: История и ключевые концепции HTTP\u002F3\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EЭта часть для тех, кто в целом мало что знает об HTTP\u002F3 и протоколах. Здесь мы говорим о самых основах.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Cb\u003EЧасть 2: Характеристики производительности HTTP\u002F3\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\nТут мы углубимся в технические детали. Если с основами вы уже знакомы, начинайте со второй части.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F09\u002Fhttp3-practical-deployment-options-part3\u002F\"\u003E\u003Cb\u003EЧасть 3: развертывание HTTP\u002F3 на практике\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EЗдесь описываются трудности, связанные с самостоятельным развёртыванием и тестированием HTTP\u002F3. Мы поговорим, как нужно изменить веб-страницы и ресурсы и нужно ли вообще \u003Ci\u003E(примечание переводчика: перевод третьей части тоже появится в нашем блоге в ближайшее время)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EСкорость \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nГоворить о производительности и скорости сложно, потому что веб-страницы загружаются медленно по многим причинам. Раз речь о сетевых протоколах, мы рассмотрим сетевые аспекты. И самые важные из них — задержка и полоса пропускания.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗадержкой мы будем считать \u003Cb\u003Eвремя, которое требуется для доставки пакета из точки А (допустим, клиента) в точку Б (сервер)\u003C\u002Fb\u003E. В теории мы ограничены скоростью света, а на практике — скоростью прохождения сигналов по проводным или беспроводным сетям. В итоге задержка часто зависит от физического расстояния между точками А и Б.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=6bbN48zCNl8\"\u003EНа планете Земля\u003C\u002Fa\u003E это значит, что задержки небольшие, от 10 до 200 мс. Но это только в одну сторону — ведь нужно ещё дождаться ответа. Задержка при передаче туда и обратно называется \u003Cb\u003Eвременем кругового пути (round-trip time, RTT)\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИз-за таких функций, как \u003Ci\u003Eконтроль перегрузок\u003C\u002Fi\u003E (см. ниже), круговых путей даже для загрузки одного-единственного файла будет немало, как правило. Поэтому даже если задержка меньше 50 мс, в сумме может получиться гораздо больше. И это одна из главных причин, по которым мы используем сети доставки контента (CDN): в них серверы находятся физически ближе к конечным пользователям, чтобы максимально сократить задержку.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПолоса пропускания — \u003Cb\u003Eэто число пакетов, которые можно отправить одновременно\u003C\u002Fb\u003E. Эту концепцию сложнее объяснить, потому что она зависит от физических свойств среды (например, частоты радиоволн), числа пользователей в сети и устройств, которые соединяют разные подсети (потому что они обычно могут обрабатывать ограниченное количество пакетов в секунду).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПредставьте себе трубу, по которой течёт вода. Длина трубы определяет задержку, а диаметр — полосу пропускания. Интернет можно сравнить с \u003Cb\u003Eцелой системой разных труб\u003C\u002Fb\u003E, и в трубах с маленьким диаметром возникают узкие места. Поэтому полоса пропускания между точками А и Б обычно ограничена самым медленным отрезком.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВсе тонкости мы рассматривать не будем, для понимания этой статьи достаточно общего представления. Если хотите узнать больше, читайте \u003Ca href=\"https:\u002F\u002Fhpbn.co\u002Fprimer-on-latency-and-bandwidth\u002F\"\u003Eпревосходную главу о задержках и полосе пропускания\u003C\u002Fa\u003E в книге Ильи Григорика (Ilya Grigorik) \u003Ci\u003EHigh Performance Browser Networking\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EКонтроль перегрузок \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nОдин из аспектов производительности — насколько \u003Cb\u003Eэффективно\u003C\u002Fb\u003E транспортный протокол может использовать полную (физическую) пропускную способность, т. е. сколько пакетов можно отправлять и получать в секунду. От этого зависит, как быстро загружаются ресурсы страницы. Некоторые считают, что в этом QUIC гораздо лучше TCP, но это не так.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nTCP-соединение, например, не начинает сразу отправлять данные на полную полосу пропускания, чтобы избежать перегрузки сети. Мы уже говорили, что каждый сетевой канал физически может обработать только определённый объём данных в секунду. Отправьте больше — и лишнее придётся отбросить, что приведет к \u003Cb\u003Eпотере пакетов\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы уже говорили, что TCP может исправить потерю пакетов только одним способом — заново отправить данные. Для этого требуется ещё один проход туда-обратно. В сетях с большой задержкой (больше 50 мс RTT) потеря пакетов может серьезно снижать производительность.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕщё одна проблема — мы не знаем заранее, какой будет максимальная \u003Cb\u003Eполоса пропускания\u003C\u002Fb\u003E. Где-то по пути может возникнуть узкое место, но где это будет — угадать невозможно. В интернете пока нет механизмов, с помощью которых можно сообщать конечным точкам о ёмкости каналов.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИ даже если бы мы знали о доступной физической полосе пропускания, это не означало бы, что вся она достанется нам. Обычно её делят между собой сразу много пользователей.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСоединение не знает, какую полосу пропускания получит, к тому же это значение меняется вместе с величиной активного потребления полосы у провайдеров. Чтобы решить эту проблему, TCP постоянно пытается выяснить доступную полосу пропускания с помощью механизма контроля перегрузки — \u003Cb\u003Econgestion control\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ начале соединения протокол отправляет несколько пакетов (от 10 до 100, или от 1\u003Cb\u003E4 до 140 КБ\u003C\u002Fb\u003E данных) и ждёт ответа о получении этих пакетов. Если получение подтверждено, значит сеть справляется с такой скоростью и можно попробовать отправить больше данных (обычно объём увеличивается вдвое при каждой итерации).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСкорость отправки растёт до тех пор, пока какие-то пакеты не останутся без подтверждения. Это значит, что сеть перегружена, и они потерялись. Такой алгоритм называется медленным стартом. Заметив пропажу, TCP уменьшает скорость, а через какое-то время пытается увеличить её снова, но с меньшим шагом приращения. Затем эта логика повторяется каждый раз при потере пакетов. По сути, это означает, что TCP всегда пытается получить свою максимально доступную долю полосы пропускания. Этот механизм показан на рисунке 1.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fho\u002Fim\u002F7p\u002Fhoim7p8gofdx8u8jbjmhyzwhj1q.png\"\u002F\u003E\u003Ci\u003EРис. 1. Упрощённая схема контроля перегрузок: TCP начинает с 10 пакетов (адаптация с сайта \u003Ca href=\"https:\u002F\u002Fhpbn.co\u002Fbuilding-blocks-of-tcp\u002F#congestion-avoidance-and-control\"\u003Ehpbn.co\u003C\u002Fa\u003E) (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F9d5e5ddd-7a90-48c6-84c5-dc5c335e2305\u002Fcongestion-control.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто \u003Ci\u003Eочень\u003C\u002Fi\u003E упрощённое объяснение контроля перегрузок. На практике здесь участвует много факторов, например, \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=ZeCIbCzGY6k\"\u003Ebufferbloat (излишняя буферизация)\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fblog.apnic.net\u002F2017\u002F05\u002F09\u002Fbbr-new-kid-tcp-block\u002F\"\u003Eколебания RTT из-за перегрузки\u003C\u002Fa\u003E и тот факт, что \u003Ca href=\"https:\u002F\u002Fjustinesherry.com\u002Fpapers\u002Fware-hotnets19.pdf\"\u003Eполучить свою долю полосы пропускания\u003C\u002Fa\u003E стараются сразу несколько желающих. Существуют и продолжают появляться разные алгоритмы контроля перегрузок, но ни один из них не универсален.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМеханизм контроля перегрузок TCP повышает надежность, но \u003Cb\u003Eоптимальная скорость отправки\u003C\u002Fb\u003E достигается не сразу, в зависимости от RTT и фактически доступной полосы пропускания. При загрузке веб-страниц медленный старт влияет на метрики, например, время до первой полезной отрисовки контента (First Contentful Paint), потому что в первых нескольких проходах туда и обратно передаётся очень маленький объём данных (пара десятков или сотен килобайт). (Слышали, наверное, о рекомендации \u003Ca href=\"https:\u002F\u002Fwww.tunetheweb.com\u002Fblog\u002Fcritical-resources-and-the-first-14kb\u002F\"\u003Eукладывать критически важные данные в 14 КБ\u003C\u002Fa\u003E.)\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли действовать агрессивнее, можно улучшить результаты в сетях с большой полосой пропускания и задержкой, особенно если потеря пакетов для вас не проблема. На эту тему бытует много \u003Cb\u003Eзаблуждений\u003C\u002Fb\u003E о принципах работы QUIC.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили, что в теории QUIC меньше страдает от потери пакетов (и связанной блокировки HoL), потому что обрабатывает каждый поток байтов независимо. Кроме того, QUIC использует \u003Ci\u003Eпротокол UDP\u003C\u002Fi\u003E, у которого, в отличие от TCP, нет встроенной функции контроля перегрузок. С ним можно попытаться отправить данные на любой скорости, но потерянные данные он не будет передавать заново.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ итоге появилось много статей, где говорится, что QUIC не контролирует перегрузки, а просто сразу отправляет данные на высокой скорости по UDP, решая проблему потери пакетов благодаря отсутствию блокировки HoL. Потому, мол, QUIC гораздо быстрее TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ реальности \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9002.html\"\u003Eэто максимально далеко от истины\u003C\u002Fa\u003E: \u003Cb\u003Eметоды управления полосой пропускания у QUIC очень похожи на то, что делает TCP\u003C\u002Fb\u003E. QUIC тоже начинает с невысокой скорости и увеличивает её со временем, используя подтверждения, чтобы измерять пропускную способность сети. Отчасти это связано с тем, что QUIC должен обеспечивать надёжность, чтобы его можно было использовать с HTTP, потому что кроме него есть и другие QUIC (и TCP!) соединения и потому что удаление блокировки HoL не гарантирует полную защиту от потери пакетов (как мы увидим чуть позже).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто не значит, что QUIC не может управлять полосой пропускания чуточку умнее, чем TCP. В основном, потому что \u003Cb\u003EQUIC дает больше гибкости и его проще развивать\u003C\u002Fb\u003E. Мы уже сказали, что алгоритмы контроля перегрузок по-прежнему активно развиваются, например, чтобы \u003Ca href=\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3387514.3405882\"\u003Eмаксимально эффективно использовать технологию 5G\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nTCP обычно реализуется в ядре ОС, самой защищённой и самой ограниченной среде, к тому же проприетарной в большинстве ОС. Поэтому логика контроля перегрузок в ОС обычно реализуется ограниченным кругом разработчиков, что замедляет развитие технологии.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nБольшинство реализаций QUIC, наоборот, находятся в пользовательском пространстве, где мы обычно запускаем нативные приложения, и имеют \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fquicwg\u002Fbase-drafts\u002Fwiki\u002FImplementations\"\u003Eоткрытый исходный код\u003C\u002Fa\u003E — как раз для того, чтобы как можно больше разработчиков экспериментировали с ним (и \u003Ca href=\"https:\u002F\u002Fresearch.fb.com\u002Fwp-content\u002Fuploads\u002F2019\u002F12\u002FMVFST-RL-An-Asynchronous-RL-Framework-for-Congestion-Control-with-Delayed-Actions.pdf\"\u003EFacebook\u003C\u002Fa\u003E уже подает пример).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕщё один пример — расширение для \u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Fdraft-iyengar-quic-delayed-ack-02\"\u003E\u003Ci\u003Eотложенной отправки подтверждений\u003C\u002Fi\u003E\u003C\u002Fa\u003E, предложенное для QUIC. По умолчанию QUIC отправляет подтверждения для каждых двух полученных пакетов. С помощью расширения можно настроить подтверждение, допустим, для каждых десяти пакетов. Такой подход показал \u003Cb\u003Eзначительное увеличение скорости\u003C\u002Fb\u003E в спутниковых сетях и сетях с большой полосой пропускания, потому что издержки на передачу подтверждений снизились. Внедрять такое расширение для TCP было бы очень долго, а с QUIC все гораздо проще.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМы ожидаем, что благодаря гибкости QUIC будет больше экспериментов, и алгоритмы контроля перегрузок со временем улучшатся. Эти наработки потом можно будет перенести на TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ официальном \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9002.html\"\u003EQUIC Recovery RFC 9002\u003C\u002Fa\u003E описано использование алгоритма контроля перегрузок NewReno. Это надежный, но немного \u003Cb\u003Eустаревший\u003C\u002Fb\u003E подход, который уже не очень широко используется на практике. Тогда почему он включен в QUIC RFC? Во-первых, потому, что в начале разработки QUIC алгоритм NewReno был самым современным из стандартизированных. Более продвинутые алгоритмы, вроде BBR и CUBIC, до сих пор не стандартизированы или \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Frfc8312\"\u003Eтолько недавно\u003C\u002Fa\u003E стали RFC.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВо-вторых, NewReno относительно просто настраивать. Поскольку любой алгоритм нужно адаптировать, чтобы учесть отличия QUIC от TCP, с простым алгоритмом будет приятнее иметь дело. Поэтому RFC 9002 можно считать скорее рекомендацией по тому, как настроить контроль перегрузок для QUIC, чем требованием использовать с QUIC именно этот алгоритм. По факту большинство реализаций QUIC на уровне продакшена используют кастомные варианты \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fcubic-and-hystart-support-in-quiche\u002F\"\u003ECubic\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fqlog.edm.uhasselt.be\u002Fepiq\u002Ffiles\u002FQUICImplementationDiversity_Marx_final_11jun2020.pdf\"\u003EBBR\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПовторю: алгоритмы контроля перегрузок \u003Cb\u003Eне привязаны к TCP или QUIC\u003C\u002Fb\u003E. Их можно использовать для обоих протоколов, и мы надеемся, что усовершенствования в QUIC доберутся и до TCP.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nС концепцией контроля перегрузок связан механизм \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#name-flow-control\"\u003Eконтроля потоков\u003C\u002Fa\u003E (flow-control). Их часто путают в TCP, потому что они оба используют \u003Cb\u003ETCP window\u003C\u002Fb\u003E (окно TCP), хотя окон по сути два: congestion window и receive window. Flow control, впрочем, не так важен для загрузки веб-страниц, поэтому здесь мы не будем о нём говорить. Если интересно, см. \u003Ca href=\"https:\u002F\u002Fqlog.edm.uhasselt.be\u002Fepiq\u002Ffiles\u002FQUICImplementationDiversity_Marx_final_11jun2020.pdf\"\u003Eисследование\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fyoutu.be\u002FHQ1uIClmzkU?t=603\"\u003Eвидео\u003C\u002Fa\u003E или \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fdelivering-http-2-upload-speed-improvements\u002F\"\u003Eстатью\u003C\u002Fa\u003E.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит? \u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nQUIC по-прежнему подчиняется законам физики и должен проявлять уважение к остальным отправителям в сети. Он \u003Cb\u003Eне сможет\u003C\u002Fb\u003E волшебным образом загружать ресурсы на сайте гораздо быстрее, чем TCP. Но QUIC очень гибкий, а значит экспериментировать с алгоритмами контроля перегрузок будет проще. TCP от этого в итоге тоже выиграет.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EУстановка соединения 0-RTT \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nВторой аспект производительности — \u003Cb\u003Eсколько раз нужно совершить круговой путь\u003C\u002Fb\u003E, прежде чем можно будет отправить полезные данные HTTP (ресурсы страницы, например) в новом соединении. Кто-то говорит, что QUIC на два-три цикла быстрее, чем TCP + TLS, но на самом деле мы экономим всего один цикл.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-core-concepts-part1\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы уже говорили, что обычно соединению требуется одно (TCP) или два (TCP + TLS) рукопожатия, прежде чем можно будет обмениваться HTTP-запросами и ответами. При этих рукопожатиях клиент и сервер обмениваются начальными параметрами, которые нужны им, например, для шифрования данных.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКак видно на рисунке 2, каждому \u003Ci\u003Eотдельному\u003C\u002Fi\u003E рукопожатию нужен как минимум один круговой путь (TCP + TLS 1.3, (b)), а иногда и все два (TLS 1.2 и ниже (a)). Это неэффективно, потому что нам приходится ждать как минимум \u003Cb\u003Eдва прохода туда и обратно\u003C\u002Fb\u003E, прежде чем можно будет отправить первый HTTP-запрос, то есть первые данные ответа HTTP (красная стрелка обратно) поступят минимум через три круга. В медленных сетях это может приводить к дополнительной задержке в 100–200 мс.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fmi\u002F9h\u002Fri\u002Fmi9hriqqmce05xmeaalq81xdmys.png\"\u002F\u003E\u003Cbr\u002F\u003E\r\n\u003Ci\u003EРис. 2: Установка соединения TCP + TLS и QUIC (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F9f4c69d1-5ab6-4ca2-ad1e-ec68d99dc9ab\u002Fconnection-setup-1.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСтранно же, что нельзя объединить рукопожатия TCP + TLS в одном проходе? Теоретически это возможно, и QUIC так и делает, но изначально было задумано, что \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003ETCP можно использовать как с TLS, так и без него\u003C\u002Fa\u003E. Другими словами, TCP просто \u003Cb\u003Eне поддерживает отправку того, что к нему не относится\u003C\u002Fb\u003E, во время рукопожатия. Были попытки добавить эту возможность в расширение TCP Fast Open, но, как мы уже сказали в \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E, оказалось, что в \u003Ca href=\"https:\u002F\u002Fsqueeze.isobar.com\u002F2019\u002F04\u002F11\u002Fthe-sad-story-of-tcp-fast-open\"\u003Eбольшом масштабе всё это трудно развернуть\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nQUIC с самого начался создавался под TLS, поэтому объединяет транспортные и криптографические рукопожатия. Получается, что QUIC нужно совершить один круговой путь, а это ровно на один меньше, чем TCP + TLS 1.3 (см. рис. 2c).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВы наверняка слышали, что QUIC быстрее на два или даже три круга, но в большинстве статей рассматривают худший сценарий (TCP + TLS 1.2 (2a)) и почему-то забывают, что TCP + TLS 1.3 укладывается в два прохода (2b). Сэкономить один проход, конечно, приятно, но вряд ли вызывает восторг. Если сеть быстрая (допустим, с RTT &lt; 50 мс), \u003Cb\u003Eэтого никто и не заметит\u003C\u002Fb\u003E, хотя для медленных соединений с отдалённым сервером преимущества будут.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nА почему мы вообще должны ждать, пока рукопожатия закончатся? Давайте сразу отправим HTTP-запрос да и всё. Но в этом случае первый запрос будет \u003Cb\u003Eне зашифрован\u003C\u002Fb\u003E. Кто угодно сможет перехватить его в нарушение всех требований безопасности и конфиденциальности. Поэтому и приходится ждать, прежде чем отправить первый HTTP-запрос. Или всё-таки это необязательно?\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТут есть одна хитрость. Мы знаем, что пользователи часто возвращаются на веб-страницы вскоре после первого посещения, а значит можно использовать \u003Cb\u003Eизначальное зашифрованное соединение\u003C\u002Fb\u003E, чтобы запустить следующее соединение в будущем. Проще говоря, во время первого соединения клиент и сервер безопасно обмениваются новыми криптографическими параметрами. С помощью этих параметров можно с самого начала \u003Cb\u003Eзашифровать второе соединение\u003C\u002Fb\u003E, не дожидаясь завершения рукопожатия TLS. Такой подход называется \u003Ci\u003Eвозобновлением сеанса\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nС его помощью можно серьёзно оптимизировать процесс: можно отправить первый HTTP-запрос вместе с рукопожатием QUIC\u002FTLS, \u003Cb\u003Eсэкономив еще один проход туда-обратно\u003C\u002Fb\u003E! Если использовать TLS 1.3, то ждать рукопожатия TLS вообще не придётся. Такой метод часто называется 0-RTT (хотя, по сути, HTTP-ответ всё-таки приходит после одного кругового пути).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМногие ошибочно считают, что возобновление сеанса и 0-RTT относятся исключительно к QUIC. На самом деле это \u003Ci\u003Eфункции TLS\u003C\u002Fi\u003E, которые уже в каком-то виде присутствуют в TLS 1.2, а теперь полноценно реализованы в \u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Frfc8446#section-2.3\"\u003ETLS 1.3\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли посмотреть на рисунок 3, будет очевидно, что производительность можно увеличить и для TCP (а значит и для HTTP\u002F2 и даже HTTP\u002F1.1)! Как видите, даже с 0-RTT протокол QUIC по-прежнему \u003Cb\u003Eвсего на один круговой путь\u003C\u002Fb\u003E опережает стек TCP + TLS 1.3. Разговоры про три круга основаны на сравнении рисунка 2a с рисунком 3f, что, как мы видели, не совсем справедливо.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fxr\u002Fks\u002Fxm\u002Fxrksxm0jdltcfcw7vj-erczaxp0.png\"\u002F\u003E\u003Ci\u003EРис. 3: Установка соединения TCP + TLS и QUIC 0-RTT (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002Fddbd604f-cec4-4e61-9172-707eda88bc99\u002Fconnection-setup-2.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПроблема в том, что при использовании 0-RTT, QUIC не может полноценно реализовать эту экономию из соображений безопасности. Чтобы понять это, нужно разобраться, зачем рукопожатие TCP вообще существует. Во-первых, оно позволяет клиенту убедиться, что сервер доступен по указанному IP-адресу, прежде чем отправлять на него данные.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВо-вторых, и это самое главное, сервер должен проверить, что клиент действительно то, за что себя выдает, прежде чем посылать ему данные в ответ. Если помните, в \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили о четырёх параметрах соединения. Так вот, клиент, в основном, идентифицируется по своему IP-адресу. В этом и проблема: \u003Cb\u003EIP-адреса можно подделывать!\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДопустим, злоумышленник запрашивает очень большой файл по HTTP через QUIC 0-RTT. При этом он подменяет IP-адрес, чтобы всё выглядело так, будто запрос 0-RTT поступил с компьютера жертвы. См. рисунок 4 ниже. Сервер QUIC никак не может определить подлинность IP-адреса, потому что это первый пакет от клиента.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fv7\u002Fv1\u002Fwx\u002Fv7v1wxee63v3t7cphkrstht0ai0.png\"\u002F\u003E\u003Ci\u003EРис. 4: Злоумышленники могут подменять IP-адрес при отправке запроса 0-RTT на сервер QUIC, запуская атаку с усилением (amplification) (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F64b9318e-3f18-4852-b911-409033d8645b\u002Famplification.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли сервер просто начнёт отправлять большой файл на этот IP, это приведёт \u003Cb\u003Eк перегрузке полосы пропускания в сети жертвы\u003C\u002Fb\u003E (особенно если параллельно отправлено много фейковых запросов). Компьютер жертвы отклонит этот ответ, потому что не запрашивал его, но это уже не важно. Сеть всё равно должна будет обработать эти пакеты!\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакже это называется \u003Ca href=\"https:\u002F\u002Fwww.f5.com\u002Flabs\u002Farticles\u002Feducation\u002Fwhat-is-a-dns-amplification-attack-\"\u003Ereflection attack (amplification attack\u003C\u002Fa\u003E), и это один из самых распространённых методов DDoS-атак. Такого не случится, если использовать 0-RTT с TCP + TLS, как раз благодаря рукопожатию TCP, которое происходит ещё до первого запроса 0-RTT + TLS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПоэтому QUIC \u003Cb\u003Eдолжен использовать консервативный подход\u003C\u002Fb\u003E, отвечая на запросы 0-RTT, и ограничить объём отправляемых данных, пока сервер не убедится, что это настоящий клиент, а не жертва. Для QUIC установлен лимит: \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#name-address-validation\"\u003Eв три раза больше данных, чем получено от клиента\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДругими словами, коэффициент усиления у QUIC равен трём. Это компромисс между производительностью и безопасностью (случались инциденты, где \u003Ca href=\"https:\u002F\u002Fwww.cloudflare.com\u002Flearning\u002Fddos\u002Fmemcached-ddos-attack\u002F\"\u003Eкоэффициент усиления был больше 51 000\u003C\u002Fa\u003E). Обычно клиент сначала отправляет один или два пакета, так что ответ 0-RTT от сервера QUIC \u003Cb\u003Eне превысит 4–6 КБ\u003C\u002Fb\u003E (включая остальные издержки QUIC и TLS). Не впечатляет?\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДругие проблемы безопасности могут привести, например, к атакам повторного воспроизведения (replay attack), что ограничивает доступные типы HTTP-запросов. Например, Cloudflare разрешает \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fintroducing-0-rtt\u002F#whatsthecatch\"\u003Eтолько запросы HTTP GET без параметров запроса\u003C\u002Fa\u003E в 0-RTT. Очевидно, что это ещё больше снижает потенциальную пользу 0-RTT.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nК счастью, у QUIC есть возможность немного улучшить ситуацию. Например, сервер может проверить, поступает ли запрос 0-RTT с \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#name-address-validation-for-futu\"\u003EIP-адреса, с которым у него уже было соединение\u003C\u002Fa\u003E. Но это работает, только если клиент остаётся в той же сети (частично это ограничивает возможность \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#connection-migration\"\u003Eмиграции соединения\u003C\u002Fa\u003E в QUIC). Даже если всё получится, ответ QUIC будет ограничен из-за логики медленного старта для контроля перегрузок, которую мы обсуждали \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#congestion-control\"\u003Eвыше\u003C\u002Fa\u003E. Как видите, \u003Cb\u003Eникакого невероятного увеличения скорости мы не получим\u003C\u002Fb\u003E, разве что сэкономим один круговой путь.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИнтересно отметить, что в QUIC коэффициент усиления, равный трём, действует и без 0-RTT (рис. 2c). Это может стать проблемой, если, например, \u003Ca href=\"https:\u002F\u002Fhpbn.co\u002Ftransport-layer-security-tls\u002F#chain-of-trust-and-certificate-authorities\"\u003ETLS-сертифкат\u003C\u002Fa\u003E сервера слишком большой и не поместится в эти 4–6 КБ. В этом случае его придется разделить, и второй фрагмент попадет во второй проход (после подтверждения первых пакетов, чтобы убедиться в подлинности IP-адреса клиента). И тогда \u003Cb\u003Eдля рукопожатий QUIC понадобится два прохода\u003C\u002Fb\u003E — прямо как у TCP + TLS! Поэтому для QUIC очень важно будет использовать такие методы, как \u003Ca href=\"https:\u002F\u002Fwww.fastly.com\u002Fblog\u002Fquic-handshake-tls-compression-certificates-extension-study\"\u003Eсжатие сертификатов\u003C\u002Fa\u003E.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ некоторых продвинутых системах эти проблемы можно будет хотя бы отчасти решить, чтобы получить больше пользы от 0-RTT. Например, сервер может помнить, какая полоса пропускания была у клиента в последний раз, и применять менее строгие алгоритмы медленного старта для контроля перегрузок для подлинных клиентов. \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1905.03144.pdf\"\u003EИсследователи уже занимаются\u003C\u002Fa\u003E этим вопросом и даже \u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Fdraft-kuhn-quic-0rtt-bdp-08\"\u003Eпредложили подходящее расширение\u003C\u002Fa\u003E для QUIC. Некоторые компании используют что-то подобное для ускорения TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕщё один вариант — отправлять с клиентов \u003Cb\u003Eбольше пакетов\u003C\u002Fb\u003E (например, еще 7 пакетов без полезных данных), чтобы трёхкратное усиление давало хотя бы 12–14 КБ даже после миграции соединения. Я писал об этом в одном из своих \u003Ca href=\"https:\u002F\u002Fqlog.edm.uhasselt.be\u002Fepiq\u002Ffiles\u002FQUICImplementationDiversity_Marx_final_11jun2020.pdf\"\u003Eисследований\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКроме того, неправильно настроенные серверы QUIC могут специально превышать трёхкратный лимит, если им кажется, что это безопасно, или проблемы с безопасностью их не волнуют (в конце концов, никакие \u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Frfc8962\"\u003Eполитики протокола\u003C\u002Fa\u003E этому не препятствуют).\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит? \u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nЕсли с 0-RTT соединение QUIC устанавливается быстрее, это скорее \u003Cb\u003Eнебольшая оптимизация\u003C\u002Fb\u003E, но уж никак не революция. По сравнению со стеком TCP + TLS 1.3 в лучшем виде, мы экономим максимум один круговой путь, да и то можем отправить только небольшой объём данных из соображений безопасности.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПо сути, вы получите большое преимущество только для пользователей в сетях \u003Cb\u003Eс очень высокой задержкой\u003C\u002Fb\u003E (допустим, спутниковые сети с RTT \u003E 200 мс) или если отправляете много данных. Пример последнего сценария — сайты с большим объёмом кэшированных данных, а еще одностраничные приложения, которые периодически получают небольшие обновления через API и другие протоколы, например, \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-dprive-dnsoquic\"\u003EDNS-over-QUIC\u003C\u002Fa\u003E. Если \u003Ca href=\"https:\u002F\u002Fstorage.googleapis.com\u002Fpub-tools-public-publication-data\u002Fpdf\u002F8b935debf13bd176a08326738f5f88ad115a071e.pdf\"\u003EGoogle получил очень хорошие результаты с 0-RTT для QUIC\u003C\u002Fa\u003E, так это потому, что они тестировали его на уже хорошо оптимизированной странице поиска с маленькими ответами на запросы.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ остальных случаях вы сэкономите не больше \u003Cb\u003Eпары десятков миллисекунд\u003C\u002Fb\u003E. Даже меньше, если используете сеть CDN (кстати, используйте CDN, если вам важна производительность!).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EМиграция соединения \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nТретья особенность ускоряет QUIC при переходе между сетями,\u003Cb\u003E поддерживая существующее соединение\u003C\u002Fb\u003E. Это полезная функция, но смена сетей происходит не так уж часто, и соединению все равно приходится сбрасывать скорость.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили, что идентификаторы соединения (CID) в QUIC позволяют переносить соединение при \u003Cb\u003Eсмене сети\u003C\u002Fb\u003E. В качестве примера мы привели переход с Wi-Fi на 4G во время загрузки большого файла. В TCP пришлось бы прервать загрузку, а в QUIC она может продолжаться.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо давайте подумаем, как часто такое вообще происходит. Может показаться, что так бывает, когда мы переходим от одной точки доступа Wi-Fi в здании к другой или между сотовыми вышками в дороге. Но если в такой системе все настроить правильно, устройство сохраняет IP-адрес, потому что переход между беспроводными базовыми станциями выполняется на более низком уровне протокола. В итоге миграция нужна только при \u003Cb\u003Eпереходе между разными сетями\u003C\u002Fb\u003E, а это не самый частый случай.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВо-вторых: полезна ли эта функция для других сценариев, кроме отправки больших файлов или онлайн-конференции? Если вы загружаете веб-страницу и в этот самый момент переходите между сетями, придется повторно запросить некоторые последние ресурсы.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо загрузка страницы занимает секунды, маловероятно, что этот период совпадёт со сменой сети. Более того, в сценариях, где это действительно проблема, \u003Cb\u003Eуже настроены другие механизмы миграции\u003C\u002Fb\u003E. Например, серверы, с которых загружают большие файлы, могут поддерживать \u003Ca href=\"https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FWeb\u002FHTTP\u002FRange_requests\"\u003EHTTP-запросы с диапазоном\u003C\u002Fa\u003E, чтобы загрузку можно было возобновлять.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПоскольку есть \u003Cb\u003Eпереходный период\u003C\u002Fb\u003E, пока первая сеть отключается, а вторая подключается, видеоприложения могут открывать несколько соединений (по одному на сеть), синхронизируя их после полного отключения первой сети. Пользователь заметит переключение, но перерывов в воспроизведении видео быть не должно.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ-третьих, нет никаких гарантий, что в новой сети будет такая же полоса пропускания, как в старой. Поэтому даже если по сути соединение не прерывается, сервер QUIC не может отправлять данные на прежней высокой скорости. Чтобы избежать перегрузки в новой сети, он должен \u003Cb\u003Eсбросить (или хотя бы снизить) скорость отправки\u003C\u002Fb\u003E и снова начать с \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#congestion-control\"\u003Eмедленного старта\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНачальная скорость обычно слишком маленькая, чтобы поддержать видеостриминг, так что вы заметите \u003Cb\u003Eпотерю качества\u003C\u002Fb\u003E или короткие сбои даже с QUIC. В каком-то смысле миграция соединения нужна скорее не для повышения производительности, а для того, чтобы сохранить контекст соединения и не потреблять лишние ресурсы сервера.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли очень постараться, можно оптимизировать миграцию соединения. Например, можно попытаться запомнить, \u003Cb\u003Eкакая полоса пропускания была доступна\u003C\u002Fb\u003E в конкретной сети в прошлый раз, и быстрее увеличить скорость до этого уровня при миграции. Ещё можно представить, что мы не просто переключаемся между сетями, а используем их обе одновременно. Эта концепция называется \u003Ci\u003Emultipath\u003C\u002Fi\u003E, и \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#future-developments-to-look-out-for\"\u003Eмы поговорим о ней чуть позже\u003C\u002Fa\u003E.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\nПока мы, в основном, говорили об активной миграции соединения, когда пользователи перемещаются между сетями. Но бывает еще и \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#name-connection-migration\"\u003Eпассивная миграция\u003C\u002Fa\u003E, когда сама сеть меняет параметры. Хороший пример — повторная привязка \u003Ca href=\"https:\u002F\u002Fcomputer.howstuffworks.com\u002Fnat.htm\"\u003ENAT\u003C\u002Fa\u003E (преобразование сетевых адресов). Здесь мы не будем подробно говорить о NAT, но суть в том, что \u003Cb\u003Eномера портов могут меняться\u003C\u002Fb\u003E в любое время без предупреждения. На большинстве роутеров это чаще происходит для UDP, чем для TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ таких случаях QUIC CID не меняется, и большинство реализаций протокола предполагают, что пользователь находится в той же физической сети, а значит не сбрасывают окно перегрузки и другие параметры. QUIC также использует \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html\"\u003EPING\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#idle-timeout\"\u003Eиндикаторы таймаута\u003C\u002Fa\u003E, чтобы предотвратить подобное, потому что обычно это происходит с соединениями, которые долго неактивны.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-core-concepts-part1\u002F#quic-supports-connection-migration\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили, что для безопасности QUIC использует несколько CID. При миграции CID меняется. На практике всё сложнее, потому что у клиента и сервера есть отдельные списки CID (\u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9000.html#name-connection-id\"\u003Eв QUIC RFC они называются CID источника и назначения\u003C\u002Fa\u003E). См. рисунок 5.\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fg6\u002F_n\u002Fwd\u002Fg6_nwda0f8kp219wy6nlnr57e38.png\"\u002F\u003E\u003Ci\u003EРис. 5: QUIC использует отдельные CID для клиента и сервера(\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F6a0b9339-6976-458d-afc2-4a0cb97a7291\u002F4-migration-src-dst-cid.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто позволяет \u003Cb\u003Eкаждой конечной точке выбирать собственный формат CID\u003C\u002Fb\u003E и содержимое. Это важно для расширенной логики маршрутизации и балансировки нагрузки. При миграции соединения балансировщики нагрузки не могут просто идентифицировать соединение по четырем параметрам и направить его на нужный бэкенд-сервер. Если бы все QUIC-соединения использовали случайные CID, это потребовало бы много памяти на стороне балансировщика нагрузки, потому что пришлось бы хранить соответствия CID с бэкенд-серверами. Миграции бы не получалось, потому что CID менялись бы на новые случайные значения.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПоэтому важно, чтобы у бэкенд-серверов QUIC, развернутых за балансировщиком нагрузки, был \u003Cb\u003Eпредсказуемый формат CID\u003C\u002Fb\u003E. Тогда балансировщик сможет определить по CID нужный сервер даже после миграции. Способы добиться этого описаны в \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-quic-load-balancers-06\"\u003Eдокументе, предложенном IETF\u003C\u002Fa\u003E. Для этого у серверов должна быть возможность выбирать собственный CID, но это было бы невозможно, если бы инициатор соединения (для QUIC это всегда клиент) выбирал CID сам. Поэтому CID клиента и сервера в QUIC разделены.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит? \u003C\u002Fh4\u003E \u003Cbr\u002F\u003E\r\nМиграция соединения зависит от ситуации. \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fquicwg\u002Fwg-materials\u002Fblob\u002Fmain\u002Fietf104\u002FIETF_104_QUIC_Connection_Migration.pdf\"\u003EНачальные тесты Google\u003C\u002Fa\u003E, например, показывают небольшой процент улучшений для их сценариев. Во многих реализациях QUIC эта функция ещё не поддерживается. А даже если поддерживается, используется для мобильных клиентов и приложений, а не их десктопных эквивалентов. Некоторые даже считают, что эта функция не нужна вовсе, потому что в большинстве случаев установка нового соединения с 0-RTT дает аналогичную производительность.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВсё же для некоторых вариантов применения и пользовательских профилей она может быть очень полезной. \u003Cb\u003EЕсли ваш сайт или приложение обычно используются во время движения\u003C\u002Fb\u003E (например, Uber или Google Maps), преимущества будут более очевидными, чем в случаях, когда ваши пользователи просто сидят за столом. Если речь о \u003Cb\u003Eнепрерывном взаимодействии\u003C\u002Fb\u003E (видеочат, совместное редактирование или игры), наихудшие варианты улучшатся заметнее, чем при использовании новостных сайтов.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EУдаление блокировки HoL \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nЧетвертая функция производительности должна ускорить QUIC в сетях с \u003Cb\u003Eбольшими потерями пакетов\u003C\u002Fb\u003E, решая проблему блокировки HoL. В теории звучит хорошо, но на практике мы, скорее всего, увидим, что производительность при загрузке веб-страниц вырастет незначительно.\u003Cbr\u002F\u003E\r\nДля начала поговорим о приоритизации потоков и мультиплексировании.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EПриоритизация потоков\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nВ \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили, что потеря одного пакета в TCP может привести к \u003Cb\u003Eзадержке данных для нескольких ресурсов\u003C\u002Fb\u003E, потому что абстракция потока байтов считает все данные частью одного файла. QUIC видит параллельные, но разные потоки байтов и обрабатывает потерю пакетов для каждого потока отдельно. На самом деле потоки передают данные не совсем параллельно. По сути, данные потока \u003Ci\u003Eмультиплексируются\u003C\u002Fi\u003E в одном соединении. Мультиплексирование происходит по-разному.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНапример, для потоков A, B и C последовательность отправки пакетов может быть \u003Ccode\u003EABCABCABCABCABCABCABCABC\u003C\u002Fcode\u003E, то есть пакеты чередуются по кругу, по принципу round-robin. Порядок может быть и другим, например \u003Ccode\u003EAAAAAAAABBBBBBBBCCCCCCCC\u003C\u002Fcode\u003E, то есть следующий поток отправляется только после полной отправки предыдущего (назовем это последовательной передачей). Комбинации могут быть разными: \u003Ccode\u003EAAAABBCAAAAABBC…\u003C\u002Fcode\u003E, \u003Ccode\u003EAABBCCAABBCC…\u003C\u002Fcode\u003E, \u003Ccode\u003EABABABCCCC…\u003C\u002Fcode\u003E и т. д. Схема мультиплексирования очень динамичная и управляется функцией приоритизации потоков на уровне HTTP (\u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#stream-prioritization\"\u003Eподробнее об этом чуть позже\u003C\u002Fa\u003E).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОказывается, выбор схемы мультиплексирования заметно влияет на производительность загрузки сайта. Это видно на видео внизу (спасибо \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fbetter-http-2-prioritization-for-a-faster-web\u002F\"\u003ECloudflare\u003C\u002Fa\u003E), поскольку у каждого браузера свой мультиплексор. У этого явления множество причин, и я не раз писал об этом (например, \u003Ca href=\"https:\u002F\u002Fspeeder.edm.uhasselt.be\u002Fwww18\u002Ffiles\u002Fh2priorities_mwijnants_www2018.pdf\"\u003Eздесь\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fh2.edm.uhasselt.be\u002Ffiles\u002FResourceMultiplexing_H2andH2_Marx2020.pdf\"\u003Eздесь\u003C\u002Fa\u003E) и \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=nH4iRpFnf1c\"\u003Eрассказывал\u003C\u002Fa\u003E на конференции. Патрик Минан (Patrick Meenan), создатель \u003Ca href=\"https:\u002F\u002Fwww.webpagetest.org\u002F\"\u003EWebpagetest\u003C\u002Fa\u003E, записал целое \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=ct5MvtmL1NM\"\u003Eтрехчасовое руководство\u003C\u002Fa\u003E исключительно на эту тему.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fro\u002F_y\u002Fqz\u002Fro_yqz59ztve8opucqpj0rfhzlm.gif\"\u002F\u003E\u003Ci\u003EКак различия в мультиплексировании влияют на загрузку сайтов в разных браузерах (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F6a0b9339-6976-458d-afc2-4a0cb97a7291\u002F4-migration-src-dst-cid.png\"\u003Eисходник\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nК счастью, основы можно объяснить относительно просто. Возможно, вы знаете, что некоторые ресурсы \u003Ca href=\"https:\u002F\u002Fweb.dev\u002Frender-blocking-resources\u002F\"\u003Eблокируют рендеринг\u003C\u002Fa\u003E. Так бывает с файлами CSS и иногда с JavaScript в элементе HTML \u003Ccode\u003Ehead\u003C\u002Fcode\u003E. Эти файлы загружаются, но браузер не может отрисовать страницу (или, например, выполнить новые JavaScript).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nБолее того, файлы CSS и JavaScript нужно \u003Cb\u003Eзагрузить полностью\u003C\u002Fb\u003E, чтобы использовать (хотя их часто можно парсить и компилировать постепенно). Такие ресурсы нужно загружать как можно быстрее, у них наивысший приоритет. Что будет, если ресурсы A, B и C будут блокировать рендеринг?\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fns\u002Ftw\u002Fyi\u002Fnstwyiqkhw4vawkbrsua2ind3ra.png\"\u002F\u003E\u003Ci\u003EРис. 6: Подход к мультиплексированию потока влияет на время загрузки ресурсов, блокирующих рендеринг (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F46ae54c1-2985-4c47-9ebe-18686bbfc4ce\u002Fmultiplexing-render-blocking.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли использовать \u003Ci\u003Eпринцип round-robin\u003C\u002Fi\u003E (верхний ряд на рис. 6), мы задержим загрузку каждого ресурса, потому что им придется делить полосу пропускания с остальными. Раз их можно использовать только после полной загрузки, задержка будет значительной. Если мультиплексировать их последовательно (нижний ряд на рис. 6), A и B загрузятся гораздо раньше и будут доступны для браузера, при этом они не повлияют на время загрузки C.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЭто не значит, что последовательный подход всегда лучше, потому что ресурсы без блокировки рендеринга (например, HTML и прогрессивный JPEG) можно \u003Cb\u003Eобрабатывать и использовать постепенно\u003C\u002Fb\u003E. В этих и некоторых других случаях лучше использовать первый вариант или что-то среднее.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо для \u003Ci\u003Eбольшинства\u003C\u002Fi\u003E ресурсов веб-страниц \u003Cb\u003Eпоследовательное мультиплексирование работает лучше\u003C\u002Fb\u003E. Так, например, поступает Google Chrome на видео выше, а Internet Explorer использует самый неподходящий мультиплексор с round-robin.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EУстойчивость к потере пакетов\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nИтак, мы знаем, что потоки не всегда активны одновременно и могут мультиплексироваться по-разному. Давайте посмотрим, что происходит при потере пакетов. В \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы видели, что если в одном потоке QUIC теряется пакет, остальные \u003Ci\u003Eактивные\u003C\u002Fi\u003E потоки все равно можно использовать (в TCP они будут приостановлены).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКак мы только что узнали, несколько параллельных активных потоков — это обычно не лучший вариант в плане производительности, потому что важные ресурсы с блокировкой рендеринга загружаются медленно даже без потери пакетов. Лучше, чтобы активным был только один или два потока, как в последовательном подходе. Но при такой схеме мы не реализуем весь потенциал удаления блокировок HoL в QUIC.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДопустим, отправитель может передать \u003Cb\u003E12 пакетов\u003C\u002Fb\u003E за раз (см. рис. 7) — помните, что это число ограничено \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#congestion-control\"\u003Eмеханизмом контроля перегрузки\u003C\u002Fa\u003E). Если все эти 12 пакетов будут относиться к потоку A (потому что он блокирует рендеринг и имеет высший приоритет — допустим, это \u003Ccode\u003Emain.js\u003C\u002Fcode\u003E), у нас будет всего один активный поток.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли один из пакетов потеряется, придется применить \u003Cb\u003Eблокировку HoL\u003C\u002Fb\u003E — у QUIC просто не будет других потоков для обработки, кроме A. Все данные здесь относятся только к A (у нас нет данных B или C) и остальным ресурсам придется ждать, как в TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ffs\u002Fpy\u002Fsv\u002Ffspysv-1_m4aaw-fvxmztiiipom.png\"\u002F\u003E\u003Ci\u003EРис. 7: Последствия потери пакетов зависят от мультиплексора. Мы предполагаем, что у каждого потока больше для данных для отправки, чем на предыдущих изображениях (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F05412377-b92f-4adc-9725-4a3b4b4d602a\u002Fhol-blocking-rr-sequential.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВозникает противоречие: последовательное мультиплексирование (\u003Ccode\u003EAAAABBBBCCCC\u003C\u002Fcode\u003E) обычно лучше для производительности веб-страниц, но оно мешает нам использовать все преимущества удаления блокировки HoL в QUIC. Мультиплексирование по принципу round-robin (\u003Ccode\u003EABCABCABCABC\u003C\u002Fcode\u003E) лучше сочетается с отсутствием блокировки HoL, но снижает производительность. В итоге получается, что \u003Cb\u003Eодин метод оптимизации нивелирует другой\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИ даже это еще не всё. Пока мы говорили только о потере пакетов по одному за раз. На самом деле пакеты в интернете теряются \u003Ca href=\"https:\u002F\u002Fhuitema.wordpress.com\u002F2020\u002F07\u002F12\u002Fparsing-quic-logs-and-assessing-packet-losses\u002F\"\u003Eпачками\u003C\u002Fa\u003E, \u003Cb\u003Eпо несколько штук одновременно\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВыше мы говорили, что пакеты часто теряются, когда сеть уже перегружена данными и отбрасывает лишнее. Затем и нужен медленный старт, после которого скорость увеличивается вплоть до… потери пакетов!\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТо есть механизм, который должен предотвращать перегрузку сети, по факту \u003Cb\u003Eперегружает сеть\u003C\u002Fb\u003E (пусть и контролируемо). В большинстве сетей это происходит через некоторое время, когда пакеты отправляются по несколько сотен за раз. Когда лимит достигнут, можно потерять сразу много пакетов.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОтчасти поэтому мы и хотели перейти на использование одного (TCP) соединения с HTTP\u002F2 вместо 6–30 соединений с HTTP\u002F1.1. Каждое отдельное соединение ускоряется примерно одинаково, поэтому у HTTP\u002F1.1 была бы хорошая скорость в начале, но потом началась бы \u003Cb\u003Eмассовая потеря пакетов\u003C\u002Fb\u003E, потому что соединения перегрузили бы сеть и мешали друг другу.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ то время \u003Ca href=\"https:\u002F\u002Fa77db9aa-a-7b23c8ea-s-sites.googlegroups.com\u002Fa\u002Fchromium.org\u002Fdev\u002Fspdy\u002FAn_Argument_For_Changing_TCP_Slow_Start.pdf\"\u003Eразработчики Chromium высказывали предположения\u003C\u002Fa\u003E, что это поведение отвечает за потерю большинства пакетов в интернете. И это одна из причин, по которым BBR часто используется как алгоритм контроля перегрузок, — он оценивает доступную полосу пропускания по колебаниям в RTT, а не потере пакетов.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДругие причины могут привести к потере небольшого количества пакетов, особенно в беспроводных сетях. Но там потери обычно обнаруживаются на нижних уровнях протокола и решаются между двумя объектами (скажем, смартфоном и вышкой 4G), а не между клиентом и сервером. Обычно это не приводит к настоящей потере пакетов, а выражается, скорее, как \u003Cb\u003Eотклонения в задержках\u003C\u002Fb\u003E (jitter) и поступление пакетов в другом порядке.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДопустим, мы используем подход round-robin (\u003Ccode\u003EABCABCABCABCABCABCABCABC…\u003C\u002Fcode\u003E), чтобы получить максимум преимуществ от удаления блокировки HoL, и у нас теряется группа из четырёх пакетов. Такая потеря всегда будет затрагивать все три потока (см. средний ряд на рис. 8). В этом случае удаление блокировки HoL в QUIC не даёт никаких преимуществ, потому что \u003Cb\u003Eвсем потокам придётся ждать повторной передачи\u003C\u002Fb\u003E.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fdi\u002Fpk\u002F3f\u002Fdipk3fhymwvigy6npltvr0qpqx0.png\"\u002F\u003E\u003Ci\u003EРис. 8: В зависимости от мультиплексора и количества потерянных пакетов будет затронут один или несколько потоков(\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002F93cb3e10-16dd-4647-af85-91cc723d35f6\u002Fhol-blocking-bursty.png\"\u003Eисходное изображение\u003C\u002Fa\u003E)\u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЧтобы потеря группы пакетов не влияла сразу на несколько потоков, нужно передавать подряд больше пакетов из одного потока. Например, схема \u003Ccode\u003EAABBCCAABBCCAABBCCAABBCC…\u003C\u002Fcode\u003E сработает чуть лучше, а \u003Ccode\u003EAAAABBBBCCCCAAAABBBBCCCC…\u003C\u002Fcode\u003E — ещё лучше (см. нижний ряд на рис. 8). Более последовательный подход будет эффективнее, хотя с ним у нас будет меньше параллельности.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ целом сложно предсказать, какую пользу мы получим от удаления блокировки HoL в QUIC. Все зависит от числа потоков, размера и частоты потери групп пакетов, фактического использования данных потока и т. д. Однако пока \u003Ca href=\"https:\u002F\u002Fh2.edm.uhasselt.be\u002Ffiles\u002FResourceMultiplexing_H2andH2_Marx2020.pdf\"\u003Eбольшинство результатов\u003C\u002Fa\u003E показывают, что преимущество \u003Cb\u003Eне так уж заметно\u003C\u002Fb\u003E при загрузке веб-страниц, потому что в этом сценарии у нас обычно меньше параллельных потоков.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли хотите больше узнать об этой теме или изучить конкретные примеры, читайте мою \u003Ca href=\"https:\u002F\u002Fcalendar.perfplanet.com\u002F2020\u002Fhead-of-line-blocking-in-quic-and-http-3-the-details\u002F\"\u003Eстатью с подробным описанием блокировки HoL в HTTP\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗдесь тоже можно использовать разные хитрости. Например, современные механизмы контроля перегрузки используют \u003Ca href=\"https:\u002F\u002Fhomes.cs.washington.edu\u002F~tom\u002Fpubs\u002Fpacing.pdf\"\u003Epacket pacing\u003C\u002Fa\u003E. Это значит, что они не отправляют, допустим, 100 пакетов одной группой, а \u003Cb\u003Eраспределяют их\u003C\u002Fb\u003E по всему RTT. Это снижает вероятность перегрузки сети, и \u003Ca href=\"https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9002.html#https:\u002F\u002Fwww.rfc-editor.org\u002Frfc\u002Frfc9002.html\"\u003Eв QUIC Recovery RFC рекомендуется использовать такой подход\u003C\u002Fa\u003E. Кроме того, некоторые алгоритмы контроля перегрузок, например \u003Ca href=\"https:\u002F\u002Fblog.apnic.net\u002F2017\u002F05\u002F09\u002Fbbr-new-kid-tcp-block\u002F\"\u003EBBR\u003C\u002Fa\u003E, не повышают скорость отправки до потери пакетов, а останавливаются заранее, учитывая, например, колебания RTT, поскольку RTT возрастает при приближении к перегрузке).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакие подходы снижают вероятность потери пакетов, но не всегда снижают частоту возникновения такого явления, как потеря пакетов.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит?\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ теории удаление блокировки HoL означает, что QUIC (и HTTP\u002F3) будут работать лучше в сетях с большими потерями, но на практике всё зависит от многих факторов. Поскольку для загрузки веб-страниц лучше подходит более последовательное мультиплексирование, а потеря пакетов непредсказуема, скорее всего, эта функция будет по-настоящему полезна только для \u003Cb\u003E1% самых медленных пользователей\u003C\u002Fb\u003E. Но исследования продолжаются и, может быть, что-то изменится.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ некоторых ситуациях улучшения будут более заметны. В основном, не для первой полноценной загрузки страницы (самого распространённого сценария), а в случаях, когда ресурсы не блокируют рендеринг, и они могут обрабатываться постепенно, тогда как потоки полностью независимы друг от друга или за один раз отправляется меньше данных.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНапример, \u003Cb\u003Eпри повторном посещении хорошо кэшированных страниц\u003C\u002Fb\u003E, фоновых загрузках и вызовах API в одностраничных приложениях. Facebook, скажем, реализует преимущества удаления блокировки HoL, когда загружает данные в их собственное приложение приложение через HTTP\u002F3.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EПроизводительность UDP и TLS \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nПятый аспект производительности QUIC и HTTP\u002F3 связан с тем, насколько эффективно и продуктивно эти протоколы могут \u003Cb\u003Eсоздавать и отправлять пакеты\u003C\u002Fb\u003E в сети. Мы увидим, что из-за UDP и массового шифрования QUIC может работать медленнее, чем TCP (но постепенно прогрессирует).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nМы \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eуже говорили\u003C\u002Fa\u003E, что QUIC использует UDP для гибкости и простоты развёртывания, а не для производительности. Это подтверждает и тот факт, что до последнего времени через QUIC с UDP пакеты отправлялись гораздо медленнее, чем у TCP. Во многом это связано с тем, где и как обычно реализуются эти протоколы (см. рис. 9).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fx1\u002Ffj\u002F2r\u002Fx1fj2ru4oj9grl_a1oplehxmk14.png\"\u002F\u003E\u003Ci\u003EРис. 9: Различия в реализации между TCP и QUIC (\u003Ca href=\"https:\u002F\u002Fcloud.netlifyusercontent.com\u002Fassets\u002F344dbf88-fdf9-42bb-adb4-46f01eedd629\u002Fcffc7945-bd57-459f-b6d3-ed06f51b30ad\u002Fkernel-user-space.png\"\u003Eисходное изображение\u003C\u002Fa\u003E) \u003C\u002Fi\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКак мы говорили выше, TCP и UDP обычно реализуются на быстром уровне, прямо в ядре ОС. TLS и QUIC, в основном, реализуются в более медленном пользовательском пространстве (в QUIC это сделано, в основном, для гибкости). Хотя бы из-за этого QUIC работает чуть медленнее, чем TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nКроме того, если данные отправляются из софта в пользовательском пространстве (допустим, браузеров или веб-серверов), мы должны \u003Cb\u003Eпередать эти данные в ядро ОС\u003C\u002Fb\u003E, которое затем использует TCP или UDP для их передачи в сеть. Данные передаются через API ядра (системные вызовы), что приводит к некоторым издержкам. Для TCP эти издержки были гораздо меньше, чем для UDP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ основном, потому что традиционно TCP использовался гораздо больше, чем UDP. Со временем в реализации TCP и API ядра добавили много оптимизаций, чтобы свести к минимуму издержки при отправке и получении пакетов. Во многих сетевых платах (NIC) даже есть встроенная аппаратная обработка (hardware-offload) для TCP. UDP не так повезло, потому что он используется ограниченно и вроде как не стоит затраченных усилий. К счастью, в последние пять лет \u003Cb\u003Eбольшинство ОС добавили\u003C\u002Fb\u003E \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fhow-to-receive-a-million-packets\u002F\"\u003Eварианты оптимизации и для UDP\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nQUIC связан с большими издержками, потому что \u003Cb\u003Eшифрует каждый пакет отдельно\u003C\u002Fb\u003E. Стек TLS + TCP делает это быстрее и эффективнее, потому что \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Foptimizing-tls-over-tcp-to-reduce-latency\u002F\"\u003Eпакеты шифруются группами\u003C\u002Fa\u003E (до 16 КБ или 11 пакетов за раз). В QUIC от этого отказались намеренно, потому что шифрование нескольких пакетов может привести \u003Ca href=\"https:\u002F\u002Fwww.igvita.com\u002F2013\u002F10\u002F24\u002Foptimizing-tls-record-size-and-buffering-latency\u002F\"\u003Eк блокировке HoL\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗдесь уже нельзя добавить API, чтобы ускорить UDP (и QUIC), а значит по этому показателю QUIC всегда будет отставать от TCP + TLS. Но на практике можно, например, использовать \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fh2o\u002Fpicotls\u002Fpull\u002F310\"\u003Eоптимизированные библиотеки шифрования\u003C\u002Fa\u003E и продуманные методы, чтобы шифровать заголовки пакетов QUIC по несколько штук.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПервые версии QUIC от Google работали \u003Ca href=\"https:\u002F\u002Frjshade.com\u002Fwork\u002Ffiles\u002Fpapers\u002Fpdf\u002Flangley_et_al_sigcomm2017_quic.pdf\"\u003Eв два раза медленнее, чем TCP + TLS\u003C\u002Fa\u003E, но с тех пор всё стало гораздо лучше. Например, в недавних тестах Microsoft удалось достичь для \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmicrosoft\u002Fmsquic\"\u003Eтщательно оптимизированного стека QUIC\u003C\u002Fa\u003E скорости в 7,85 Гбит\u002Fс, тогда как TCP + TLS показал 11,85 Гбит\u002Fс в той же системе (здесь QUIC примерно на треть медленнее TCP + TLS).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВсё благодаря последним апдейтам Windows, которые ускорили UDP (для полноты сравнения — пропускная способность UDP в этой системе была 19,5 Гбит\u002Fс). Самая оптимизированная версия стека QUIC у Google сейчас \u003Ca href=\"https:\u002F\u002Fyoutu.be\u002FxxN4FfwaANk?t=3161\"\u003Eна 20% медленнее, чем TCP + TLS\u003C\u002Fa\u003E. \u003Ca href=\"https:\u002F\u002Fwww.fastly.com\u002Fblog\u002Fmeasuring-quic-vs-tcp-computational-efficiency\"\u003EРанние тесты, проведённые Fastly\u003C\u002Fa\u003E на менее продвинутых системах и с некоторыми доработками даже показывают одинаковые цифры (примерно 450 Мбит\u002Fс), то есть в определённых условиях QUIC вполне может составить конкуренцию TCP.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНо даже если QUIC будет в два раза медленнее TCP + TLS, это не так уж и страшно. Начнем с того, что обработка QUIC и TCP + TLS — не самая ресурсоёмкая задача на сервере, потому что есть и другие процессы (допустим, HTTP, кэширование, прокси и т. д.). Поэтому вам не понадобится \u003Cb\u003Eв два раза больше серверов для QUIC\u003C\u002Fb\u003E (пока не совсем ясно, как всё-таки это отразится на реальном дата-центре, потому что никто из крупных компаний ещё не рассказывал об этом).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВо-вторых, есть много возможностей оптимизировать реализации QUIC в будущем. Например, со временем некоторые реализации QUIC будут частично перенесены в ядро ОС (как TCP) или будут обходить его (некоторые уже это делают, например \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmicrosoft\u002Fmsquic\"\u003EMsQuic\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FNTAP\u002Fquant\"\u003EQuant\u003C\u002Fa\u003E). Можно ожидать появления \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fmeeting\u002F104\u002Fmaterials\u002Fslides-104-quic-offloading-quic-00\"\u003Eоборудования под QUIC.\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСкорее всего, в некоторых сценариях TCP + TLS останется предпочтительным вариантом. Например, в Netflix в обозримом будущем не собираются переходить на QUIC, потому что \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=8NSzkYSX5nY\"\u003Eсерьёзно вложились в специфичные решения на базе FreeBSD\u003C\u002Fa\u003E для стриминга по TCP + TLS.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ Facebook тоже говорят, что из-за больших издержек QUIC пока будет использоваться \u003Cb\u003Eмежду конечными пользователями и границей CDN\u003C\u002Fb\u003E, но не между дата-центрами или граничными узлами и исходными серверами. В целом, если полоса пропускания большая, лучше использовать TCP + TLS. Во всяком случае в следующие пару-тройку лет.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cblockquote\u003E\u003Ci\u003E\u003Cb\u003EА вы знали?\u003C\u002Fb\u003E\u003C\u002Fi\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nОптимизация сетевых стеков — это огромное непаханое поле, которое мы пока ковыряем лопаткой. Если вам хватит смелости или очень хочется узнать, что такое \u003Ccode\u003EGRO\u002FGSO\u003C\u002Fcode\u003E, \u003Ccode\u003ESO_TXTIME\u003C\u002Fcode\u003E, kernel bypass, \u003Ccode\u003Esendmmsg()\u003C\u002Fcode\u003E и \u003Ccode\u003Erecvmmsg()\u003C\u002Fcode\u003E, почитайте интересные статьи об оптимизации QUIC от \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Faccelerating-udp-packet-transmission-for-quic\u002F\"\u003ECloudflare\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fwww.fastly.com\u002Fblog\u002Fmeasuring-quic-vs-tcp-computational-efficiency\"\u003EFastly\u003C\u002Fa\u003E или посмотрите подробные обзоры от \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=Icskyw17Dgw\"\u003EMicrosoft\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Farchive.fosdem.org\u002F2020\u002Fschedule\u002Fevent\u002Ffast_quic_sockets_for_cloud_networking\u002F\"\u003ECisco\u003C\u002Fa\u003E. Один инженер из Google интересно рассказал, как они \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=xxN4FfwaANk\"\u003Eпланируют оптимизировать свою реализацию QUIC\u003C\u002Fa\u003E.\u003C\u002Fblockquote\u003E\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит?\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nИз-за подхода к применению протоколов UDP и TLS изначально QUIC был гораздо медленнее, чем TCP + TLS. Сейчас благодаря разным улучшениям он потихоньку догоняет. В обычных условиях при загрузке веб-страниц вы вряд ли что-то заметите, но на больших серверных фермах эти расхождения будут бросаться в глаза.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EВозможности HTTP\u002F3\u003C\u002Fh2\u003E \u003Cbr\u002F\u003E\r\nДо сих пор мы сравнивали QUIC и TCP. А как насчёт HTTP\u002F3 и HTTP\u002F2? В \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsouthbridge\u002Fblog\u002F575464\u002F\"\u003Eпервой части\u003C\u002Fa\u003E мы говорили, что \u003Cb\u003EHTTP\u002F3 — это, по сути, HTTP\u002F2-over-QUIC\u003C\u002Fb\u003E, так что ничего особо нового ждать не приходится. HTTP\u002F1.1 и HTTP\u002F2 гораздо сильнее отличаются друг от друга, например, сжатием заголовков, приоритизацией потоков и server push. Всё это есть и в HTTP\u002F3. Разница в том, как эти возможности реализованы.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ основном, это связано с тем, как работает в QUIC удаление блокировки HoL. \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#head-of-line-blocking-removal\"\u003EМы уже говорили\u003C\u002Fa\u003E, что потеря пакетов из потока B больше не означает, что потокам A и C придётся ждать, пока B догонит, как это было в TCP. Так что если пакеты A, B и C были отправлены через QUIC в этом порядке, в итоге браузер может получить и обработать их в порядке A, C, B! Другими словами, в отличие от TCP, QUIC \u003Cb\u003Eне соблюдает строгий порядок потоков\u003C\u002Fb\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nHTTP\u002F2 ждал от TCP пакеты в определённом порядке для многих функций, которые используют специальные управляющие сообщения и фрагменты данных. В QUIC управляющие сообщения могут поступать и применяться в любом порядке, так что потенциально результат выполнения функций может быть противоположен ожидаемому. В технические дебри углубляться не будем, но по \u003Ca href=\"https:\u002F\u002Fh2.edm.uhasselt.be\u002Ffiles\u002FHTTP3_Prioritization_extended_3jul2019.pdf\"\u003Eпервой половине этой статьи\u003C\u002Fa\u003E видно, насколько это неразумно сложная схема.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ итоге внутренняя механика и реализация функций должна была измениться в HTTP\u002F3. Конкретный пример — \u003Cb\u003Eсжатие заголовков HTTP\u003C\u002Fb\u003E, которое позволяет сэкономить на повторяющихся больших заголовках HTTP (например, cookie и строки user-agent). В HTTP\u002F2 для этого использовался \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Frfc7541\"\u003EHPACK\u003C\u002Fa\u003E, который для HTTP\u002F3 переделали в более сложный \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-quic-qpack\"\u003EQPACK\u003C\u002Fa\u003E. Обе системы выполняют одну задачу (сжимают заголовки), но по-разному. Подробные технические описания и схемы читайте в \u003Ca href=\"https:\u002F\u002Fblog.litespeedtech.com\u002Ftag\u002Fquic-header-compression-design-team\u002F\"\u003Eблоге Litespeed\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПримерно то же самое можно сказать и о функции приоритизации, которая управляет логикой мультиплексирования потоков, \u003Ca href=\"https:\u002F\u002Fwww.smashingmagazine.com\u002F2021\u002F08\u002Fhttp3-performance-improvements-part2\u002F#head-of-line-blocking-removal\"\u003Eкак мы недавно увидели\u003C\u002Fa\u003E. В HTTP\u002F2 она реализована с помощью сложного дерева зависимостей, которое пыталось описать все ресурсы страницы и их взаимосвязи (есть \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=nH4iRpFnf1c\"\u003Eинтересное видео о приоритизации ресурсов в HTTP\u003C\u002Fa\u003E). Если просто перенести эту систему на QUIC, дерево может получиться очень странное, потому что добавление в него каждого ресурса потребовало бы отдельного управляющего сообщения.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nТакой подход оказался слишком сложным, так что \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fnginx-structural-enhancements-for-http-2-performance\u002F\"\u003Eв реализациях возникали баги и недостатки\u003C\u002Fa\u003E, а \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fandydavies\u002Fhttp2-prioritization-issues\"\u003Eпроизводительность на многих серверах оставляла желать лучшего\u003C\u002Fa\u003E. В итоге система приоритизации \u003Ca href=\"https:\u002F\u002Fblog.cloudflare.com\u002Fadopting-a-new-approach-to-http-prioritization\u002F\"\u003Eв HTTP\u002F3 была переработана и упрощена\u003C\u002Fa\u003E. С упрощённой структурой затруднительно или даже невозможно реализовать некоторые сложные сценарии (например, проксирование трафика с нескольких клиентов в одно соединение), но для оптимизации загрузки веб-страниц возможностей достаточно.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЗдесь тоже оба подхода решают одну задачу (мультиплексирование), но мы надеемся, что благодаря простоте настройки HTTP\u002F3 в реализации будет меньше багов.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nНаконец, \u003Cb\u003Eserver push\u003C\u002Fb\u003E. позволяет серверу отправлять HTTP-ответы без явного запроса. В теории это должно серьезно повысить производительность. На практике оказалось, что \u003Ca href=\"https:\u002F\u002Fcalendar.perfplanet.com\u002F2016\u002Fhttp2-push-the-details\u002F\"\u003Eправильно использовать эту функцию сложно\u003C\u002Fa\u003E, и \u003Ca href=\"https:\u002F\u002Fjakearchibald.com\u002F2017\u002Fh2-push-tougher-than-i-thought\u002F\"\u003Eреализуется она несогласованно\u003C\u002Fa\u003E. Скорее всего, \u003Ca href=\"https:\u002F\u002Fgroups.google.com\u002Fa\u002Fchromium.org\u002Fg\u002Fblink-dev\u002Fc\u002FK3rYLvmQUBY\u002Fm\u002FvOWBKZGoAQAJ\"\u003Eиз Google Chrome эту функцию удалят\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\nПока она \u003Ci\u003Eвсё ещё\u003C\u002Fi\u003E числится \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-quic-http\"\u003Eкак функция HTTP\u002F3\u003C\u002Fa\u003E (хотя ее поддерживают мало реализаций). Она изменилась не так сильно, как предыдущие две функции, но её адаптировали к недетерминированному порядку в QUIC. К сожалению, это мало поможет решить её давние проблемы.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит?\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nМы уже говорили, что большинство потенциальных преимуществ HTTP\u002F3 связаны с QUIC. Внутренняя реализация протокола \u003Ci\u003Eочень\u003C\u002Fi\u003E отличается от HTTP\u002F2, но высокоуровневые возможности производительности и варианты их применения не изменились.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EЧего нужно ждать в будущем \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nВ этой серии я не раз подчёркивал главные преимущества QUIC (а значит и HTTP\u002F3) — быстрое развитие и хорошая гибкость. Это значит, что \u003Cb\u003Eновые расширения\u003C\u002Fb\u003E протокола и варианты его применения уже разрабатываются. Вот за чем нужно следить особенно внимательно:\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Fdraft-swett-nwcrg-coding-for-quic\"\u003E\u003Cb\u003EForward error correction\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EЦель этой техники — \u003Cb\u003Eповысить устойчивость QUIC к потере пакетов\u003C\u002Fb\u003E. Суть заключается в отправке избыточных копий данных (они по-умному закодированы и сжаты, так что занимают не очень много места). Если пакет потерялся, но у нас есть его копия, снова передавать его не нужно.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nИзначально такая возможность была в Google QUIC (откуда и пошли разговоры об устойчивости к потере пакетов), но в стандартизированный QUIC version 1 она не входит, потому что её влияние на производительность пока не проверено. Эксперименты уже ведутся, и вы можете поучаствовать в них через приложение \u003Ca href=\"https:\u002F\u002Fplay.google.com\u002Fstore\u002Fapps\u002Fdetails?id=org.pquic.pquic_fec_android\"\u003EPQUIC-FEC Download Experiments\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Fdraft-liu-multipath-quic\"\u003E\u003Cb\u003EMultipath QUIC\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EВы уже знаете о миграции соединения и о том, что она даёт, скажем, при переходе с Wi-Fi на сотовую сеть. А почему бы тогда не использовать Wi-Fi и сотовую сеть \u003Cb\u003Eодновременно\u003C\u002Fb\u003E, чтобы увеличить полосу пропускания и повысить надёжность. Это главная концепция, на которой основан подход multipath.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВ Google экспериментировали с этим, но в QUIC version 1 эта возможность не входит из-за своей сложности. Исследователи видят здесь \u003Ca href=\"https:\u002F\u002Fmultipath-quic.org\u002F\"\u003Eбольшой потенциал\u003C\u002Fa\u003E, так что ждём QUIC version 2. Кстати, \u003Ca href=\"https:\u002F\u002Fwww.multipath-tcp.org\u002F\"\u003ETCP multipath\u003C\u002Fa\u003E тоже существует, но ему понадобилось почти десять лет, чтобы стать применимым на практике.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Ftools.ietf.org\u002Fhtml\u002Fdraft-ietf-quic-datagram\"\u003E\u003Cb\u003EПередача ненадёжных данных по QUIC\u003C\u002Fb\u003E\u003C\u002Fa\u003E \u003Cb\u003Eи\u003C\u002Fb\u003E \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-masque-h2-datagram\"\u003E\u003Cb\u003EHTTP\u002F3\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EQUIC очень надёжный протокол, но работает поверх ненадёжного UDP, так что QUIC можно приспособить и для передачи ненадёжных данных. Механизм описан в предложенном расширении для датаграмм. Он, конечно, не подходит для отправки ресурсов веб-страницы, но может пригодиться для игр или видеостриминга. Так пользователи получат все преимущества UDP, но с шифрованием и, по желанию, контролем перегрузок от QUIC.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fweb.dev\u002Fwebtransport\u002F\"\u003E\u003Cb\u003EWebTransport\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\n\u003C\u002Fa\u003EБраузеры не открывают TCP или UDP для JavaScript напрямую, в основном, из соображений безопасности. Приходится использовать API на уровне HTTP, например Fetch, и более гибкие протоколы \u003Ca href=\"https:\u002F\u002Fhpbn.co\u002Fwebsocket\u002F\"\u003EWebSocket\u003C\u002Fa\u003E и \u003Ca href=\"https:\u002F\u002Fhpbn.co\u002Fwebrtc\u002F\"\u003EWebRTC\u003C\u002Fa\u003E. Самый новый вариант — WebTransport, с которым можно использовать HTTP\u002F3 (а значит и QUIC) на более низком уровне (хотя его можно приспособить и для TCP и HTTP\u002F2, если нужно).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nСамое главное, он позволит использовать ненадёжные данные по HTTP\u002F3 (см. выше), чтобы упростить реализацию в браузере, например, для игр. Для обычных (JSON) вызовов API мы всё равно будем использовать Fetch, который автоматически будет применять HTTP\u002F3 по возможности. Вокруг WebTransport пока много дискуссий, так что неясно, как он в итоге будет выглядеть. Из браузеров только Chromium пока работает над открытой \u003Ca href=\"https:\u002F\u002Fgroups.google.com\u002Fa\u002Fchromium.org\u002Fg\u002Fweb-transport-dev\u002Fc\u002F6PwPFy9fVfw\"\u003Eproof-on-concept реализацией\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Cb\u003EDASH и HLS для стриминга\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\nДля видео по запросу (например, YouTube или Netflix) браузеры обычно используют протоколы Dynamic Adaptive Streaming over HTTP (DASH) и HTTP Live Streaming (HLS). Оба подразумевают кодирование видео маленькими фрагментами (2–10 секунд) и разные уровни качества (720p, 1080p, 4K).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПри запуске браузер оценивает максимальное качество, которое потянет сеть (или оптимальный уровень для конкретного сценария), и запрашивает соответствующие файлы у сервера по HTTP. У браузера нет прямого доступа к стеку TCP (потому что он обычно реализуется в ядре), так что иногда он ошибается в своих оценках или медленно реагирует на изменение условий (и видео зависает).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nQUIC реализуется как часть браузера, поэтому его можно заметно улучшить, если \u003Ca href=\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3386367.3431901\"\u003Eдать механизмам оценки доступ к информации на нижнем уровне протоколов\u003C\u002Fa\u003E (процент потерь, полоса пропускания и т. д.). Другие исследователи тоже экспериментировали со \u003Ca href=\"https:\u002F\u002Fwww.researchgate.net\u002Fprofile\u002FMirko-Palmer\u002Fpublication\u002F327930175_The_QUIC_Fix_for_Optimal_Video_Streaming\u002Flinks\u002F5f60ea97299bf1d43c063075\u002FThe-QUIC-Fix-for-Optimal-Video-Streaming.pdf\"\u003Eсмешиванием надёжных и ненадёжных данных для видеостриминга\u003C\u002Fa\u003E и получили неплохие результаты.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003Cli\u003E\u003Cb\u003EДругие протоколы (кроме HTTP\u002F3)\u003C\u002Fb\u003E\u003Cbr\u002F\u003E\r\nQUIC — это транспортный протокол общего назначения, и, скорее всего, многие протоколы на прикладном уровне, которые сейчас используют TCP, будут работать и на QUIC. Сейчас уже разрабатывают \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-ietf-dprive-dnsoquic\"\u003EDNS-over-QUIC\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Ftechcommunity.microsoft.com\u002Ft5\u002Fitops-talk-blog\u002Fsmb-over-quic-files-without-the-vpn\u002Fba-p\u002F1183449\"\u003ESMB-over-QUIC\u003C\u002Fa\u003E и даже \u003Ca href=\"https:\u002F\u002Fdatatracker.ietf.org\u002Fdoc\u002Fhtml\u002Fdraft-bider-ssh-quic-09\"\u003ESSH-over-QUIC\u003C\u002Fa\u003E. У этих протоколов другие требования, не связанные с HTTP и загрузкой веб-страниц, так что в них улучшения производительности QUIC могут проявляться заметнее.\u003Cbr\u002F\u003E\r\n\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch4\u003EЧто всё это значит?\u003C\u002Fh4\u003E\u003Cbr\u002F\u003E\r\nQUIC version 1 — это \u003Cb\u003Eвсего лишь начало\u003C\u002Fb\u003E. Многие улучшения производительности, над которыми экспериментировал Google, не вошли в первую версию. Но протокол очень быстро развивается, появляются всё новые расширения и функции. Со временем QUIC (и HTTP\u002F3 вместе с ним) станут заметно более быстрыми и гибкими по сравнению с TCP (и HTTP\u002F2).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\n\u003Ch2\u003EЗаключение \u003C\u002Fh2\u003E\u003Cbr\u002F\u003E\r\nВо второй части серии мы рассмотрели разные \u003Cb\u003Eфункции и аспекты производительности HTTP\u002F3\u003C\u002Fb\u003E и особенно QUIC. Мы увидели, что большинство этих функций кажутся интересными, но на практике не приносят ожидаемой пользы среднему пользователю при загрузке веб-страниц.\u003Cbr\u002F\u003E\r\nНапример, хоть QUIC и использует UDP, это не значит, что ему доступна более широкая полоса пропускания, чем TCP, или что он будет загружать ресурсы быстрее. Хвалёный 0-RTT позволяет сэкономить всего один круговой путь, и то мы успеем передать примерно пять килобайт (в худшем сценарии).\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nУдаление блокировки HoL не спасает, \u003Cb\u003Eесли мы теряем много пакетов сразу\u003C\u002Fb\u003E или загружаем ресурсы с блокировкой рендеринга. Миграция соединения зависит от ситуации, и HTTP\u002F3 здесь особо не обгоняет HTTP\u002F2.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nВсё это звучит так, будто игра не стоит свеч. И что теперь? Забыть об HTTP\u002F3 и QUIC? Ни в коем случае! Новые протоколы вряд ли впечатлят пользователей в быстрых (городских) сетях, но определённо принесут пользу \u003Cb\u003Eмобильным пользователям\u003C\u002Fb\u003E и тем, кто вынужден использовать медленные сети.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nДаже, например, в Европе, где мы используем быстрые устройства и высокоскоростные сотовые сети, улучшения заметят от 1 до 10% пользователей в зависимости от продукта. Например, пассажиру поезда срочно нужно найти важную информацию на вашем сайте, но приходится ждать 45 секунд, пока всё загрузится. Я не раз бывал в таких ситуациях, и QUIC пришёлся бы очень кстати.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nА ведь есть страны и регионы, где условия гораздо хуже. Там среднему пользователю приходится хуже, чем 10% самых медленных пользователей в европейской стране, а для одного худшего процента страница вообще может так и не загрузиться. Во \u003Ca href=\"https:\u002F\u002Finfrequently.org\u002F2021\u002F03\u002Fthe-performance-inequality-gap\u002F\"\u003Eмногих частях мира\u003C\u002Fa\u003E веб-производительность — \u003Ca href=\"https:\u002F\u002Fhookedoncode.com\u002F2020\u002F07\u002Fperformance-is-accessibility\u002F\"\u003Eэто вопрос доступности и инклюзивности\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nПоэтому тестировать страницы нужно не только на нашем хорошем оборудовании (а ещё и использовать сервисы вроде \u003Ca href=\"https:\u002F\u002Fwww.webpagetest.org\u002F\"\u003EWebpagetest\u003C\u002Fa\u003E), и поэтому же \u003Cb\u003Eобязательно нужно развернуть QUIC и HTTP\u002F3\u003C\u002Fb\u003E. Если ваши пользователи часто находятся в дороге или не имеют доступа к быстрым сотовым сетям, новые протоколы принесут огромную пользу, даже если на своём MacBook Pro с кабельным интернетом вы ничего особенного не заметите. Обязательно почитайте \u003Ca href=\"https:\u002F\u002Fwww.fastly.com\u002Fblog\u002Fhow-http3-and-quic-help-long-tail-connections\"\u003Eпост Fastly на эту тему\u003C\u002Fa\u003E.\u003Cbr\u002F\u003E\r\n\u003Cbr\u002F\u003E\r\nЕсли и это вас не убедит, просто знайте, что QUIC и HTTP\u002F3 \u003Cb\u003Eбудут активно развиваться и ускоряться\u003C\u002Fb\u003E в следующие несколько лет. Опыт с протоколом на ранних этапах обязательно окупится в будущем, где вы сможете использовать преимущества новых функций сразу после их появления. Наконец, QUIC использует лучшие методы безопасности и конфиденциальности, которые будут полезны абсолютно всем пользователям.\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"http\u002F2"},{"titleHtml":"http2"},{"titleHtml":"http\u002F3"},{"titleHtml":"http3"},{"titleHtml":"quic"},{"titleHtml":"0-rtt"},{"titleHtml":"tcp"},{"titleHtml":"tls"},{"titleHtml":"tls 1.2"},{"titleHtml":"tls 1.3"},{"titleHtml":"udp"},{"titleHtml":"протоколы передачи данных"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fmp\u002Fmn\u002Fhr\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fmp\u002Fmn\u002Fhr\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fsouthbridge\\\u002Fblog\\\u002F583434\\\u002F\"},\"headline\":\"HTTP\\\u002F3: улучшения производительности. Часть 2\",\"datePublished\":\"2021-10-19T18:14:35+03:00\",\"dateModified\":\"2021-10-19T19:26:48+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Polina_Averina\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Фото Jack Hunter, Unsplash.com  После почти пятилетней разработки протокол HTTP\\\u002F3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP\\\u002F3 у...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fcompany\\\u002Fsouthbridge\\\u002Fblog\\\u002F583434\\\u002F#post-content-body\",\"about\":[\"c_southbridge\",\"h_hi\",\"h_webdev\",\"h_s_admin\",\"h_devops\",\"f_develop\",\"f_admin\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F583434\\\u002Ffc35dcb9ceb2a1447e81306c6e4b286c\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fmp\\\u002Fmn\\\u002Fhr\\\u002Fmpmnhrdwnrpnxbk385wmq2-lbq8.jpeg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fho\\\u002Fim\\\u002F7p\\\u002Fhoim7p8gofdx8u8jbjmhyzwhj1q.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fmi\\\u002F9h\\\u002Fri\\\u002Fmi9hriqqmce05xmeaalq81xdmys.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fxr\\\u002Fks\\\u002Fxm\\\u002Fxrksxm0jdltcfcw7vj-erczaxp0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fv7\\\u002Fv1\\\u002Fwx\\\u002Fv7v1wxee63v3t7cphkrstht0ai0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fg6\\\u002F_n\\\u002Fwd\\\u002Fg6_nwda0f8kp219wy6nlnr57e38.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fro\\\u002F_y\\\u002Fqz\\\u002Fro_yqz59ztve8opucqpj0rfhzlm.gif\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fns\\\u002Ftw\\\u002Fyi\\\u002Fnstwyiqkhw4vawkbrsua2ind3ra.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ffs\\\u002Fpy\\\u002Fsv\\\u002Ffspysv-1_m4aaw-fvxmztiiipom.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fdi\\\u002Fpk\\\u002F3f\\\u002Fdipk3fhymwvigy6npltvr0qpqx0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fx1\\\u002Ffj\\\u002F2r\\\u002Fx1fj2ru4oj9grl_a1oplehxmk14.png\"]}","metaDescription":"Фото Jack Hunter, Unsplash.com\r\n\r\nПосле почти пятилетней разработки протокол HTTP\u002F3 наконец приближается к окончательному выпуску. Здесь мы узнаем, как в HTTP\u002F3 улучшилась производительность,...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":""},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{"southbridge":{"alias":"southbridge","imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fcompany\u002F754\u002Fd93\u002F3ca\u002F754d933caeb494c6127add17ff60feb5.png","titleHtml":"Southbridge","descriptionHtml":"Обеспечиваем стабильную работу highload-проектов","relatedData":null,"statistics":{"postsCount":604,"newsCount":29,"vacanciesCount":0,"employeesCount":20,"careerRating":4.31,"subscribersCount":32155,"rating":159.57,"invest":null},"foundationDate":{"year":"2008","month":"02","day":"22"},"location":{"city":{"id":"447159","title":"Москва"},"region":{"id":"1885","title":"Москва и Московская обл."},"country":{"id":"168","title":"Россия"}},"siteUrl":"https:\u002F\u002Fsouthbridge.io","staffNumber":"51–100 человек","registrationDate":"2012-11-15T08:41:16+00:00","representativeUser":{"alias":"aSkobin","fullname":"Антон Скобин"},"contacts":[{"title":"Сайт","url":"https:\u002F\u002Fsouthbridge.io\u002F"}],"settings":{"analyticsSettings":[{"type":"ga","trackingId":"UA-78870906-5"},{"type":"ym","trackingId":"49219348"}],"branding":{"imageUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fbranding\u002F307\u002Ff03\u002F4ad\u002F307f034ad5afe09d902d1991c541ef3d.png","linkUrl":"https:\u002F\u002Fslurm.io\u002Fkubernetes-security?utm_source=habr&utm_medium=top&utm_campaign=kubernetes-security&utm_content=top_20-10-2021&utm_term=habr-top","pixelUrl":""},"status":"active"},"metadata":{"titleHtml":"Southbridge, Москва - Обеспечиваем стабильную работу highload-проектов с 22 февраля 2008 г.","title":"Southbridge, Москва - Обеспечиваем стабильную работу highload-проектов с 22 февраля 2008 г.","keywords":["DevOps","Системное администрирование","IT-инфраструктура","Серверное администрирование","Kubernetes"],"descriptionHtml":"604 статьи от авторов компании Southbridge","description":"604 статьи от авторов компании Southbridge"},"aDeskSettings":null,"careerAlias":"southbridge","maxCustomTrackerLinks":3}},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
