<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/583516\/"},"headline":"Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов","datePublished":"2021-10-14T17:07:10+03:00","dateModified":"2021-10-18T20:22:22+03:00","author":{"@type":"Person","name":"mechkladenets"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей...","url":"https:\/\/habr.com\/ru\/post\/583516\/#post-content-body","about":["h_machine_learning","h_artificial_intelligence","h_natural_language_processing","f_develop","f_popsci"],"image":["https:\/\/habr.com\/share\/publication\/583516\/fec0cbbf227a5e1d025e9ebac2b355a9\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/056\/c0c\/c3c\/056c0cc3ce6aab5a0254bd9594d78067.jpeg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/8e1\/71e\/c1b\/8e171ec1b8407f81ab15400acc2ea13a.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/d80\/f17\/db3\/d80f17db3c9b58c4684f7308def9b5e1.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/69d\/ca5\/b8b\/69dca5b8b680f3538bf8345387fbbd34.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/067\/f16\/022\/067f16022f13dface2701c3f9b2c0696.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/d8a\/02a\/85b\/d8a02a85bec5d81e347fe80fbce6d86c.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/ba4\/0e4\/20f\/ba40e420ffc3e1c1ffd2c885b8f6581e.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/f79\/642\/5af\/f796425afe81d1ca0e84a150c6997b2c.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/8b9\/121\/349\/8b91213499757bbcf6f310919d30c68a.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/422\/580\/313\/422580313810f57e1e333b4155baa961.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/ef2\/eb7\/241\/ef2eb72412121755a4d8a5e943c65326.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/430\/0c5\/d3e\/4300c5d3e208e33afe97f29e146df7cb.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/3bf\/2d8\/c4f\/3bf2d8c4f4dd1060d1e39e6bc2c0d16c.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/36c\/1d1\/cca\/36c1d1cca9842cb1d6e1cd60354d0612.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/025\/e9e\/046\/025e9e04670e7769d00f14879da211cc.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/1c7\/9f1\/1f8\/1c79f11f89f79d06d5dd3af177a4fbe2.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/7a6\/0de\/834\/7a60de834da77decbaf6ff510dde5965.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/aef\/72b\/dbf\/aef72bdbf815ed97b861ad0cf56e7492.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/abc\/128\/cdb\/abc128cdb0c37d6b2ee64a82576bcd0a.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/9a8\/a88\/5c5\/9a8a885c52c31bf1f6448a83ed23c92b.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/497\/669\/8a7\/4976698a70ae8f18d91dc64cb29f0995.jpg","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/dfb\/d6a\/20b\/dfbd6a20bbe3734a5f51cb0c53b35d58.jpg"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="583516" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2021-10-14T14:07:10.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/583516/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/583516/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-vmid="image:href"><link data-vue-meta="ssr" rel="amphtml" href="https://habr.com/ru/amp/post/583516/">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/mechkladenets/" title="mechkladenets" class="tm-user-info__userpic"><div class="tm-entity-image"><svg height="24" width="24" class="tm-svg-img tm-image-placeholder tm-image-placeholder_blue"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <span class="tm-user-info__user"><a href="/ru/users/mechkladenets/" class="tm-user-info__username">
      mechkladenets
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2021-10-14T14:07:10.000Z" title="2021-10-14, 17:07">14  октября   в 17:07</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/machine_learning/" class="tm-article-snippet__hubs-item-link"><span>Машинное обучение</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/artificial_intelligence/" class="tm-article-snippet__hubs-item-link"><span>Искусственный интеллект</span> <!----></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/natural_language_processing/" class="tm-article-snippet__hubs-item-link"><span>Natural Language Processing</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p>Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка (NLP, NLU) для создания реалистичных, человечных разговорных «скиллов». Одним из первых примеров «человечных» диалоговых решений стала Xiaoice от Microsoft, которая обладала навыками дружелюбности. Позже такие компании как Яндекс, Google [1], Mail.ru и другие выпустили на рынок своих голосовых помощников. Однако все они столкнулись с фундаментальной проблемой: их решения хорошо выполняют запросы пользователей, связанные с четкими командами («расскажи новости»), но совершенно не обладают человечными способностями, качествами характера, эмуляцией чувств, эмпатией и поэтому не способны поддерживать человеческий разговор на различные темы. При этом «видимость человечности» часто обеспечивается набором шаблонных фраз и шуток, подходящих практически в любой ситуации (неспецифичных контексту разговора).</p><p>В этой статье мы покажем, как устроен и как работает разработанный нами умный Ранжировщик ответов для нейросеток Трансформер и какой эффект он оказывает на качество разговора любых генеративных чатботов. </p><p>Для того, чтобы решить проблему «человечности» чатботов и голосовых помощников необходимо разработать инфраструктуру базовых навыков (скиллов и стилей) цифровой личности на основе современных архитектур нейронных сетей с возможностью правдоподобного генерирования ответов на запросы пользователей. При этом данная инфраструктура должна обладать возможностью бесшовной интеграции различных архитектур нейронных сетей, что является ключевым элементом, обеспечивающим качество когерентного разговора при переключении скиллов.</p><p>Мы в Аватар Машина считаем, что важность данного исследования обусловлена его центральным местом в науке и исследовании работы мозга и, как следствие, работы нейросетевых архитектур, которые, как известно, во многом калькированно повторяют архитектуру некоторых его отделов. </p><p>Например, директор Научно-координационного совета Центра науки и технологий искусственного интеллекта МФТИ Сергей Шумский в своей книге «Машинный интеллект. Очерки по теории машинного обучения и искусственного интеллекта» [2]  отмечает важность повторения, или, более верно «воссоздания» биологической архитектуры различных отделов мозга в искусственных нейронных сетях. В книге он предлагает подход к созданию «сильного» искусственного интеллекта с использованием принципов работы человеческого мозга. Благодаря правильной архитектуре исследователи смогли бы добиться и аналогичных когнитивных свойств искусственных систем. Пока же уровень развития когнитивных свойств в сфере Conversational Ai (разговорного искусственного интеллекта) является довольно низким: слабая память в нейросетях LSTM, простые seq2seq модели, даже эмерджентный феномен «внимания» (attention) в самых современных нейросетях трансформер довольно ограниченно моделирует то, как человек в реальности работает с объектами, обращает внимание и запоминает важные факты в потоке событий.</p><p>Доктор Alan D. Thompson, являющийся экспертом в ИИ на семинаре  «Новая нерелевантность интеллекта» [3]  в августе 2021го года представил свой взгляд на разрозненность моделей нейросетей и то, как они соответствуют современным представлениям о работе мозга. На рисунке ниже представлена таблица соответствия различных когнитивных способностей человека и тех отделов мозга, которые за них отвечают. В частности за разговор в данном сравнении представлены ответственными чатботы от Facebook Ai – BlenderBot (первой версии) [4] и система разговорного ИИ с интерактивом от Google – LaMDa [5]. Однако данные системы, несмотря на всю свою сложную структуру обладают существенным недостатком – они работают, используя раздельные пайплайны из разных нейросетей, в результате чего достигнуть эмерджентного эффекта невозможно, ведь в таких системах модули и компоненты являются отдельными не архитектурно, как в нейросетях, а структурно – то есть они объединены программно, через API и вызовы функций, что хорошо работает инженерно, но не позволяет появиться в такой системе новым свойствам.</p><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" alt="Рисунок 1. Модели ИИ и соответствующие им разделы мозга" title="Рисунок 1. Модели ИИ и соответствующие им разделы мозга" width="1280" height="720" data-src="https://habrastorage.org/getpro/habr/upload_files/056/c0c/c3c/056c0cc3ce6aab5a0254bd9594d78067.jpeg" data-blurred="true"/><figcaption>Рисунок 1. Модели ИИ и соответствующие им разделы мозга</figcaption></figure><p>В этой разработке мы учитывали недостатки существующих, лучших на сегодняшний день разговорных систем, в том числе и команды разработки бота ChirpyCardinal [6] (2е место в конкурсе от компании Amazon Alexa Prize), проекта AliceMind [7] от китайской компании Alibaba. Очень хорош также и чатбот от Сбера [<a href="https://habr.com/ru/company/sberbank/blog/524522/" rel="noopener noreferrer nofollow"><u>статья</u></a>] - и все же в некоторых сеттингах мы замечали разрывы в логике поддержания разговора, при том, что в целом ответы на каждую реплику у него очень разумные.</p><p><em>Итак, постановка исследовательской задачи такая: разработать систему ранжирования реплик, генерируемых чатботом так, чтобы она работала когнитивно близко к тому, как человек выбирает ту или иную реплику в контексте разговора – как правило, человек рассматривает несколько вариантов ответных реплик, учитывая всю историю общения, важные факты и согласованность по тематике. Именно так и должна работать система ранжирования – ведь сейчас генераторы в нейросетях трансформер устроены куда более просто.</em></p><p>На данный момент очень актуальна проблема генерации текста в нейросетевых генеративных ботах, в частности, построенных на базе GPT(<em>Generative Pre-trained Transformer</em>)[8]. Генерация ведется на уровне токенов, а выбирать следующий токен в последовательности можно разными способами, например, при помощи генератора случайных чисел, где нейросеть задает для него распределение вероятностей на каждом шаге. Также существует стратегия выбирать на каждом шаге токен, которому соответствует наибольшая вероятность, или использовать алгоритмы на вроде метода поиска по лучу (beam search). [9] Этими методами возможно сгенерировать несколько версий ответов на один вопрос или реплику. Ранжирование версий ответов позволяет улучшать качество генерации, делая выход модели более согласованным по смыслу(тематике) с вопросом или контекстом. Предложенный в этой работе алгоритм ранжирования работает по следующему принципу: текст вопроса заменяется на вектор признаков, аналогично векторизуется каждая версия ответа, рассчитываются расстояния между вектором вопроса или контекста и каждым вектором ответа, таким образом, чтобы ответ с нулевым индексом был наиболее подходящим по тематике к вопросу.</p><p>В нашей разработке мы предлагаем алгоритм векторизации текста на базе нейронной сети с тремя функциями ошибки, такими как ошибка классификации, ошибка моделирования распределения (дивергенция Кульбака-Лейблера) и ошибка дисперсии (отклонение логарифма дисперсии от вектора нулей), что позволяет преобразовывать тексты в вектора без разрывов в пространстве признаков.</p><p><em>Далее рассмотрим основные шаги исследования: набор данных, алгоритм, векторизацию.</em> </p><h2>Описание набора данных</h2><p>Для исследования было выбрано 2 набора данных:</p><ul><li><p>Первый набор данных использовался для предварительной оценки модели, включает в себя девять тем: игры, программное обеспечение, искусство, технологии, отношения, хобби, психология, облачные технологии, языки программирования.</p></li><li><p>Второй набор данных представлял собой 139 тысяч сэмплов текстов, разделенных на 66 классов (тем), которые чаще всего использовались в общении с ботом, основные темы: игры, книги, программное обеспечение, вселенная, футбол, единоборства, искусство, технологии, отношения и т.п.  </p></li></ul><p>Данный датасет, его распределение тематик и объем был использован потому, что по нашим наблюдениям именно эти темы наиболее часто встречаются в живом разговоре, они достаточно полно представлены в Интернете и датасет относительно легко собрать из открытых источников в нужно объеме. </p><h2>Описание алгоритма</h2><p>Алгоритм ранжирования представлен на рисунке 23. Текст поступает в блок предварительной обработки, который преобразует слова текста в токены. Нейронная сеть блока векторизации формирует вектор фиксированной размерности из последовательности токенов. Все тексты, которые должны быть ранжированы векторизуются вышеописанным способом и добавляются в массив структур вектор-текст. После чего алгоритм ранжирования сортирует векторы по неубыванию расстояния и текст, соотнесенный с вектором с нулевым индексом является с точки зрения модели наиболее подходящим по тематике к тексту вопроса.</p><p>Основное требование к пространству признаков следующее: близкие по смыслу тексты должны быть преобразованы в близкие по некоторой метрике точки (векторы).</p><figure class=""><img src="/img/image-loader.svg" alt="Рисунок 2. Общая структура алгоритма ранжирования" title="Рисунок 2. Общая структура алгоритма ранжирования" height="663" data-src="https://habrastorage.org/getpro/habr/upload_files/8e1/71e/c1b/8e171ec1b8407f81ab15400acc2ea13a.png" data-width="394"/><figcaption>Рисунок 2. Общая структура алгоритма ранжирования</figcaption></figure><h2>Предварительная обработка текста</h2><p>На первом этапе текст стандартизируется, т.е. из него удаляются все знаки препинания и специальные символы, множественные пробелы заменяются на одинарные, также удаляются стоп-слова, слова заменяются на соответствующие им леммы. Мы рассмотрели две стратегии токенизации:</p><p>а) токенизация на уровне лемм, и </p><p>б) токенизация при помощи предварительно обученного токенизатора BPE[10], используемого в GPT2[11].</p><p>Во втором случае возможна работа с текстами, содержащими неизвестные слова и с опечатками. В случае работы с леммами составляется словарь из 30 тыс. наиболее часто встречающихся лемм. Блок-схема модуля предварительной обработки текстов показана на рисунке.</p><figure class=""><img src="/img/image-loader.svg" alt="Рисунок 3. Модуль предварительной обработки текста" title="Рисунок 3. Модуль предварительной обработки текста" height="423" data-src="https://habrastorage.org/getpro/habr/upload_files/d80/f17/db3/d80f17db3c9b58c4684f7308def9b5e1.png" data-width="242"/><figcaption>Рисунок 3. Модуль предварительной обработки текста</figcaption></figure><h2>Векторизация</h2><p>Мы разработали две стратегии векторизации: выход предпоследнего слоя нейросетевого классификатора и выход предсказания математического ожидания в вариационном классификаторе, он описан ниже.</p><p>Входной слой — это слой встраивания, он ставит вектор в соответствие каждому индексу. Последовательность индексов заменяется на матрицу. Изначально векторы либо выбираются случайными, либо задаются предварительно обученные, а далее, во время обучения сети могут обучаться вместе со всей сетью при помощи обратного распространения ошибки (backpropagation).</p><p>    В данной работе в качестве классификаторов были исследованы следующие сети: </p><ul><li><p>одномерная сверточная,</p></li><li><p>полносвязная,</p></li><li><p>рекуррентная,</p></li><li><p>гибридная: содержащая как сверточные, так и рекуррентные слои. </p></li></ul><p>Одномерные сверточные и рекуррентные нейронные сети хорошо зарекомендовали себя для работы с последовательностями[12], в том числе и с текстами. [13, 14] Исследование проводилось на данных из первого датасета содержащего 9 классов (тем), описанного выше в подразделе Описание набора данных.</p><h2>Результаты исследования</h2><p>Ниже, на рисунке 4, представлены графики обучения некоторых архитектур нейронных сетей из этого исследования, без предварительно обученных векторов встраивания. А именно, одномерной сверточной сети, полносвязной, LSTM, и гибридной, содержащей, как одномерные сверточные слои, так и LSTM ячейки.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания" title="Рисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания" height="792" data-src="https://habrastorage.org/getpro/habr/upload_files/69d/ca5/b8b/69dca5b8b680f3538bf8345387fbbd34.png" data-width="1133"/><figcaption>Рисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания</figcaption></figure><p>На рисунке 5 показаны графики обучения следующих архитектур (одномерной сверточной сети с 3мя сверточными слоями, одномерной сверточной сети с одним сверточным слоем и LSTM сети) с предварительно обученными векторами встраивания.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани" title="Рисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани" height="860" data-src="https://habrastorage.org/getpro/habr/upload_files/067/f16/022/067f16022f13dface2701c3f9b2c0696.png" data-width="1160"/><figcaption>Рисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани</figcaption></figure><p>Результаты тестирования нейронных сетей сведены в таблицу 1, все замеры выполнены на валидационной выборке.</p><div><div class="table"><table><tbody><tr><td><p>Номер эксперимента</p></td><td><p>Вероятность правильного распознавания</p><p>(Accuracy)</p></td><td><p>Ошибка на валидационных данных</p><p>(Перекрестная энтропия)</p></td></tr><tr><td colspan="3"><p>Вектора встраивания инициализированы случайными числами</p></td></tr><tr><td><p>Сверточная сеть №1</p></td><td><p>71.05%</p></td><td><p>0.8898</p></td></tr><tr><td><p>Полносвязная</p></td><td><p>74.57%</p></td><td><p>0.767</p></td></tr><tr><td><p>Сверточная сеть №2</p></td><td><p>74.44%</p></td><td><p>0.7862</p></td></tr><tr><td><p>LSTM</p></td><td><p>73.52%</p></td><td><p>0.8146</p></td></tr><tr><td><p>GRU</p></td><td><p>73.19%</p></td><td><p>0.8177</p></td></tr><tr><td><p>CNN+LSTM</p></td><td><p>71.46%</p></td><td><p>0.8886</p></td></tr><tr><td colspan="3"><p>Пред. обученные вектора встраивания (Word2Vec)</p></td></tr><tr><td><p>Сверточная сеть №1</p></td><td><p>69.38%</p></td><td><p>0.8714</p></td></tr><tr><td><p><strong>Сверточная сеть №2</strong></p></td><td><p><strong>75.11%</strong></p></td><td><p><strong>0.7357</strong></p></td></tr><tr><td><p>LSTM</p></td><td><p>73.77%</p></td><td><p>0.8293</p></td></tr></tbody></table></div></div><p>Таблица 1. Результаты тестирования различных архитектур</p><p>В конечном итоге наилучший результат показывает Сверточная сеть №2, вероятность правильного распознавания у нее составила 75.11%.</p><p>В результате описанного в данном разделе исследования была разработана модель ранжировщика реплик(ответов) генеративной модели. Данная модель является прототипом модели выбора логичного ответа у человека, однако, как мы рассмотрим далее в следующем разделе есть несколько вопросов, касающихся эффективности ее срабатывания в различных контекстах разговора – плавности переключения тематик и их согласованности внутри самих сгенерированных реплик.</p><h2>Обучение на новой выборке</h2><p>Для дальнейшего обучения на втором наборе данных в 139 тыс. реплик, разделенных на 66 классов, была выбрана одномерная сверточная сеть с одним сверточным и одним полносвязным слоем, т.к. она обеспечивала наивысшую вероятность правильного распознавания.  График обучения сверточной сети для распознавания 66 классов представлен на рисунке 27. </p><figure class=""><img src="/img/image-loader.svg" alt="Рисунок 6. График обучения нейронной сети" title="Рисунок 6. График обучения нейронной сети" height="265" data-src="https://habrastorage.org/getpro/habr/upload_files/d8a/02a/85b/d8a02a85bec5d81e347fe80fbce6d86c.png" data-width="391"/><figcaption>Рисунок 6. График обучения нейронной сети</figcaption></figure><p>Вероятность правильного распознавания на валидационных данных составила 64.01%</p><p>Ниже представлена визуализация векторов, получаемых из текстов, на скрытом слое: на рисунке изображены все 139 тысяч текстовых реплик, одна текстовая  реплика — одна точка, цветом отмечены классы. На рисунке 7 слева сделана проекция векторного пространства на 2 оси, на рисунке 7 справа — визуализация в 3х мерном пространстве. Если рассмотреть распределение векторов после векторизации текстов, то можно заметить, что их распределение имеет довольно сложный вид и не обеспечивает плавного перехода между темами.</p><p><em>Пример. Представьте, что вы говорите с собеседником на тему отношений, и постепенно тема меняется на политику. На какую тему должна быть реплика после смены темы разговора? Про отношения, так как контекст содержит много реплик с этим классом или про политику, так как это новая актуальная тема, а может быть нужна смесь? Здесь нет однозначного ответа. Если темы различаются между собой сильно, то они попадут в разные «лучи салюта» - чатбот не сможет сгенерировать реплику, которая бы соответствовала обеим тематикам. Правда, это мы наблюдаем в комментариях почти к любому социальному ролику или статье - разброс тем даже внутри одной отрасли колоссальный и поэтому часто комментарии людей выглядят оторванными от контекста.</em></p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора" title="Рисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора" height="667" data-src="https://habrastorage.org/getpro/habr/upload_files/ba4/0e4/20f/ba40e420ffc3e1c1ffd2c885b8f6581e.png" data-width="1535"/><figcaption>Рисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора</figcaption></figure><p>Для реализации более плавного перехода между темами была введена дополнительная функция потерь, известная как дивергенция Кульбака – Лейблера [14], используемая в вариационных автокодировщиках [15].  Также была введена составляющая функции потерь, отвечающая за форму и размер области в пространстве признаков, ошибка которой увеличивается с ростом отклонения логарифма дисперсии от вектора, состоящего из нулей. </p><p>Дивергенция Кульбака – Лейблера показывает отклонение полученного распределения от ожидаемого. В данной задаче мы хотим получить гауссово распределение, т.е. чтобы наше признаковое пространство было в виде гиперсферы.</p><p>Таким образом, мы ожидаем получить гиперсферы без разрывов, а получаем что-то другое — так вот этот лосс показывает насколько сильно мы отклонились. А производная от него по параметрам модели позволяет настраивать модель так, чтобы она «выдавала» именно гиперсферы. </p><p>Ошибка Кульбака-Лейблера рассчитывается по следующей формуле: в данной формуле расписан след и определитель диагональной ковариационной матрицы, </p><figure class="full-width "><img src="/img/image-loader.svg" height="133" data-src="https://habrastorage.org/getpro/habr/upload_files/f79/642/5af/f796425afe81d1ca0e84a150c6997b2c.png" data-width="1107"/><figcaption></figcaption></figure><p>— коэффициент вклада ошибки Кульбака – Лейблера в общую функцию потерь. </p><p>Ошибка дисперсии рассчитывается по формуле:</p><figure class="full-width "><img src="/img/image-loader.svg" height="104" data-src="https://habrastorage.org/getpro/habr/upload_files/8b9/121/349/8b91213499757bbcf6f310919d30c68a.png" data-width="755"/><figcaption></figcaption></figure><p>В качестве ошибки классификации была использована категориальная перекрестная энтропия,</p><figure class="full-width "><img src="/img/image-loader.svg" height="138" data-src="https://habrastorage.org/getpro/habr/upload_files/422/580/313/422580313810f57e1e333b4155baa961.png" data-width="656"/><figcaption></figcaption></figure><p>Коэффициенты kKL, kVar, kH введены для настройки модели. В данной работе они соответственно равны 7, 2, 1.</p><p>На рисунке 8 показана блок-схема классификатора, для векторизации используется выход предсказывающий вектор математического ожидания генератора случайных чисел с гауссовым распределением.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 8. Блок-схема классификатора" title="Рисунок 8. Блок-схема классификатора" height="844" data-src="https://habrastorage.org/getpro/habr/upload_files/ef2/eb7/241/ef2eb72412121755a4d8a5e943c65326.png" data-width="567"/><figcaption>Рисунок 8. Блок-схема классификатора</figcaption></figure><p>На рисунке 9 показана зависимость различных составляющих функции ошибки от эпохи обучения. По причине того, что масштаб изменений других составляющих функции потерь сильно отличается от масштаба изменений отклонения логарифма дисперсии, ошибка дисперсии вынесена в другом масштабе на рисунок 10.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи" title="Рисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи" height="551" data-src="https://habrastorage.org/getpro/habr/upload_files/430/0c5/d3e/4300c5d3e208e33afe97f29e146df7cb.png" data-width="1380"/><figcaption>Рисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи</figcaption></figure><p>Ниже представлена визуализация пространства признаков, на рисунке слева — проекция на две оси, на рисунке справа — на три.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания" title="Рисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания" height="555" data-src="https://habrastorage.org/getpro/habr/upload_files/3bf/2d8/c4f/3bf2d8c4f4dd1060d1e39e6bc2c0d16c.png" data-width="1409"/><figcaption>Рисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания</figcaption></figure><p>Рассмотрим далее параметры при использовании в качестве токенизатора предварительно обученного токенизатора BPE. На рисунке 12 показана зависимость различных составляющих функции ошибки от эпохи обучения, также на рисунке 13, продемонстрированы проекция пространства признаков на две и три оси соответственно, параметры функции ошибки следующие, </p><figure class="full-width "><img src="/img/image-loader.svg" height="95" data-src="https://habrastorage.org/getpro/habr/upload_files/36c/1d1/cca/36c1d1cca9842cb1d6e1cd60354d0612.png" data-width="900"/><figcaption></figcaption></figure><p>где BS размер мини-пакета.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 12. Зависимость составляющих ошибки обучения от эпохи" title="Рисунок 12. Зависимость составляющих ошибки обучения от эпохи" height="431" data-src="https://habrastorage.org/getpro/habr/upload_files/025/e9e/046/025e9e04670e7769d00f14879da211cc.png" data-width="1058"/><figcaption>Рисунок 12. Зависимость составляющих ошибки обучения от эпохи</figcaption></figure><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/1c7/9f1/1f8/1c79f11f89f79d06d5dd3af177a4fbe2.jpg" alt="Рисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания" title="Рисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания" width="1491" height="689" data-src="https://habrastorage.org/getpro/habr/upload_files/1c7/9f1/1f8/1c79f11f89f79d06d5dd3af177a4fbe2.jpg" data-blurred="true"/><figcaption>Рисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания</figcaption></figure><p><strong>Ключевым элементом данного исследования является выбор метрики и архитектуры для алгоритма ранжирования.</strong></p><p>Наилучшая метрика должна обеспечивать лучшую точность при ее использовании в методе ближайшего соседа в задаче классификации, т.к. это означает, что при ранжировании в самом верху списка (с нулевым индексом) окажется текст той же темы, что и текст на входе. Результаты тестирования различных метрик, на двух последних архитектурах с токенизацией на уровне лемм сведены в таблицу 2.</p><div><div class="table"><table><tbody><tr><td rowspan="2"><p>Метрика</p></td><td colspan="2"><p>Без использования дивергенции Кульбака-Лейблера и ошибки дисперсии</p></td><td colspan="2"><p>С использованием дивергенции Кульбака-Лейблера и ошибки дисперсии</p></td></tr><tr><td><p>F1 микро усреднение</p></td><td><p>F1 макро усреднение</p></td><td><p>F1 микро усреднение</p></td><td><p>F1 макро усреднение</p></td></tr><tr><td><p>Евклидова</p></td><td><p>78.2%</p></td><td><p><strong>67.74%</strong></p></td><td><p><strong>90.2%</strong></p></td><td><p><strong>82.26%</strong></p></td></tr><tr><td><p>Манхэттена</p></td><td><p>78.1%</p></td><td><p>66.04%</p></td><td><p>89.7%</p></td><td><p>80.67%</p></td></tr><tr><td><p>Чебышёва</p></td><td><p>74.3%</p></td><td><p>60.86%</p></td><td><p>88.6%</p></td><td><p>79.83%</p></td></tr><tr><td><p>Минковского p=3</p></td><td><p>78%</p></td><td><p>66.9%</p></td><td><p>89.9%</p></td><td><p>81.53%</p></td></tr><tr><td><p>Минковского p=4</p></td><td><p>77.3%</p></td><td><p>65.56%</p></td><td><p>89.8%</p></td><td><p>81.23%</p></td></tr><tr><td><p>Минковского p=5</p></td><td><p>76.4%</p></td><td><p>63.97%</p></td><td><p>89.7%</p></td><td><p>80.9%</p></td></tr><tr><td><p>Минковского p=6</p></td><td><p>77%</p></td><td><p>64.65%</p></td><td><p>89.4%</p></td><td><p>80.25%</p></td></tr><tr><td><p>Минковского p=7</p></td><td><p>76.7%</p></td><td><p>64.48%</p></td><td><p>89.2%</p></td><td><p>80.01%</p></td></tr><tr><td><p>Минковского p=8</p></td><td><p>76.4%</p></td><td><p>64.18%</p></td><td><p>89.1%</p></td><td><p>80.02%</p></td></tr><tr><td><p>Минковского p=9</p></td><td><p>76.3%</p></td><td><p>63.79%</p></td><td><p>89.1%</p></td><td><p>80.02%</p></td></tr><tr><td><p>Канберры</p></td><td><p>76.5%</p></td><td><p>64.54%</p></td><td><p>83.3%</p></td><td><p>72.25%</p></td></tr><tr><td><p>Стандартизированная Евклидова метрика</p></td><td><p>77.0%</p></td><td><p>64.65%</p></td><td><p>87.0%</p></td><td><p>78.8%</p></td></tr><tr><td><p>Несходство Брея-Кертиса</p></td><td><p><strong>79.1%</strong></p></td><td><p>67.02%</p></td><td><p>89.3%</p></td><td><p>80.66%</p></td></tr></tbody></table></div></div><p>Таблица 2. Результат тестирования метрик, токенизация на уровне лемм </p><p>Сравнение различных режимов обучения, а также сравнение с векторизацией при помощи многоязычного BERT’а, без дообучения на нашем наборе данных, с использованием предварительно обученного токенизатора BPE, сведены в таблицу 3, максимальное число токенов в последовательности составляет 85, вероятность правильного распознавания оценивалась, как усредненная по 66 классам.   </p><div><div class="table"><table><tbody><tr><td><p></p></td><td colspan="2"><p><strong>Обучено на лемматизированных</strong></p></td><td><p><strong>Обучено на не лемматизированных</strong></p></td><td><p><strong>Bert</strong></p></td></tr><tr><td><p></p></td><td><p>Датасет без лемматизации</p></td><td><p>Датасет с лемматизацией</p></td><td><p></p></td><td><p></p></td></tr><tr><td><p>Евклидова</p></td><td><p>50.6%</p></td><td><p>82.9%</p></td><td><p>62.42%</p></td><td><p>26.4%</p></td></tr><tr><td><p>Манхэттен</p></td><td><p>49.9%</p></td><td><p>82.3%</p></td><td><p>62.23%</p></td><td><p>26.0%</p></td></tr><tr><td><p>Чебышёва</p></td><td><p>46.5%</p></td><td><p>80.1%</p></td><td><p>61.74%</p></td><td><p>20.3%</p></td></tr><tr><td><p>Несходство Брея-Кертиса</p></td><td><p><strong>51.3%</strong></p></td><td><p><strong>82.3%</strong></p></td><td><p><strong>62.74%</strong></p></td><td><p><strong>28.6%</strong></p></td></tr></tbody></table></div></div><p>Таблица 3. Результат тестирования метрик, токенизация на уровне байт </p><p>Ниже на рисунке представлены фрагменты программного кода реализации Ранжировщика, в качестве скилла в экосистеме скиллов и стилей: на рисунке 14 класс Ranker и его методы подгрузки параметров модели, удаление стоп-слов. Полностью код мы не раскрываем.</p><figure class="full-width "><img src="/img/image-loader.svg" alt="Рисунок 14. Фрагмент кода: класс Ранжировщик" title="Рисунок 14. Фрагмент кода: класс Ранжировщик" height="1020" data-src="https://habrastorage.org/getpro/habr/upload_files/7a6/0de/834/7a60de834da77decbaf6ff510dde5965.png" data-width="1374"/><figcaption>Рисунок 14. Фрагмент кода: класс Ранжировщик</figcaption></figure><h2>Результаты диалоговой модели и тестирование на разумность</h2><p>Как видно из таблицы 2, наилучшее качества ранжировщика обеспечивается использованием в качестве модуля векторизации классификатора с использованием моделирования распределения посредством введения дивергенции Кульбака — Лейблера и контроля дисперсии. </p><p>Евклидова метрика обеспечивает наилучшее качество ранжирования, при использовании токенизации на уровне лемм, а при токенизации на уровне байт, наилучшее качество было получено при использовании «несходства Брея-Кертиса». Объем памяти занимаемой нашей моделью составляет всего 10 Мб. </p><p>Ранжирование версий ответов позволяет улучшать качество генерации, делая выход модели более согласованным по смыслу(тематике) с вопросом или контекстом. Важно отметить, что согласование работает с учетом всего контекста разговора, а не только последней реплики пользователя.</p><p>Поскольку бенчмаркинг (benchmarking) диалоговых моделей является сейчас активной исследовательской темой и на сегодняшний день еще не существует индустриального стандарта сравнения общения чатботов – мы оценивали:</p><ol><li><p>метрику SSA от Google [1] (Sensibleness and Specificity Average – среднее между специфичностью и релевантностью ответа в данном контексте)  и</p></li><li><p>общий показатель вовлеченности и интереса общения, выражающийся в количестве пар реплик общения одного пользователя за сессию (промежуток времени между репликами не более 1 минуты) усреднённый по всем пользователям.</p></li></ol><p>Мы расскажем о сеттинге тестирования позже. Рассмотрим сначала диалоговую модель без ранжировщика и оценим в целом логику его ответов на рисунке ниже:</p><figure class="float full-width "><img src="/img/image-loader.svg" alt="Рисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы " title="Рисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы " height="1142" data-src="https://habrastorage.org/getpro/habr/upload_files/aef/72b/dbf/aef72bdbf815ed97b861ad0cf56e7492.png" data-width="791"/><figcaption>Рисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы </figcaption></figure><p> </p><p>В сеттинге выше модель выбирает ответ используя beam search, однако какое бы число лучей ни было использовано, это все равно не позволяет работать с логикой ответа на уровне целого предложения – ведь генерация происходит по токенам.</p><p>Ответы при этой похожи на ответы Яндекс Алисы: они иногда смешные, но их основное свойство это неспецифичность, то есть, как правило, такие ответы подходят под многие контексты сразу и именно поэтому кажутся пользователям, общающимся с ботом слишком общими, не содержащими новой полезной информации и отсылок к предыдущим репликам.</p><p>Еще одно свойство ответов: они в целом следуют теме разговора, но сами темы имеют часто нечеткие границы и поэтому часто вместо ответа на вопрос или исполнения просьбы (разные модальности) модель генерирует ответ по теме, но полностью противоречивый по содержанию.</p><h2>Наша диалоговая модель</h2><figure class="float full-width "><img src="/img/image-loader.svg" alt="Рисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные" title="Рисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные" height="1534" data-src="https://habrastorage.org/getpro/habr/upload_files/abc/128/cdb/abc128cdb0c37d6b2ee64a82576bcd0a.png" data-width="860"/><figcaption>Рисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные</figcaption></figure><p>Диалог с моделью, имеющей ранжировщик и личность(мы опишем ее в другой статье) существенно отличается в лучшую сторону по следующим характеристическим параметрам:</p><ol><li><p>Ответы специфичные: они относятся к данной конкретной ситуации, возникшей в контексте разговора.</p></li><li><p>Ответы релевантные: они разумны и логичны, семантически согласованы и грамматически верны: если пользователь задавал вопрос, то модель дает ответ. </p></li><li><p>У бота есть личность, он отыгрывает девушку и это прослеживается в глаголах и местоимениях женского рода(«люблю ходить одна»)</p></li><li><p>Бот вежливый и обладает знаниями (хотя боту и не обязательно быть вежливым) и поддерживает более качественное общение на темы о психологии, сексе, отношениях, потому что для обучения использовался преимущественно такой датасет. </p></li></ol><p>В процессе ранжировщик рассматривал в том числе и такие варианты генерации:</p><ol><li><p>«И мне» (слишком короткий и неспецифичный)</p></li><li><p>«А мне холодно» (нерелевантный теме разговора)Однако выбран был наиболее согласованный по контексту и тематике вариант:</p></li><li><p>«У меня такая же проблема, только еще зима не закончилась. Так хочется тепла и солнца..»</p></li></ol><p>Ниже представлены тематически другие разговоры с разработанной моделью и скиллами ранжировщика и личности.</p><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/9a8/a88/5c5/9a8a885c52c31bf1f6448a83ed23c92b.jpg" alt="Рисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации" title="Рисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации" width="1297" height="914" data-src="https://habrastorage.org/getpro/habr/upload_files/9a8/a88/5c5/9a8a885c52c31bf1f6448a83ed23c92b.jpg" data-blurred="true"/><figcaption>Рисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации</figcaption></figure><figure class="full-width "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/497/669/8a7/4976698a70ae8f18d91dc64cb29f0995.jpg" alt="Рисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры" title="Рисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры" width="1188" height="1079" data-src="https://habrastorage.org/getpro/habr/upload_files/497/669/8a7/4976698a70ae8f18d91dc64cb29f0995.jpg" data-blurred="true"/><figcaption>Рисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры</figcaption></figure><figure class="float "><img src="https://habrastorage.org/r/w780q1/getpro/habr/upload_files/dfb/d6a/20b/dfbd6a20bbe3734a5f51cb0c53b35d58.jpg" alt="Рисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)" title="Рисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)" width="416" height="899" data-src="https://habrastorage.org/getpro/habr/upload_files/dfb/d6a/20b/dfbd6a20bbe3734a5f51cb0c53b35d58.jpg" data-blurred="true"/><figcaption>Рисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)</figcaption></figure><p>Разработанная модель Ранжировщика является в целом хорошим научным результатом и развитием идеи выбора логичного и разумного ответа в зависимости от контекста разговора. </p><p>Модель является прототипом скилла когнитивной способности человека к выбору логичного продолжения разговора в соответствии с целью, состоянием, эмоциями и другими параметрами, которые являются внешними, но которые проявлены в разговоре. Модель имеет малый размер (10мб.), легко обучается и не требует огромных массивов датасетов для обучения на новые тематики. Наилучшее качества ранжировщика обеспечивается использованием в качестве модуля векторизации классификатора с использованием моделирования распределения посредством введение дивергенции Кульбака — Лейблера и контроля дисперсии. Евклидова метрика обеспечивает наилучшее качество ранжирования, при использовании токенизации на уровне лемм, при токенизации на уровне байт, наилучшее качество было получено при использовании «несходства Брея-Кертиса». </p><p>Наш бот полностью готов к коммерческому внедрению и уже продается на рынке. Результаты разработки мы уже докладывали на конференции по искусственному интеллекту Ai-men. Подроднее о боте можно узнать на <a href="http://graphgrail.com/ru/" rel="noopener noreferrer nofollow">сайте</a>.</p><details class="spoiler"><summary>Список литературы</summary><div class="spoiler__content"><ol><li><p>Towards a Human-like Open-Domain Chatbot [Электронный ресурс] Режим доступа <a href="https://arxiv.org/abs/2001.09977" rel="noopener noreferrer nofollow"><u>https://arxiv.org/abs/2001.09977</u></a> свободный. - Загл. с экрана (дата обращения: 1.02.2021).</p></li><li><p>Сергей Шумский. Машинный интеллект. Очерки по теории машинного обучения и искусственного интеллекта. — изд. первое, — М.: Наука, 2020. — 335 с. <a href="https://www.litres.ru/sergey-shumskiy/mashinnyy-intellekt-ocherki-po-teorii-mashinnogo-48958628/" rel="noopener noreferrer nofollow"><u>https://www.litres.ru/sergey-shumskiy/mashinnyy-intellekt-ocherki-po-teorii-mashinnogo-48958628/</u></a> </p></li><li><p>Alan D. Thompson. AI + the human brain. The new irrelevance of intelligence  [Электронный ресурс] <a href="https://lifearchitect.ai/brain/" rel="noopener noreferrer nofollow"><u>https://lifearchitect.ai/brain/</u></a> - Загл. с экрана (дата обращения: 10.08.2021)</p></li><li><p>Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston // Recipes for building an open-domain chatbot // April 7, 2020 // URL <a href="https://arxiv.org/abs/2004.13637" rel="noopener noreferrer nofollow"><u>https://arxiv.org/abs/2004.13637</u></a> </p></li><li><p>LaMDA: our breakthrough conversation technology. [Электронный ресурс] <a href="https://blog.google/technology/ai/lamda/" rel="noopener noreferrer nofollow"><u>https://blog.google/technology/ai/lamda/</u></a> - Загл. с экрана (дата обращения: 10.08.2021)</p></li><li><p>Welcome to Chirpy Cardinal. [Электронный ресурс]  <a href="https://stanfordnlp.github.io/chirpycardinal/" rel="noopener noreferrer nofollow"><u>https://stanfordnlp.github.io/chirpycardinal/</u></a> - Загл. с экрана (дата обращения: 10.08.2021)</p></li><li><p>AliceMind: ALIbaba's Collection of Encoder-decoders from MinD (Machine IntelligeNce of Damo) Lab. [Электронный ресурс]   <a href="https://github.com/alibaba/AliceMind" rel="noopener noreferrer nofollow"><u>https://github.com/alibaba/AliceMind</u></a> - Загл. с экрана (дата обращения: 10.08.2021)</p></li><li><p>Jianfeng Gao, Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, Heung-Yeung Shum // Robust Conversational AI with Grounded Text Generation // September 7, 2020 // URL <a href="https://arxiv.org/pdf/2009.03457.pdf" rel="noopener noreferrer nofollow"><u>https://arxiv.org/pdf/2009.03457.pdf</u></a></p></li><li><p>Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktaschel, Vassilis Plachouras, Fabrizio Silvestri, Sebastian Riedel // How Decoding Strategies Affect the Verifiability of Generated Text // 29 Sep 2020// URL <a href="https://arxiv.org/pdf/1911.03587.pdf" rel="noopener noreferrer nofollow"><u>https://arxiv.org/pdf/1911.03587.pdf</u></a> </p></li><li><p>Serkan Kiranyaz, Onur Avci, Osama Abdeljaber, Turker Ince, Moncef Gabbouj, Daniel J. Inman // 1D Convolutional Neural Networks and Applications – A Survey// URL: <a href="https://arxiv.org/ftp/arxiv/papers/1905/1905.03554.pdf" rel="noopener noreferrer nofollow"><u>https://arxiv.org/ftp/arxiv/papers/1905/1905.03554.pdf</u></a></p></li><li><p>Marc Moreno Lopez, Jugal Kalita // Deep Learning applied to NLP // 9 Mar 2017// URL <a href="https://arxiv.org/pdf/1703.03091.pdf" rel="noopener noreferrer nofollow"><u>https://arxiv.org/pdf/1703.03091.pdf</u></a> </p></li><li><p>Wenpeng Yin, Katharina Kann, Mo Yu, Hinrich Schütze // Comparative Study of CNN and RNN for Natural Language Processing // 7 Feb 2017 // URL <a href="https://arxiv.org/abs/1702.01923" rel="noopener noreferrer nofollow"><u>https://arxiv.org/abs/1702.01923</u></a> </p></li><li><p>Raphael Shu, Hideki Nakayama // COMPRESSING WORD EMBEDDINGS VIA DEEP COMPOSITIONAL CODE LEARNING // 17 Nov 2017 // URL <a href="https://arxiv.org/pdf/1711.01068.pdf" rel="noopener noreferrer nofollow"><u>https://arxiv.org/pdf/1711.01068.pdf</u></a> </p></li><li><p>Kullback S. Information Theory and Statistics. — John Wiley &amp; Sons, 1959</p></li><li><p>Diederik P. Kingma, Max Welling // An Introduction to Variational Autoencoders //  6 Jun 2019 // URL <a href="https://arxiv.org/abs/1906.02691" rel="noopener noreferrer nofollow"><u>https://arxiv.org/abs/1906.02691</u></a> </p></li></ol><p>Работа выполнена при поддержке Фонда содействия инновациям.</p></div></details></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5BruGPT3%5D" class="tm-tags-list__link">ruGPT3</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bgpt-3%5D" class="tm-tags-list__link">gpt-3</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B5%D1%80%D1%8B%5D" class="tm-tags-list__link">трансформеры</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%5D" class="tm-tags-list__link">генеративные модели</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%5D" class="tm-tags-list__link">нейронные сети</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%80%D0%B0%D0%BD%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA%5D" class="tm-tags-list__link">ранжировщик</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/machine_learning/" class="tm-hubs-list__link">
    Машинное обучение
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/artificial_intelligence/" class="tm-hubs-list__link">
    Искусственный интеллект
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/natural_language_processing/" class="tm-hubs-list__link">
    Natural Language Processing
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 3: ↑3 и ↓0</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 3: ↑3 и ↓0" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+3</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">1.9K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    27
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/mechkladenets/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><svg class="tm-svg-img tm-image-placeholder tm-image-placeholder_blue"><!----> <use xlink:href="/img/megazord-v24.ce74655c.svg#placeholder-user"></use></svg></div></a> <div class="tm-user-card__meta"><div title=" 13 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_positive">
    9
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">3</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/mechkladenets/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @mechkladenets
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Ai, Data-science</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/583516/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 11 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/583516/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/583516/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"583516":{"id":"583516","timePublished":"2021-10-14T14:07:10+00:00","isCorporative":false,"lang":"ru","titleHtml":"Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов","leadData":{"textHtml":"\u003Cp\u003EНейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка (NLP, NLU) для создания реалистичных, человечных разговорных «скиллов». Одним из первых примеров «человечных» диалоговых решений стала Xiaoice от Microsoft, которая обладала навыками дружелюбности. Позже такие компании как Яндекс, Google [1], Mail.ru и другие выпустили на рынок своих голосовых помощников. Однако все они столкнулись с фундаментальной проблемой: их решения хорошо выполняют запросы пользователей, связанные с четкими командами («расскажи новости»), но совершенно не обладают человечными способностями, качествами характера, эмуляцией чувств, эмпатией и поэтому не способны поддерживать человеческий разговор на различные темы. При этом «видимость человечности» часто обеспечивается набором шаблонных фраз и шуток, подходящих практически в любой ситуации (неспецифичных контексту разговора).\u003C\u002Fp\u003E\u003Cp\u003EВ этой статье мы покажем, как устроен и как работает разработанный нами умный Ранжировщик ответов для нейросеток Трансформер и какой эффект он оказывает на качество разговора любых генеративных чатботов. \u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":9,"votesCount":13},"rating":3,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"107432","alias":"mechkladenets","fullname":null,"avatarUrl":null,"speciality":"Ai, Data-science"},"statistics":{"commentsCount":11,"favoritesCount":27,"readingCount":1908,"score":3,"votesCount":3},"hubs":[{"relatedData":null,"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true},{"relatedData":null,"id":"21922","alias":"artificial_intelligence","type":"collective","title":"Искусственный интеллект","titleHtml":"Искусственный интеллект","isProfiled":false},{"relatedData":null,"id":"22125","alias":"natural_language_processing","type":"collective","title":"Natural Language Processing","titleHtml":"Natural Language Processing","isProfiled":true}],"flows":[{"id":"1","alias":"develop","title":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EНейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка (NLP, NLU) для создания реалистичных, человечных разговорных «скиллов». Одним из первых примеров «человечных» диалоговых решений стала Xiaoice от Microsoft, которая обладала навыками дружелюбности. Позже такие компании как Яндекс, Google [1], Mail.ru и другие выпустили на рынок своих голосовых помощников. Однако все они столкнулись с фундаментальной проблемой: их решения хорошо выполняют запросы пользователей, связанные с четкими командами («расскажи новости»), но совершенно не обладают человечными способностями, качествами характера, эмуляцией чувств, эмпатией и поэтому не способны поддерживать человеческий разговор на различные темы. При этом «видимость человечности» часто обеспечивается набором шаблонных фраз и шуток, подходящих практически в любой ситуации (неспецифичных контексту разговора).\u003C\u002Fp\u003E\u003Cp\u003EВ этой статье мы покажем, как устроен и как работает разработанный нами умный Ранжировщик ответов для нейросеток Трансформер и какой эффект он оказывает на качество разговора любых генеративных чатботов. \u003C\u002Fp\u003E\u003Cp\u003EДля того, чтобы решить проблему «человечности» чатботов и голосовых помощников необходимо разработать инфраструктуру базовых навыков (скиллов и стилей) цифровой личности на основе современных архитектур нейронных сетей с возможностью правдоподобного генерирования ответов на запросы пользователей. При этом данная инфраструктура должна обладать возможностью бесшовной интеграции различных архитектур нейронных сетей, что является ключевым элементом, обеспечивающим качество когерентного разговора при переключении скиллов.\u003C\u002Fp\u003E\u003Cp\u003EМы в Аватар Машина считаем, что важность данного исследования обусловлена его центральным местом в науке и исследовании работы мозга и, как следствие, работы нейросетевых архитектур, которые, как известно, во многом калькированно повторяют архитектуру некоторых его отделов. \u003C\u002Fp\u003E\u003Cp\u003EНапример, директор Научно-координационного совета Центра науки и технологий искусственного интеллекта МФТИ Сергей Шумский в своей книге «Машинный интеллект. Очерки по теории машинного обучения и искусственного интеллекта» [2]  отмечает важность повторения, или, более верно «воссоздания» биологической архитектуры различных отделов мозга в искусственных нейронных сетях. В книге он предлагает подход к созданию «сильного» искусственного интеллекта с использованием принципов работы человеческого мозга. Благодаря правильной архитектуре исследователи смогли бы добиться и аналогичных когнитивных свойств искусственных систем. Пока же уровень развития когнитивных свойств в сфере Conversational Ai (разговорного искусственного интеллекта) является довольно низким: слабая память в нейросетях LSTM, простые seq2seq модели, даже эмерджентный феномен «внимания» (attention) в самых современных нейросетях трансформер довольно ограниченно моделирует то, как человек в реальности работает с объектами, обращает внимание и запоминает важные факты в потоке событий.\u003C\u002Fp\u003E\u003Cp\u003EДоктор Alan D. Thompson, являющийся экспертом в ИИ на семинаре  «Новая нерелевантность интеллекта» [3]  в августе 2021го года представил свой взгляд на разрозненность моделей нейросетей и то, как они соответствуют современным представлениям о работе мозга. На рисунке ниже представлена таблица соответствия различных когнитивных способностей человека и тех отделов мозга, которые за них отвечают. В частности за разговор в данном сравнении представлены ответственными чатботы от Facebook Ai – BlenderBot (первой версии) [4] и система разговорного ИИ с интерактивом от Google – LaMDa [5]. Однако данные системы, несмотря на всю свою сложную структуру обладают существенным недостатком – они работают, используя раздельные пайплайны из разных нейросетей, в результате чего достигнуть эмерджентного эффекта невозможно, ведь в таких системах модули и компоненты являются отдельными не архитектурно, как в нейросетях, а структурно – то есть они объединены программно, через API и вызовы функций, что хорошо работает инженерно, но не позволяет появиться в такой системе новым свойствам.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg\" alt=\"Рисунок 1. Модели ИИ и соответствующие им разделы мозга\" title=\"Рисунок 1. Модели ИИ и соответствующие им разделы мозга\" width=\"1280\" height=\"720\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EРисунок 1. Модели ИИ и соответствующие им разделы мозга\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EВ этой разработке мы учитывали недостатки существующих, лучших на сегодняшний день разговорных систем, в том числе и команды разработки бота ChirpyCardinal [6] (2е место в конкурсе от компании Amazon Alexa Prize), проекта AliceMind [7] от китайской компании Alibaba. Очень хорош также и чатбот от Сбера [\u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fsberbank\u002Fblog\u002F524522\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Eстатья\u003C\u002Fu\u003E\u003C\u002Fa\u003E] - и все же в некоторых сеттингах мы замечали разрывы в логике поддержания разговора, при том, что в целом ответы на каждую реплику у него очень разумные.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cem\u003EИтак, постановка исследовательской задачи такая: разработать систему ранжирования реплик, генерируемых чатботом так, чтобы она работала когнитивно близко к тому, как человек выбирает ту или иную реплику в контексте разговора – как правило, человек рассматривает несколько вариантов ответных реплик, учитывая всю историю общения, важные факты и согласованность по тематике. Именно так и должна работать система ранжирования – ведь сейчас генераторы в нейросетях трансформер устроены куда более просто.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cp\u003EНа данный момент очень актуальна проблема генерации текста в нейросетевых генеративных ботах, в частности, построенных на базе GPT(\u003Cem\u003EGenerative Pre-trained Transformer\u003C\u002Fem\u003E)[8]. Генерация ведется на уровне токенов, а выбирать следующий токен в последовательности можно разными способами, например, при помощи генератора случайных чисел, где нейросеть задает для него распределение вероятностей на каждом шаге. Также существует стратегия выбирать на каждом шаге токен, которому соответствует наибольшая вероятность, или использовать алгоритмы на вроде метода поиска по лучу (beam search). [9] Этими методами возможно сгенерировать несколько версий ответов на один вопрос или реплику. Ранжирование версий ответов позволяет улучшать качество генерации, делая выход модели более согласованным по смыслу(тематике) с вопросом или контекстом. Предложенный в этой работе алгоритм ранжирования работает по следующему принципу: текст вопроса заменяется на вектор признаков, аналогично векторизуется каждая версия ответа, рассчитываются расстояния между вектором вопроса или контекста и каждым вектором ответа, таким образом, чтобы ответ с нулевым индексом был наиболее подходящим по тематике к вопросу.\u003C\u002Fp\u003E\u003Cp\u003EВ нашей разработке мы предлагаем алгоритм векторизации текста на базе нейронной сети с тремя функциями ошибки, такими как ошибка классификации, ошибка моделирования распределения (дивергенция Кульбака-Лейблера) и ошибка дисперсии (отклонение логарифма дисперсии от вектора нулей), что позволяет преобразовывать тексты в вектора без разрывов в пространстве признаков.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cem\u003EДалее рассмотрим основные шаги исследования: набор данных, алгоритм, векторизацию.\u003C\u002Fem\u003E \u003C\u002Fp\u003E\u003Ch2\u003EОписание набора данных\u003C\u002Fh2\u003E\u003Cp\u003EДля исследования было выбрано 2 набора данных:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EПервый набор данных использовался для предварительной оценки модели, включает в себя девять тем: игры, программное обеспечение, искусство, технологии, отношения, хобби, психология, облачные технологии, языки программирования.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EВторой набор данных представлял собой 139 тысяч сэмплов текстов, разделенных на 66 классов (тем), которые чаще всего использовались в общении с ботом, основные темы: игры, книги, программное обеспечение, вселенная, футбол, единоборства, искусство, технологии, отношения и т.п.  \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EДанный датасет, его распределение тематик и объем был использован потому, что по нашим наблюдениям именно эти темы наиболее часто встречаются в живом разговоре, они достаточно полно представлены в Интернете и датасет относительно легко собрать из открытых источников в нужно объеме. \u003C\u002Fp\u003E\u003Ch2\u003EОписание алгоритма\u003C\u002Fh2\u003E\u003Cp\u003EАлгоритм ранжирования представлен на рисунке 23. Текст поступает в блок предварительной обработки, который преобразует слова текста в токены. Нейронная сеть блока векторизации формирует вектор фиксированной размерности из последовательности токенов. Все тексты, которые должны быть ранжированы векторизуются вышеописанным способом и добавляются в массив структур вектор-текст. После чего алгоритм ранжирования сортирует векторы по неубыванию расстояния и текст, соотнесенный с вектором с нулевым индексом является с точки зрения модели наиболее подходящим по тематике к тексту вопроса.\u003C\u002Fp\u003E\u003Cp\u003EОсновное требование к пространству признаков следующее: близкие по смыслу тексты должны быть преобразованы в близкие по некоторой метрике точки (векторы).\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 2. Общая структура алгоритма ранжирования\" title=\"Рисунок 2. Общая структура алгоритма ранжирования\" height=\"663\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e1\u002F71e\u002Fc1b\u002F8e171ec1b8407f81ab15400acc2ea13a.png\" data-width=\"394\"\u002F\u003E\u003Cfigcaption\u003EРисунок 2. Общая структура алгоритма ранжирования\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EПредварительная обработка текста\u003C\u002Fh2\u003E\u003Cp\u003EНа первом этапе текст стандартизируется, т.е. из него удаляются все знаки препинания и специальные символы, множественные пробелы заменяются на одинарные, также удаляются стоп-слова, слова заменяются на соответствующие им леммы. Мы рассмотрели две стратегии токенизации:\u003C\u002Fp\u003E\u003Cp\u003Eа) токенизация на уровне лемм, и \u003C\u002Fp\u003E\u003Cp\u003Eб) токенизация при помощи предварительно обученного токенизатора BPE[10], используемого в GPT2[11].\u003C\u002Fp\u003E\u003Cp\u003EВо втором случае возможна работа с текстами, содержащими неизвестные слова и с опечатками. В случае работы с леммами составляется словарь из 30 тыс. наиболее часто встречающихся лемм. Блок-схема модуля предварительной обработки текстов показана на рисунке.\u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 3. Модуль предварительной обработки текста\" title=\"Рисунок 3. Модуль предварительной обработки текста\" height=\"423\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fd80\u002Ff17\u002Fdb3\u002Fd80f17db3c9b58c4684f7308def9b5e1.png\" data-width=\"242\"\u002F\u003E\u003Cfigcaption\u003EРисунок 3. Модуль предварительной обработки текста\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EВекторизация\u003C\u002Fh2\u003E\u003Cp\u003EМы разработали две стратегии векторизации: выход предпоследнего слоя нейросетевого классификатора и выход предсказания математического ожидания в вариационном классификаторе, он описан ниже.\u003C\u002Fp\u003E\u003Cp\u003EВходной слой — это слой встраивания, он ставит вектор в соответствие каждому индексу. Последовательность индексов заменяется на матрицу. Изначально векторы либо выбираются случайными, либо задаются предварительно обученные, а далее, во время обучения сети могут обучаться вместе со всей сетью при помощи обратного распространения ошибки (backpropagation).\u003C\u002Fp\u003E\u003Cp\u003E    В данной работе в качестве классификаторов были исследованы следующие сети: \u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eодномерная сверточная,\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eполносвязная,\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eрекуррентная,\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eгибридная: содержащая как сверточные, так и рекуррентные слои. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EОдномерные сверточные и рекуррентные нейронные сети хорошо зарекомендовали себя для работы с последовательностями[12], в том числе и с текстами. [13, 14] Исследование проводилось на данных из первого датасета содержащего 9 классов (тем), описанного выше в подразделе Описание набора данных.\u003C\u002Fp\u003E\u003Ch2\u003EРезультаты исследования\u003C\u002Fh2\u003E\u003Cp\u003EНиже, на рисунке 4, представлены графики обучения некоторых архитектур нейронных сетей из этого исследования, без предварительно обученных векторов встраивания. А именно, одномерной сверточной сети, полносвязной, LSTM, и гибридной, содержащей, как одномерные сверточные слои, так и LSTM ячейки.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания\" title=\"Рисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания\" height=\"792\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F69d\u002Fca5\u002Fb8b\u002F69dca5b8b680f3538bf8345387fbbd34.png\" data-width=\"1133\"\u002F\u003E\u003Cfigcaption\u003EРисунок 4. Графики обучения различных архитектур, без предварительно обученных векторов встраивания\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНа рисунке 5 показаны графики обучения следующих архитектур (одномерной сверточной сети с 3мя сверточными слоями, одномерной сверточной сети с одним сверточным слоем и LSTM сети) с предварительно обученными векторами встраивания.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани\" title=\"Рисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани\" height=\"860\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F067\u002Ff16\u002F022\u002F067f16022f13dface2701c3f9b2c0696.png\" data-width=\"1160\"\u002F\u003E\u003Cfigcaption\u003EРисунок 5. Графики обучения различных архитектур, с предварительно обученными векторами встраивани\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EРезультаты тестирования нейронных сетей сведены в таблицу 1, все замеры выполнены на валидационной выборке.\u003C\u002Fp\u003E\u003Cdiv\u003E\u003Cdiv class=\"table\"\u003E\u003Ctable\u003E\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EНомер эксперимента\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EВероятность правильного распознавания\u003C\u002Fp\u003E\u003Cp\u003E(Accuracy)\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EОшибка на валидационных данных\u003C\u002Fp\u003E\u003Cp\u003E(Перекрестная энтропия)\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd colspan=\"3\"\u003E\u003Cp\u003EВектора встраивания инициализированы случайными числами\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EСверточная сеть №1\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E71.05%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8898\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EПолносвязная\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E74.57%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.767\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EСверточная сеть №2\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E74.44%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.7862\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003ELSTM\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E73.52%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8146\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EGRU\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E73.19%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8177\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003ECNN+LSTM\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E71.46%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8886\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd colspan=\"3\"\u003E\u003Cp\u003EПред. обученные вектора встраивания (Word2Vec)\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EСверточная сеть №1\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E69.38%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8714\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003EСверточная сеть №2\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E75.11%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E0.7357\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003ELSTM\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E73.77%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E0.8293\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cp\u003EТаблица 1. Результаты тестирования различных архитектур\u003C\u002Fp\u003E\u003Cp\u003EВ конечном итоге наилучший результат показывает Сверточная сеть №2, вероятность правильного распознавания у нее составила 75.11%.\u003C\u002Fp\u003E\u003Cp\u003EВ результате описанного в данном разделе исследования была разработана модель ранжировщика реплик(ответов) генеративной модели. Данная модель является прототипом модели выбора логичного ответа у человека, однако, как мы рассмотрим далее в следующем разделе есть несколько вопросов, касающихся эффективности ее срабатывания в различных контекстах разговора – плавности переключения тематик и их согласованности внутри самих сгенерированных реплик.\u003C\u002Fp\u003E\u003Ch2\u003EОбучение на новой выборке\u003C\u002Fh2\u003E\u003Cp\u003EДля дальнейшего обучения на втором наборе данных в 139 тыс. реплик, разделенных на 66 классов, была выбрана одномерная сверточная сеть с одним сверточным и одним полносвязным слоем, т.к. она обеспечивала наивысшую вероятность правильного распознавания.  График обучения сверточной сети для распознавания 66 классов представлен на рисунке 27. \u003C\u002Fp\u003E\u003Cfigure class=\"\"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 6. График обучения нейронной сети\" title=\"Рисунок 6. График обучения нейронной сети\" height=\"265\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fd8a\u002F02a\u002F85b\u002Fd8a02a85bec5d81e347fe80fbce6d86c.png\" data-width=\"391\"\u002F\u003E\u003Cfigcaption\u003EРисунок 6. График обучения нейронной сети\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EВероятность правильного распознавания на валидационных данных составила 64.01%\u003C\u002Fp\u003E\u003Cp\u003EНиже представлена визуализация векторов, получаемых из текстов, на скрытом слое: на рисунке изображены все 139 тысяч текстовых реплик, одна текстовая  реплика — одна точка, цветом отмечены классы. На рисунке 7 слева сделана проекция векторного пространства на 2 оси, на рисунке 7 справа — визуализация в 3х мерном пространстве. Если рассмотреть распределение векторов после векторизации текстов, то можно заметить, что их распределение имеет довольно сложный вид и не обеспечивает плавного перехода между темами.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cem\u003EПример. Представьте, что вы говорите с собеседником на тему отношений, и постепенно тема меняется на политику. На какую тему должна быть реплика после смены темы разговора? Про отношения, так как контекст содержит много реплик с этим классом или про политику, так как это новая актуальная тема, а может быть нужна смесь? Здесь нет однозначного ответа. Если темы различаются между собой сильно, то они попадут в разные «лучи салюта» - чатбот не сможет сгенерировать реплику, которая бы соответствовала обеим тематикам. Правда, это мы наблюдаем в комментариях почти к любому социальному ролику или статье - разброс тем даже внутри одной отрасли колоссальный и поэтому часто комментарии людей выглядят оторванными от контекста.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора\" title=\"Рисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора\" height=\"667\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fba4\u002F0e4\u002F20f\u002Fba40e420ffc3e1c1ffd2c885b8f6581e.png\" data-width=\"1535\"\u002F\u003E\u003Cfigcaption\u003EРисунок 7. Двумерная и трехмерная визуализация скрытого состояния классификатора\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EДля реализации более плавного перехода между темами была введена дополнительная функция потерь, известная как дивергенция Кульбака – Лейблера [14], используемая в вариационных автокодировщиках [15].  Также была введена составляющая функции потерь, отвечающая за форму и размер области в пространстве признаков, ошибка которой увеличивается с ростом отклонения логарифма дисперсии от вектора, состоящего из нулей. \u003C\u002Fp\u003E\u003Cp\u003EДивергенция Кульбака – Лейблера показывает отклонение полученного распределения от ожидаемого. В данной задаче мы хотим получить гауссово распределение, т.е. чтобы наше признаковое пространство было в виде гиперсферы.\u003C\u002Fp\u003E\u003Cp\u003EТаким образом, мы ожидаем получить гиперсферы без разрывов, а получаем что-то другое — так вот этот лосс показывает насколько сильно мы отклонились. А производная от него по параметрам модели позволяет настраивать модель так, чтобы она «выдавала» именно гиперсферы. \u003C\u002Fp\u003E\u003Cp\u003EОшибка Кульбака-Лейблера рассчитывается по следующей формуле: в данной формуле расписан след и определитель диагональной ковариационной матрицы, \u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"133\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Ff79\u002F642\u002F5af\u002Ff796425afe81d1ca0e84a150c6997b2c.png\" data-width=\"1107\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E— коэффициент вклада ошибки Кульбака – Лейблера в общую функцию потерь. \u003C\u002Fp\u003E\u003Cp\u003EОшибка дисперсии рассчитывается по формуле:\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"104\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8b9\u002F121\u002F349\u002F8b91213499757bbcf6f310919d30c68a.png\" data-width=\"755\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EВ качестве ошибки классификации была использована категориальная перекрестная энтропия,\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"138\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F422\u002F580\u002F313\u002F422580313810f57e1e333b4155baa961.png\" data-width=\"656\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EКоэффициенты kKL, kVar, kH введены для настройки модели. В данной работе они соответственно равны 7, 2, 1.\u003C\u002Fp\u003E\u003Cp\u003EНа рисунке 8 показана блок-схема классификатора, для векторизации используется выход предсказывающий вектор математического ожидания генератора случайных чисел с гауссовым распределением.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 8. Блок-схема классификатора\" title=\"Рисунок 8. Блок-схема классификатора\" height=\"844\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fef2\u002Feb7\u002F241\u002Fef2eb72412121755a4d8a5e943c65326.png\" data-width=\"567\"\u002F\u003E\u003Cfigcaption\u003EРисунок 8. Блок-схема классификатора\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНа рисунке 9 показана зависимость различных составляющих функции ошибки от эпохи обучения. По причине того, что масштаб изменений других составляющих функции потерь сильно отличается от масштаба изменений отклонения логарифма дисперсии, ошибка дисперсии вынесена в другом масштабе на рисунок 10.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи\" title=\"Рисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи\" height=\"551\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F430\u002F0c5\u002Fd3e\u002F4300c5d3e208e33afe97f29e146df7cb.png\" data-width=\"1380\"\u002F\u003E\u003Cfigcaption\u003EРисунок 9, 10. Зависимость ошибок обучения от эпохи. Зависимость ошибки дисперсии от эпохи\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EНиже представлена визуализация пространства признаков, на рисунке слева — проекция на две оси, на рисунке справа — на три.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания\" title=\"Рисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания\" height=\"555\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3bf\u002F2d8\u002Fc4f\u002F3bf2d8c4f4dd1060d1e39e6bc2c0d16c.png\" data-width=\"1409\"\u002F\u003E\u003Cfigcaption\u003EРисунок 11. Двумерная и трехмерная визуализация предсказания мат. ожидания\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EРассмотрим далее параметры при использовании в качестве токенизатора предварительно обученного токенизатора BPE. На рисунке 12 показана зависимость различных составляющих функции ошибки от эпохи обучения, также на рисунке 13, продемонстрированы проекция пространства признаков на две и три оси соответственно, параметры функции ошибки следующие, \u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" height=\"95\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F36c\u002F1d1\u002Fcca\u002F36c1d1cca9842cb1d6e1cd60354d0612.png\" data-width=\"900\"\u002F\u003E\u003Cfigcaption\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003Eгде BS размер мини-пакета.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 12. Зависимость составляющих ошибки обучения от эпохи\" title=\"Рисунок 12. Зависимость составляющих ошибки обучения от эпохи\" height=\"431\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F025\u002Fe9e\u002F046\u002F025e9e04670e7769d00f14879da211cc.png\" data-width=\"1058\"\u002F\u003E\u003Cfigcaption\u003EРисунок 12. Зависимость составляющих ошибки обучения от эпохи\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F1c7\u002F9f1\u002F1f8\u002F1c79f11f89f79d06d5dd3af177a4fbe2.jpg\" alt=\"Рисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания\" title=\"Рисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания\" width=\"1491\" height=\"689\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F1c7\u002F9f1\u002F1f8\u002F1c79f11f89f79d06d5dd3af177a4fbe2.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EРисунок 13. Двумерная и трехмерная визуализация предсказания мат. ожидания\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cstrong\u003EКлючевым элементом данного исследования является выбор метрики и архитектуры для алгоритма ранжирования.\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cp\u003EНаилучшая метрика должна обеспечивать лучшую точность при ее использовании в методе ближайшего соседа в задаче классификации, т.к. это означает, что при ранжировании в самом верху списка (с нулевым индексом) окажется текст той же темы, что и текст на входе. Результаты тестирования различных метрик, на двух последних архитектурах с токенизацией на уровне лемм сведены в таблицу 2.\u003C\u002Fp\u003E\u003Cdiv\u003E\u003Cdiv class=\"table\"\u003E\u003Ctable\u003E\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd rowspan=\"2\"\u003E\u003Cp\u003EМетрика\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd colspan=\"2\"\u003E\u003Cp\u003EБез использования дивергенции Кульбака-Лейблера и ошибки дисперсии\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd colspan=\"2\"\u003E\u003Cp\u003EС использованием дивергенции Кульбака-Лейблера и ошибки дисперсии\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EF1 микро усреднение\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EF1 макро усреднение\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EF1 микро усреднение\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EF1 макро усреднение\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EЕвклидова\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E78.2%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E67.74%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E90.2%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E82.26%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМанхэттена\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E78.1%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E66.04%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.7%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.67%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EЧебышёва\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E74.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E60.86%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E88.6%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E79.83%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=3\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E78%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E66.9%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.9%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E81.53%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=4\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E77.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E65.56%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.8%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E81.23%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=5\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E76.4%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E63.97%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.7%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.9%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=6\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E77%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E64.65%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.4%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.25%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=7\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E76.7%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E64.48%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.2%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.01%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=8\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E76.4%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E64.18%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.1%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.02%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМинковского p=9\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E76.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E63.79%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.1%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.02%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EКанберры\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E76.5%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E64.54%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E83.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E72.25%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EСтандартизированная Евклидова метрика\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E77.0%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E64.65%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E87.0%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E78.8%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EНесходство Брея-Кертиса\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E79.1%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E67.02%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E89.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.66%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cp\u003EТаблица 2. Результат тестирования метрик, токенизация на уровне лемм \u003C\u002Fp\u003E\u003Cp\u003EСравнение различных режимов обучения, а также сравнение с векторизацией при помощи многоязычного BERT’а, без дообучения на нашем наборе данных, с использованием предварительно обученного токенизатора BPE, сведены в таблицу 3, максимальное число токенов в последовательности составляет 85, вероятность правильного распознавания оценивалась, как усредненная по 66 классам.   \u003C\u002Fp\u003E\u003Cdiv\u003E\u003Cdiv class=\"table\"\u003E\u003Ctable\u003E\u003Ctbody\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd colspan=\"2\"\u003E\u003Cp\u003E\u003Cstrong\u003EОбучено на лемматизированных\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003EОбучено на не лемматизированных\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003EBert\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EДатасет без лемматизации\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003EДатасет с лемматизацией\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EЕвклидова\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E50.6%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E82.9%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E62.42%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E26.4%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EМанхэттен\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E49.9%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E82.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E62.23%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E26.0%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EЧебышёва\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E46.5%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E80.1%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E61.74%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E20.3%\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cp\u003EНесходство Брея-Кертиса\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E51.3%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E82.3%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E62.74%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003Ctd\u003E\u003Cp\u003E\u003Cstrong\u003E28.6%\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cp\u003EТаблица 3. Результат тестирования метрик, токенизация на уровне байт \u003C\u002Fp\u003E\u003Cp\u003EНиже на рисунке представлены фрагменты программного кода реализации Ранжировщика, в качестве скилла в экосистеме скиллов и стилей: на рисунке 14 класс Ranker и его методы подгрузки параметров модели, удаление стоп-слов. Полностью код мы не раскрываем.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 14. Фрагмент кода: класс Ранжировщик\" title=\"Рисунок 14. Фрагмент кода: класс Ранжировщик\" height=\"1020\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F7a6\u002F0de\u002F834\u002F7a60de834da77decbaf6ff510dde5965.png\" data-width=\"1374\"\u002F\u003E\u003Cfigcaption\u003EРисунок 14. Фрагмент кода: класс Ранжировщик\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EРезультаты диалоговой модели и тестирование на разумность\u003C\u002Fh2\u003E\u003Cp\u003EКак видно из таблицы 2, наилучшее качества ранжировщика обеспечивается использованием в качестве модуля векторизации классификатора с использованием моделирования распределения посредством введения дивергенции Кульбака — Лейблера и контроля дисперсии. \u003C\u002Fp\u003E\u003Cp\u003EЕвклидова метрика обеспечивает наилучшее качество ранжирования, при использовании токенизации на уровне лемм, а при токенизации на уровне байт, наилучшее качество было получено при использовании «несходства Брея-Кертиса». Объем памяти занимаемой нашей моделью составляет всего 10 Мб. \u003C\u002Fp\u003E\u003Cp\u003EРанжирование версий ответов позволяет улучшать качество генерации, делая выход модели более согласованным по смыслу(тематике) с вопросом или контекстом. Важно отметить, что согласование работает с учетом всего контекста разговора, а не только последней реплики пользователя.\u003C\u002Fp\u003E\u003Cp\u003EПоскольку бенчмаркинг (benchmarking) диалоговых моделей является сейчас активной исследовательской темой и на сегодняшний день еще не существует индустриального стандарта сравнения общения чатботов – мы оценивали:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003Eметрику SSA от Google [1] (Sensibleness and Specificity Average – среднее между специфичностью и релевантностью ответа в данном контексте)  и\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003Eобщий показатель вовлеченности и интереса общения, выражающийся в количестве пар реплик общения одного пользователя за сессию (промежуток времени между репликами не более 1 минуты) усреднённый по всем пользователям.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EМы расскажем о сеттинге тестирования позже. Рассмотрим сначала диалоговую модель без ранжировщика и оценим в целом логику его ответов на рисунке ниже:\u003C\u002Fp\u003E\u003Cfigure class=\"float full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы \" title=\"Рисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы \" height=\"1142\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Faef\u002F72b\u002Fdbf\u002Faef72bdbf815ed97b861ad0cf56e7492.png\" data-width=\"791\"\u002F\u003E\u003Cfigcaption\u003EРисунок 15. Модель без ранжировщика: ответы в целом логичные, но неспецифичные и без учета контекста и общей темы \u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E \u003C\u002Fp\u003E\u003Cp\u003EВ сеттинге выше модель выбирает ответ используя beam search, однако какое бы число лучей ни было использовано, это все равно не позволяет работать с логикой ответа на уровне целого предложения – ведь генерация происходит по токенам.\u003C\u002Fp\u003E\u003Cp\u003EОтветы при этой похожи на ответы Яндекс Алисы: они иногда смешные, но их основное свойство это неспецифичность, то есть, как правило, такие ответы подходят под многие контексты сразу и именно поэтому кажутся пользователям, общающимся с ботом слишком общими, не содержащими новой полезной информации и отсылок к предыдущим репликам.\u003C\u002Fp\u003E\u003Cp\u003EЕще одно свойство ответов: они в целом следуют теме разговора, но сами темы имеют часто нечеткие границы и поэтому часто вместо ответа на вопрос или исполнения просьбы (разные модальности) модель генерирует ответ по теме, но полностью противоречивый по содержанию.\u003C\u002Fp\u003E\u003Ch2\u003EНаша диалоговая модель\u003C\u002Fh2\u003E\u003Cfigure class=\"float full-width \"\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" alt=\"Рисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные\" title=\"Рисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные\" height=\"1534\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fabc\u002F128\u002Fcdb\u002Fabc128cdb0c37d6b2ee64a82576bcd0a.png\" data-width=\"860\"\u002F\u003E\u003Cfigcaption\u003EРисунок 16. Модель с ранжировщиком и личностью: ответы логичные, с учетом темы и контекста, специфичные и релевантные\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EДиалог с моделью, имеющей ранжировщик и личность(мы опишем ее в другой статье) существенно отличается в лучшую сторону по следующим характеристическим параметрам:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003EОтветы специфичные: они относятся к данной конкретной ситуации, возникшей в контексте разговора.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EОтветы релевантные: они разумны и логичны, семантически согласованы и грамматически верны: если пользователь задавал вопрос, то модель дает ответ. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EУ бота есть личность, он отыгрывает девушку и это прослеживается в глаголах и местоимениях женского рода(«люблю ходить одна»)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EБот вежливый и обладает знаниями (хотя боту и не обязательно быть вежливым) и поддерживает более качественное общение на темы о психологии, сексе, отношениях, потому что для обучения использовался преимущественно такой датасет. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EВ процессе ранжировщик рассматривал в том числе и такие варианты генерации:\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003E«И мне» (слишком короткий и неспецифичный)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E«А мне холодно» (нерелевантный теме разговора)Однако выбран был наиболее согласованный по контексту и тематике вариант:\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E«У меня такая же проблема, только еще зима не закончилась. Так хочется тепла и солнца..»\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EНиже представлены тематически другие разговоры с разработанной моделью и скиллами ранжировщика и личности.\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F9a8\u002Fa88\u002F5c5\u002F9a8a885c52c31bf1f6448a83ed23c92b.jpg\" alt=\"Рисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации\" title=\"Рисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации\" width=\"1297\" height=\"914\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F9a8\u002Fa88\u002F5c5\u002F9a8a885c52c31bf1f6448a83ed23c92b.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EРисунок 17. Модель с ранжировщиком и личностью: каверзные вопросы, тематика финансов, нетипичные ситуации\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F497\u002F669\u002F8a7\u002F4976698a70ae8f18d91dc64cb29f0995.jpg\" alt=\"Рисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры\" title=\"Рисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры\" width=\"1188\" height=\"1079\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F497\u002F669\u002F8a7\u002F4976698a70ae8f18d91dc64cb29f0995.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EРисунок 18. Модель с ранжировщиком и личностью: общение о фактах реального мира, разрешение анафоры\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure class=\"float \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780q1\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fdfb\u002Fd6a\u002F20b\u002Fdfbd6a20bbe3734a5f51cb0c53b35d58.jpg\" alt=\"Рисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)\" title=\"Рисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)\" width=\"416\" height=\"899\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Fdfb\u002Fd6a\u002F20b\u002Fdfbd6a20bbe3734a5f51cb0c53b35d58.jpg\" data-blurred=\"true\"\u002F\u003E\u003Cfigcaption\u003EРисунок 19. Модель с ранжировщиком и личностью: поддержка сложных тем (психология, отношения)\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EРазработанная модель Ранжировщика является в целом хорошим научным результатом и развитием идеи выбора логичного и разумного ответа в зависимости от контекста разговора. \u003C\u002Fp\u003E\u003Cp\u003EМодель является прототипом скилла когнитивной способности человека к выбору логичного продолжения разговора в соответствии с целью, состоянием, эмоциями и другими параметрами, которые являются внешними, но которые проявлены в разговоре. Модель имеет малый размер (10мб.), легко обучается и не требует огромных массивов датасетов для обучения на новые тематики. Наилучшее качества ранжировщика обеспечивается использованием в качестве модуля векторизации классификатора с использованием моделирования распределения посредством введение дивергенции Кульбака — Лейблера и контроля дисперсии. Евклидова метрика обеспечивает наилучшее качество ранжирования, при использовании токенизации на уровне лемм, при токенизации на уровне байт, наилучшее качество было получено при использовании «несходства Брея-Кертиса». \u003C\u002Fp\u003E\u003Cp\u003EНаш бот полностью готов к коммерческому внедрению и уже продается на рынке. Результаты разработки мы уже докладывали на конференции по искусственному интеллекту Ai-men. Подроднее о боте можно узнать на \u003Ca href=\"http:\u002F\u002Fgraphgrail.com\u002Fru\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eсайте\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cdetails class=\"spoiler\"\u003E\u003Csummary\u003EСписок литературы\u003C\u002Fsummary\u003E\u003Cdiv class=\"spoiler__content\"\u003E\u003Col\u003E\u003Cli\u003E\u003Cp\u003ETowards a Human-like Open-Domain Chatbot [Электронный ресурс] Режим доступа \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2001.09977\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2001.09977\u003C\u002Fu\u003E\u003C\u002Fa\u003E свободный. - Загл. с экрана (дата обращения: 1.02.2021).\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EСергей Шумский. Машинный интеллект. Очерки по теории машинного обучения и искусственного интеллекта. — изд. первое, — М.: Наука, 2020. — 335 с. \u003Ca href=\"https:\u002F\u002Fwww.litres.ru\u002Fsergey-shumskiy\u002Fmashinnyy-intellekt-ocherki-po-teorii-mashinnogo-48958628\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Fwww.litres.ru\u002Fsergey-shumskiy\u002Fmashinnyy-intellekt-ocherki-po-teorii-mashinnogo-48958628\u002F\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EAlan D. Thompson. AI + the human brain. The new irrelevance of intelligence  [Электронный ресурс] \u003Ca href=\"https:\u002F\u002Flifearchitect.ai\u002Fbrain\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Flifearchitect.ai\u002Fbrain\u002F\u003C\u002Fu\u003E\u003C\u002Fa\u003E - Загл. с экрана (дата обращения: 10.08.2021)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EStephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston \u002F\u002F Recipes for building an open-domain chatbot \u002F\u002F April 7, 2020 \u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.13637\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F2004.13637\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003ELaMDA: our breakthrough conversation technology. [Электронный ресурс] \u003Ca href=\"https:\u002F\u002Fblog.google\u002Ftechnology\u002Fai\u002Flamda\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Fblog.google\u002Ftechnology\u002Fai\u002Flamda\u002F\u003C\u002Fu\u003E\u003C\u002Fa\u003E - Загл. с экрана (дата обращения: 10.08.2021)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EWelcome to Chirpy Cardinal. [Электронный ресурс]  \u003Ca href=\"https:\u002F\u002Fstanfordnlp.github.io\u002Fchirpycardinal\u002F\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Fstanfordnlp.github.io\u002Fchirpycardinal\u002F\u003C\u002Fu\u003E\u003C\u002Fa\u003E - Загл. с экрана (дата обращения: 10.08.2021)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EAliceMind: ALIbaba's Collection of Encoder-decoders from MinD (Machine IntelligeNce of Damo) Lab. [Электронный ресурс]   \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Falibaba\u002FAliceMind\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Fgithub.com\u002Falibaba\u002FAliceMind\u003C\u002Fu\u003E\u003C\u002Fa\u003E - Загл. с экрана (дата обращения: 10.08.2021)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EJianfeng Gao, Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, Heung-Yeung Shum \u002F\u002F Robust Conversational AI with Grounded Text Generation \u002F\u002F September 7, 2020 \u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2009.03457.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fpdf\u002F2009.03457.pdf\u003C\u002Fu\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003ELuca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktaschel, Vassilis Plachouras, Fabrizio Silvestri, Sebastian Riedel \u002F\u002F How Decoding Strategies Affect the Verifiability of Generated Text \u002F\u002F 29 Sep 2020\u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1911.03587.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fpdf\u002F1911.03587.pdf\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003ESerkan Kiranyaz, Onur Avci, Osama Abdeljaber, Turker Ince, Moncef Gabbouj, Daniel J. Inman \u002F\u002F 1D Convolutional Neural Networks and Applications – A Survey\u002F\u002F URL: \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fftp\u002Farxiv\u002Fpapers\u002F1905\u002F1905.03554.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fftp\u002Farxiv\u002Fpapers\u002F1905\u002F1905.03554.pdf\u003C\u002Fu\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EMarc Moreno Lopez, Jugal Kalita \u002F\u002F Deep Learning applied to NLP \u002F\u002F 9 Mar 2017\u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1703.03091.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fpdf\u002F1703.03091.pdf\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EWenpeng Yin, Katharina Kann, Mo Yu, Hinrich Schütze \u002F\u002F Comparative Study of CNN and RNN for Natural Language Processing \u002F\u002F 7 Feb 2017 \u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.01923\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1702.01923\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003ERaphael Shu, Hideki Nakayama \u002F\u002F COMPRESSING WORD EMBEDDINGS VIA DEEP COMPOSITIONAL CODE LEARNING \u002F\u002F 17 Nov 2017 \u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1711.01068.pdf\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fpdf\u002F1711.01068.pdf\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EKullback S. Information Theory and Statistics. — John Wiley &amp; Sons, 1959\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EDiederik P. Kingma, Max Welling \u002F\u002F An Introduction to Variational Autoencoders \u002F\u002F  6 Jun 2019 \u002F\u002F URL \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1906.02691\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cu\u003Ehttps:\u002F\u002Farxiv.org\u002Fabs\u002F1906.02691\u003C\u002Fu\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003EРабота выполнена при поддержке Фонда содействия инновациям.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdetails\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"ruGPT3"},{"titleHtml":"gpt-3"},{"titleHtml":"трансформеры"},{"titleHtml":"генеративные модели"},{"titleHtml":"нейронные сети"},{"titleHtml":"ранжировщик"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F056\u002Fc0c\u002Fc3c\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F583516\\\u002F\"},\"headline\":\"Улучшаем генеративных чатботов на нейросети ruGPT3: умный ранжировщик ответов\",\"datePublished\":\"2021-10-14T17:07:10+03:00\",\"dateModified\":\"2021-10-18T20:22:22+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"mechkladenets\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F583516\\\u002F#post-content-body\",\"about\":[\"h_machine_learning\",\"h_artificial_intelligence\",\"h_natural_language_processing\",\"f_develop\",\"f_popsci\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F583516\\\u002Ffec0cbbf227a5e1d025e9ebac2b355a9\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F056\\\u002Fc0c\\\u002Fc3c\\\u002F056c0cc3ce6aab5a0254bd9594d78067.jpeg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F8e1\\\u002F71e\\\u002Fc1b\\\u002F8e171ec1b8407f81ab15400acc2ea13a.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fd80\\\u002Ff17\\\u002Fdb3\\\u002Fd80f17db3c9b58c4684f7308def9b5e1.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F69d\\\u002Fca5\\\u002Fb8b\\\u002F69dca5b8b680f3538bf8345387fbbd34.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F067\\\u002Ff16\\\u002F022\\\u002F067f16022f13dface2701c3f9b2c0696.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fd8a\\\u002F02a\\\u002F85b\\\u002Fd8a02a85bec5d81e347fe80fbce6d86c.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fba4\\\u002F0e4\\\u002F20f\\\u002Fba40e420ffc3e1c1ffd2c885b8f6581e.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Ff79\\\u002F642\\\u002F5af\\\u002Ff796425afe81d1ca0e84a150c6997b2c.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F8b9\\\u002F121\\\u002F349\\\u002F8b91213499757bbcf6f310919d30c68a.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F422\\\u002F580\\\u002F313\\\u002F422580313810f57e1e333b4155baa961.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fef2\\\u002Feb7\\\u002F241\\\u002Fef2eb72412121755a4d8a5e943c65326.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F430\\\u002F0c5\\\u002Fd3e\\\u002F4300c5d3e208e33afe97f29e146df7cb.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F3bf\\\u002F2d8\\\u002Fc4f\\\u002F3bf2d8c4f4dd1060d1e39e6bc2c0d16c.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F36c\\\u002F1d1\\\u002Fcca\\\u002F36c1d1cca9842cb1d6e1cd60354d0612.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F025\\\u002Fe9e\\\u002F046\\\u002F025e9e04670e7769d00f14879da211cc.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F1c7\\\u002F9f1\\\u002F1f8\\\u002F1c79f11f89f79d06d5dd3af177a4fbe2.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F7a6\\\u002F0de\\\u002F834\\\u002F7a60de834da77decbaf6ff510dde5965.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Faef\\\u002F72b\\\u002Fdbf\\\u002Faef72bdbf815ed97b861ad0cf56e7492.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fabc\\\u002F128\\\u002Fcdb\\\u002Fabc128cdb0c37d6b2ee64a82576bcd0a.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F9a8\\\u002Fa88\\\u002F5c5\\\u002F9a8a885c52c31bf1f6448a83ed23c92b.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F497\\\u002F669\\\u002F8a7\\\u002F4976698a70ae8f18d91dc64cb29f0995.jpg\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Fdfb\\\u002Fd6a\\\u002F20b\\\u002Fdfbd6a20bbe3734a5f51cb0c53b35d58.jpg\"]}","metaDescription":"Нейронные сети все прочнее входят в нашу жизнь. В последнее время особую значимость приобретают исследования, связанные с обучением искусственных нейронных сетей в сфере анализа естественного языка...","mainImageUrl":null,"amp":true},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"machine_learning,artificial_intelligence,natural_language_processing"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
